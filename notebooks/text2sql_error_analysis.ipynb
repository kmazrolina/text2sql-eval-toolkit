{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325433af",
   "metadata": {},
   "source": [
    "# üß† Text-to-SQL Error Analysis Notebook\n",
    "\n",
    "Welcome to the **Text-to-SQL Error Analysis Notebook**. This notebook is designed to help you systematically evaluate and debug the performance of Text-to-SQL models using the `text2sql-eval-toolkit`.\n",
    "\n",
    "## üìã Notebook Overview\n",
    "\n",
    "This notebook is organized into the following sections:\n",
    "\n",
    "1. **Setup** ‚Äì Install dependencies and prepare your environment.\n",
    "2. **Inference** ‚Äì Run baseline or custom inference to generate and save SQL queries.\n",
    "3. **Execution** ‚Äì Execute ground truth and predicted SQL queries against a target database.\n",
    "5. **Error Analysis** ‚Äì Visualize and analyze common failure modes and error types.\n",
    "\n",
    "## üß∞ Toolkit Features\n",
    "\n",
    "- Plug-and-play evaluation for any Text-to-SQL model or pipeline\n",
    "- Execution-based and string-based metrics\n",
    "- Easy integration with Postgres, Cognos (WX BI) and SQLite databases (more to come soon!)\n",
    "- A set of enterprise and academic benchmarks (with configs in: [benchmarks.json](../data/benchmarks.json))\n",
    "- Tools for error analysis, including the use of LLM as a judge\n",
    "\n",
    "---\n",
    "\n",
    "> ‚ö†Ô∏è **Note**: This notebook assumes you have access to the internal GitHub repository and a working SSH setup for installation.\n",
    "\n",
    "Let‚Äôs get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1b48a9",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cad7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Installation\n",
    "\n",
    "# Auto-reload for dev\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Check if the package is already installed\n",
    "try:\n",
    "    import text2sql_eval_toolkit\n",
    "except ImportError:\n",
    "    # Install via git+SSH if not installed\n",
    "    !pip install -e git+ssh://git@github.com:IBM/text2sql-eval-toolkit.git#egg=text2sql-eval-toolkit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6429e2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available benchmarks:\n",
      "- bird_mini_dev_sqlite_test_50\n",
      "- bird_mini_dev_postgres_test_50\n",
      "- spider_dev_test_50\n",
      "- beaver_test_10\n",
      "- archer_en_dev_test_10\n",
      "- bird_sqlite_test_benchmark\n"
     ]
    }
   ],
   "source": [
    "## The toolkit comes with a set of pre-defined benchmarks in case you want to use them.\n",
    "## These benchmarks require some advance setup, such as setting the right env variables including connection strings, or downloading the sqlite DBs\n",
    "## Check the benchmarks.json file for the env variable or folder configrations you may need to set to use each benchmark\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# benchmarks_json_file = Path().resolve().parent / \"data\" / \"benchmarks.json\"\n",
    "benchmarks_json_file = Path().resolve().parent / \"data\" / \"test-benchmarks.json\"\n",
    "benchmarks_info = json.load(open(benchmarks_json_file, \"r\"))\n",
    "print(\"Available benchmarks:\")\n",
    "for benchmark_id in benchmarks_info.keys():\n",
    "    print(f\"- {benchmark_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b60be",
   "metadata": {},
   "source": [
    "# 2. Inference: Generating SQL for benchmark queries, or loading prior results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb3a0011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipelines with inference results: ['wxai:openai/gpt-oss-120b-agentic-baseline2-3attempts', 'wxai:openai/gpt-oss-120b-agentic-baseline5-3attempts', 'wxai:openai/gpt-oss-120b-greedy-zero-shot-chatapi', 'wxai:meta-llama/llama-4-maverick-17b-128e-instruct-fp8-greedy-zero-shot-chatapi', 'wxai:openai/gpt-oss-120b-agentic-baseline0-3attempts', 'wxai:openai/gpt-oss-120b-agentic-baseline3-3attempts', 'wxai:ibm/granite-4-h-small-greedy-zero-shot-chatapi', 'wxai:openai/gpt-oss-120b-agentic-baseline4-3attempts', 'wxai:openai/gpt-oss-120b-agentic-baseline1-3attempts', 'wxai:meta-llama/llama-3-3-70b-instruct-greedy-zero-shot-chatapi']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sql</th>\n",
       "      <th>wxai:meta-llama/llama-3-3-70b-instruct-greedy-zero-shot-chatapi</th>\n",
       "      <th>wxai:ibm/granite-4-h-small-greedy-zero-shot-chatapi</th>\n",
       "      <th>wxai:meta-llama/llama-4-maverick-17b-128e-instruct-fp8-greedy-zero-shot-chatapi</th>\n",
       "      <th>wxai:openai/gpt-oss-120b-greedy-zero-shot-chatapi</th>\n",
       "      <th>wxai:openai/gpt-oss-120b-agentic-baseline0-3attempts</th>\n",
       "      <th>wxai:openai/gpt-oss-120b-agentic-baseline1-3attempts</th>\n",
       "      <th>wxai:openai/gpt-oss-120b-agentic-baseline2-3attempts</th>\n",
       "      <th>wxai:openai/gpt-oss-120b-agentic-baseline3-3attempts</th>\n",
       "      <th>wxai:openai/gpt-oss-120b-agentic-baseline4-3attempts</th>\n",
       "      <th>wxai:openai/gpt-oss-120b-agentic-baseline5-3attempts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1483</td>\n",
       "      <td>[SELECT SUM(Consumption) FROM yearmonth WHERE ...</td>\n",
       "      <td>{'predicted_sql': 'SELECT SUM(Consumption) \n",
       "FR...</td>\n",
       "      <td>{'predicted_sql': 'SELECT SUM(Consumption) AS ...</td>\n",
       "      <td>{'predicted_sql': 'SELECT SUM(Consumption) \n",
       "FR...</td>\n",
       "      <td>{'predicted_sql': 'SELECT SUM(Consumption) AS ...</td>\n",
       "      <td>{'predicted_sql': 'SELECT \n",
       "    SUM(Consumption...</td>\n",
       "      <td>{'predicted_sql': 'SELECT SUM(Consumption) AS ...</td>\n",
       "      <td>{'predicted_sql': 'SELECT SUM(Consumption) AS ...</td>\n",
       "      <td>{'predicted_sql': 'SELECT SUM(Consumption) AS ...</td>\n",
       "      <td>{'predicted_sql': 'SELECT SUM(Consumption) AS ...</td>\n",
       "      <td>{'predicted_sql': 'SELECT SUM(Consumption) AS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1471</td>\n",
       "      <td>[SELECT CAST(SUM(IIF(Currency = 'EUR', 1, 0)) ...</td>\n",
       "      <td>{'predicted_sql': 'SELECT \n",
       "    (SELECT COUNT(*...</td>\n",
       "      <td>{'predicted_sql': 'SELECT \n",
       "    (SELECT COUNT(D...</td>\n",
       "      <td>{'predicted_sql': 'SELECT \n",
       "  (SELECT COUNT(Cus...</td>\n",
       "      <td>{'predicted_sql': 'SELECT\n",
       "    CAST(SUM(CASE WH...</td>\n",
       "      <td>{'predicted_sql': 'SELECT \n",
       "    /* Count of cus...</td>\n",
       "      <td>{'predicted_sql': 'SELECT \n",
       "    (SUM(CASE WHEN ...</td>\n",
       "      <td>{'predicted_sql': 'SELECT\n",
       "    SUM(CASE WHEN Cu...</td>\n",
       "      <td>{'predicted_sql': 'SELECT \n",
       "    (CAST(COUNT(CAS...</td>\n",
       "      <td>{'predicted_sql': 'SELECT \n",
       "    SUM(CASE WHEN C...</td>\n",
       "      <td>{'predicted_sql': 'SELECT 1.0 * SUM(CASE WHEN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1473</td>\n",
       "      <td>[SELECT AVG(T2.Consumption) / 12 FROM customer...</td>\n",
       "      <td>{'predicted_sql': 'SELECT AVG(T2.Consumption) ...</td>\n",
       "      <td>{'predicted_sql': 'SELECT AVG(Consumption) / 1...</td>\n",
       "      <td>{'predicted_sql': 'SELECT AVG(Consumption) \n",
       "FR...</td>\n",
       "      <td>{'predicted_sql': 'SELECT AVG(ym.Consumption) ...</td>\n",
       "      <td>{'predicted_sql': '-- Average monthly consumpt...</td>\n",
       "      <td>{'predicted_sql': 'SELECT AVG(month_total) AS ...</td>\n",
       "      <td>{'predicted_sql': 'SELECT AVG(ym.Consumption) ...</td>\n",
       "      <td>{'predicted_sql': 'SELECT AVG(ym.Consumption) ...</td>\n",
       "      <td>{'predicted_sql': 'SELECT AVG(ym.Consumption) ...</td>\n",
       "      <td>{'predicted_sql': 'SELECT AVG(ym.Consumption) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1484</td>\n",
       "      <td>[SELECT SUM(IIF(Country = 'CZE', 1, 0)) - SUM(...</td>\n",
       "      <td>{'predicted_sql': 'SELECT \n",
       "    (SELECT COUNT(*...</td>\n",
       "      <td>{'predicted_sql': 'SELECT\n",
       "    SUM(CASE WHEN Co...</td>\n",
       "      <td>{'predicted_sql': 'SELECT \n",
       "  (SELECT COUNT(Gas...</td>\n",
       "      <td>{'predicted_sql': 'SELECT \n",
       "    (SELECT COUNT(*...</td>\n",
       "      <td>{'predicted_sql': 'SELECT \n",
       "    (SELECT COUNT(*...</td>\n",
       "      <td>{'predicted_sql': 'SELECT \n",
       "    (SELECT COUNT(*...</td>\n",
       "      <td>{'predicted_sql': 'SELECT\n",
       "    (SELECT COUNT(*)...</td>\n",
       "      <td>{'predicted_sql': 'SELECT\n",
       "    (SELECT COUNT(*)...</td>\n",
       "      <td>{'predicted_sql': 'SELECT (\n",
       "        SELECT COU...</td>\n",
       "      <td>{'predicted_sql': 'SELECT (\n",
       "  SELECT COUNT(*) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1480</td>\n",
       "      <td>[SELECT SUBSTR(T2.Date, 5, 2) FROM customers A...</td>\n",
       "      <td>{'predicted_sql': 'SELECT Date \n",
       "FROM yearmonth...</td>\n",
       "      <td>{'predicted_sql': 'SELECT \n",
       "    substr(Date, 5,...</td>\n",
       "      <td>{'predicted_sql': 'SELECT Date \n",
       "FROM yearmonth...</td>\n",
       "      <td>{'predicted_sql': 'SELECT ym.Date\n",
       "FROM yearmon...</td>\n",
       "      <td>{'predicted_sql': 'SELECT \n",
       "    ym.Date AS Year...</td>\n",
       "      <td>{'predicted_sql': 'SELECT\n",
       "    ym.Date AS Month...</td>\n",
       "      <td>{'predicted_sql': 'SELECT y.Date AS Month, SUM...</td>\n",
       "      <td>{'predicted_sql': 'SELECT\n",
       "    ym.Date AS PeakM...</td>\n",
       "      <td>{'predicted_sql': 'SELECT ym.Date AS month, SU...</td>\n",
       "      <td>{'predicted_sql': 'SELECT SUBSTR(ym.Date, 5, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                                sql  \\\n",
       "0  1483  [SELECT SUM(Consumption) FROM yearmonth WHERE ...   \n",
       "1  1471  [SELECT CAST(SUM(IIF(Currency = 'EUR', 1, 0)) ...   \n",
       "2  1473  [SELECT AVG(T2.Consumption) / 12 FROM customer...   \n",
       "3  1484  [SELECT SUM(IIF(Country = 'CZE', 1, 0)) - SUM(...   \n",
       "4  1480  [SELECT SUBSTR(T2.Date, 5, 2) FROM customers A...   \n",
       "\n",
       "  wxai:meta-llama/llama-3-3-70b-instruct-greedy-zero-shot-chatapi  \\\n",
       "0  {'predicted_sql': 'SELECT SUM(Consumption) \n",
       "FR...                \n",
       "1  {'predicted_sql': 'SELECT \n",
       "    (SELECT COUNT(*...                \n",
       "2  {'predicted_sql': 'SELECT AVG(T2.Consumption) ...                \n",
       "3  {'predicted_sql': 'SELECT \n",
       "    (SELECT COUNT(*...                \n",
       "4  {'predicted_sql': 'SELECT Date \n",
       "FROM yearmonth...                \n",
       "\n",
       "  wxai:ibm/granite-4-h-small-greedy-zero-shot-chatapi  \\\n",
       "0  {'predicted_sql': 'SELECT SUM(Consumption) AS ...    \n",
       "1  {'predicted_sql': 'SELECT \n",
       "    (SELECT COUNT(D...    \n",
       "2  {'predicted_sql': 'SELECT AVG(Consumption) / 1...    \n",
       "3  {'predicted_sql': 'SELECT\n",
       "    SUM(CASE WHEN Co...    \n",
       "4  {'predicted_sql': 'SELECT \n",
       "    substr(Date, 5,...    \n",
       "\n",
       "  wxai:meta-llama/llama-4-maverick-17b-128e-instruct-fp8-greedy-zero-shot-chatapi  \\\n",
       "0  {'predicted_sql': 'SELECT SUM(Consumption) \n",
       "FR...                                \n",
       "1  {'predicted_sql': 'SELECT \n",
       "  (SELECT COUNT(Cus...                                \n",
       "2  {'predicted_sql': 'SELECT AVG(Consumption) \n",
       "FR...                                \n",
       "3  {'predicted_sql': 'SELECT \n",
       "  (SELECT COUNT(Gas...                                \n",
       "4  {'predicted_sql': 'SELECT Date \n",
       "FROM yearmonth...                                \n",
       "\n",
       "   wxai:openai/gpt-oss-120b-greedy-zero-shot-chatapi  \\\n",
       "0  {'predicted_sql': 'SELECT SUM(Consumption) AS ...   \n",
       "1  {'predicted_sql': 'SELECT\n",
       "    CAST(SUM(CASE WH...   \n",
       "2  {'predicted_sql': 'SELECT AVG(ym.Consumption) ...   \n",
       "3  {'predicted_sql': 'SELECT \n",
       "    (SELECT COUNT(*...   \n",
       "4  {'predicted_sql': 'SELECT ym.Date\n",
       "FROM yearmon...   \n",
       "\n",
       "  wxai:openai/gpt-oss-120b-agentic-baseline0-3attempts  \\\n",
       "0  {'predicted_sql': 'SELECT \n",
       "    SUM(Consumption...     \n",
       "1  {'predicted_sql': 'SELECT \n",
       "    /* Count of cus...     \n",
       "2  {'predicted_sql': '-- Average monthly consumpt...     \n",
       "3  {'predicted_sql': 'SELECT \n",
       "    (SELECT COUNT(*...     \n",
       "4  {'predicted_sql': 'SELECT \n",
       "    ym.Date AS Year...     \n",
       "\n",
       "  wxai:openai/gpt-oss-120b-agentic-baseline1-3attempts  \\\n",
       "0  {'predicted_sql': 'SELECT SUM(Consumption) AS ...     \n",
       "1  {'predicted_sql': 'SELECT \n",
       "    (SUM(CASE WHEN ...     \n",
       "2  {'predicted_sql': 'SELECT AVG(month_total) AS ...     \n",
       "3  {'predicted_sql': 'SELECT \n",
       "    (SELECT COUNT(*...     \n",
       "4  {'predicted_sql': 'SELECT\n",
       "    ym.Date AS Month...     \n",
       "\n",
       "  wxai:openai/gpt-oss-120b-agentic-baseline2-3attempts  \\\n",
       "0  {'predicted_sql': 'SELECT SUM(Consumption) AS ...     \n",
       "1  {'predicted_sql': 'SELECT\n",
       "    SUM(CASE WHEN Cu...     \n",
       "2  {'predicted_sql': 'SELECT AVG(ym.Consumption) ...     \n",
       "3  {'predicted_sql': 'SELECT\n",
       "    (SELECT COUNT(*)...     \n",
       "4  {'predicted_sql': 'SELECT y.Date AS Month, SUM...     \n",
       "\n",
       "  wxai:openai/gpt-oss-120b-agentic-baseline3-3attempts  \\\n",
       "0  {'predicted_sql': 'SELECT SUM(Consumption) AS ...     \n",
       "1  {'predicted_sql': 'SELECT \n",
       "    (CAST(COUNT(CAS...     \n",
       "2  {'predicted_sql': 'SELECT AVG(ym.Consumption) ...     \n",
       "3  {'predicted_sql': 'SELECT\n",
       "    (SELECT COUNT(*)...     \n",
       "4  {'predicted_sql': 'SELECT\n",
       "    ym.Date AS PeakM...     \n",
       "\n",
       "  wxai:openai/gpt-oss-120b-agentic-baseline4-3attempts  \\\n",
       "0  {'predicted_sql': 'SELECT SUM(Consumption) AS ...     \n",
       "1  {'predicted_sql': 'SELECT \n",
       "    SUM(CASE WHEN C...     \n",
       "2  {'predicted_sql': 'SELECT AVG(ym.Consumption) ...     \n",
       "3  {'predicted_sql': 'SELECT (\n",
       "        SELECT COU...     \n",
       "4  {'predicted_sql': 'SELECT ym.Date AS month, SU...     \n",
       "\n",
       "  wxai:openai/gpt-oss-120b-agentic-baseline5-3attempts  \n",
       "0  {'predicted_sql': 'SELECT SUM(Consumption) AS ...    \n",
       "1  {'predicted_sql': 'SELECT 1.0 * SUM(CASE WHEN ...    \n",
       "2  {'predicted_sql': 'SELECT AVG(ym.Consumption) ...    \n",
       "3  {'predicted_sql': 'SELECT (\n",
       "  SELECT COUNT(*) ...    \n",
       "4  {'predicted_sql': 'SELECT SUBSTR(ym.Date, 5, 2...    "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run your model or load precomputed predictions\n",
    "# If you're using a model API or local inference, replace this with your own logic\n",
    "import pandas as pd\n",
    "from text2sql_eval_toolkit.inference.baseline_llm_pipeline import (\n",
    "    LLMSQLGenerationPipeline,\n",
    ")\n",
    "\n",
    "# Pipeline run is async, so we need nest_asyncio to run in a notebook\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "benchmark_id = \"bird_mini_dev_sqlite_test_50\"\n",
    "\n",
    "model_parameters = {\n",
    "    \"decoding_method\": \"greedy\",\n",
    "    \"max_new_tokens\": 256,\n",
    "    \"stop_sequences\": [\"```\"],\n",
    "}\n",
    "\n",
    "model_names = [\n",
    "    \"wxai:meta-llama/llama-3-3-70b-instruct\",\n",
    "    # \"wxai:ibm/granite-3-3-8b-instruct\",\n",
    "    # \"wxai:meta-llama/llama-4-maverick-17b-128e-instruct-fp8\"\n",
    "]\n",
    "\n",
    "pipeline = LLMSQLGenerationPipeline()\n",
    "\n",
    "# for model in model_names:\n",
    "#     pipeline.run_pipeline(\n",
    "#         benchmark_id, model_name=model, model_parameters=model_parameters\n",
    "#     )\n",
    "\n",
    "predictions_file = (\n",
    "    benchmarks_json_file.parent / benchmarks_info[benchmark_id][\"predictions\"]\n",
    ")\n",
    "predictions = json.load(open(predictions_file, \"r\"))\n",
    "\n",
    "# Gather all the pipeline IDs (name of model + -greedy-zero-shot for our baseline)\n",
    "pipeline_ids = list(\n",
    "    set().union(\n",
    "        *(\n",
    "            r[\"predictions\"].keys()\n",
    "            for r in predictions\n",
    "            if \"predictions\" in r and isinstance(r[\"predictions\"], dict)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(f\"Pipelines with inference results: {pipeline_ids}\")\n",
    "\n",
    "# Optional: Display a few predictions for the selected models\n",
    "df = pd.DataFrame(predictions)[[\"id\", \"sql\", \"predictions\"]].head()\n",
    "expanded = df[\"predictions\"].apply(pd.Series)\n",
    "df_expanded = pd.concat([df.drop(columns=[\"predictions\"]), expanded], axis=1)\n",
    "df_expanded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68df574a",
   "metadata": {},
   "source": [
    "# 3. Execution: Getting the DFs for the gt and predicted SQLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abb58f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions and df for pipeline: wxai:openai/gpt-oss-120b-agentic-baseline2-3attempts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sql</th>\n",
       "      <th>gt_df</th>\n",
       "      <th>predicted_sql</th>\n",
       "      <th>predicted_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1483</td>\n",
       "      <td>[SELECT SUM(Consumption) FROM yearmonth WHERE ...</td>\n",
       "      <td>{\"columns\":[\"SUM(Consumption)\"],\"index\":[0],\"d...</td>\n",
       "      <td>SELECT SUM(Consumption) AS total_consumption\\n...</td>\n",
       "      <td>{\"columns\":[\"total_consumption\"],\"index\":[0],\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1471</td>\n",
       "      <td>[SELECT CAST(SUM(IIF(Currency = 'EUR', 1, 0)) ...</td>\n",
       "      <td>{\"columns\":[\"ratio\"],\"index\":[0],\"data\":[[0.06...</td>\n",
       "      <td>SELECT\\n    SUM(CASE WHEN Currency = 'EUR' THE...</td>\n",
       "      <td>{\"columns\":[\"eur_to_czk_ratio\"],\"index\":[0],\"d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1473</td>\n",
       "      <td>[SELECT AVG(T2.Consumption) / 12 FROM customer...</td>\n",
       "      <td>{\"columns\":[\"AVG(T2.Consumption) \\/ 12\"],\"inde...</td>\n",
       "      <td>SELECT AVG(ym.Consumption) AS avg_monthly_cons...</td>\n",
       "      <td>{\"columns\":[\"avg_monthly_consumption\"],\"index\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1484</td>\n",
       "      <td>[SELECT SUM(IIF(Country = 'CZE', 1, 0)) - SUM(...</td>\n",
       "      <td>{\"columns\":[\"SUM(IIF(Country = 'CZE', 1, 0)) -...</td>\n",
       "      <td>SELECT\\n    (SELECT COUNT(*) FROM gasstations ...</td>\n",
       "      <td>{\"columns\":[\"discount_gasstation_difference\"],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1480</td>\n",
       "      <td>[SELECT SUBSTR(T2.Date, 5, 2) FROM customers A...</td>\n",
       "      <td>{\"columns\":[\"SUBSTR(T2.Date, 5, 2)\"],\"index\":[...</td>\n",
       "      <td>SELECT y.Date AS Month, SUM(y.Consumption) AS ...</td>\n",
       "      <td>{\"columns\":[\"Month\",\"TotalConsumption\"],\"index...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                                sql  \\\n",
       "0  1483  [SELECT SUM(Consumption) FROM yearmonth WHERE ...   \n",
       "1  1471  [SELECT CAST(SUM(IIF(Currency = 'EUR', 1, 0)) ...   \n",
       "2  1473  [SELECT AVG(T2.Consumption) / 12 FROM customer...   \n",
       "3  1484  [SELECT SUM(IIF(Country = 'CZE', 1, 0)) - SUM(...   \n",
       "4  1480  [SELECT SUBSTR(T2.Date, 5, 2) FROM customers A...   \n",
       "\n",
       "                                               gt_df  \\\n",
       "0  {\"columns\":[\"SUM(Consumption)\"],\"index\":[0],\"d...   \n",
       "1  {\"columns\":[\"ratio\"],\"index\":[0],\"data\":[[0.06...   \n",
       "2  {\"columns\":[\"AVG(T2.Consumption) \\/ 12\"],\"inde...   \n",
       "3  {\"columns\":[\"SUM(IIF(Country = 'CZE', 1, 0)) -...   \n",
       "4  {\"columns\":[\"SUBSTR(T2.Date, 5, 2)\"],\"index\":[...   \n",
       "\n",
       "                                       predicted_sql  \\\n",
       "0  SELECT SUM(Consumption) AS total_consumption\\n...   \n",
       "1  SELECT\\n    SUM(CASE WHEN Currency = 'EUR' THE...   \n",
       "2  SELECT AVG(ym.Consumption) AS avg_monthly_cons...   \n",
       "3  SELECT\\n    (SELECT COUNT(*) FROM gasstations ...   \n",
       "4  SELECT y.Date AS Month, SUM(y.Consumption) AS ...   \n",
       "\n",
       "                                        predicted_df  \n",
       "0  {\"columns\":[\"total_consumption\"],\"index\":[0],\"...  \n",
       "1  {\"columns\":[\"eur_to_czk_ratio\"],\"index\":[0],\"d...  \n",
       "2  {\"columns\":[\"avg_monthly_consumption\"],\"index\"...  \n",
       "3  {\"columns\":[\"discount_gasstation_difference\"],...  \n",
       "4  {\"columns\":[\"Month\",\"TotalConsumption\"],\"index...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Execute gt and predicted SQLs and store them in the predictions file\n",
    "from text2sql_eval_toolkit.execution.execution_tools import run_execution\n",
    "\n",
    "# run_execution(benchmark_id)\n",
    "\n",
    "predictions_file = (\n",
    "    benchmarks_json_file.parent / benchmarks_info[benchmark_id][\"predictions\"]\n",
    ")\n",
    "predictions = json.load(open(predictions_file, \"r\"))\n",
    "\n",
    "# Optional: Display a few predictions for the selected models\n",
    "df = pd.DataFrame(predictions)[[\"id\", \"sql\", \"gt_df\", \"predictions\"]].head()\n",
    "expanded = df[\"predictions\"].apply(pd.Series)\n",
    "df_expanded = pd.concat([df.drop(columns=[\"predictions\"]), expanded], axis=1)\n",
    "\n",
    "pipeline_id = pipeline_ids[0]\n",
    "expanded = df_expanded[pipeline_id].apply(pd.Series)\n",
    "df_expanded = pd.concat([df_expanded.drop(columns=[pipeline_id]), expanded], axis=1)\n",
    "cols = [\"id\", \"sql\", \"gt_df\", \"predicted_sql\", \"predicted_df\"]\n",
    "print(f\"Predictions and df for pipeline: {pipeline_id}\")\n",
    "df_expanded[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521fe46b",
   "metadata": {},
   "source": [
    "# 4. Evaluation: Getting accuracy metrics on the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc2069f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):   1%|          | 6/500 [00:00<00:15, 31.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):   3%|‚ñé         | 16/500 [00:00<00:08, 59.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):   6%|‚ñå         | 28/500 [00:00<00:05, 80.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):   9%|‚ñâ         | 44/500 [00:00<00:06, 74.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):   9%|‚ñâ         | 44/500 [00:00<00:06, 74.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:56 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  12%|‚ñà‚ñè        | 60/500 [00:00<00:06, 69.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  12%|‚ñà‚ñè        | 60/500 [00:00<00:06, 69.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  14%|‚ñà‚ñç        | 69/500 [00:01<00:05, 72.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  15%|‚ñà‚ñå        | 77/500 [00:01<00:06, 69.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  19%|‚ñà‚ñä        | 93/500 [00:01<00:05, 73.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  20%|‚ñà‚ñà        | 102/500 [00:01<00:05, 77.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  24%|‚ñà‚ñà‚ñç       | 120/500 [00:01<00:04, 82.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  26%|‚ñà‚ñà‚ñå       | 129/500 [00:01<00:05, 73.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:57 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  27%|‚ñà‚ñà‚ñã       | 137/500 [00:01<00:04, 74.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  29%|‚ñà‚ñà‚ñâ       | 145/500 [00:02<00:04, 72.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  29%|‚ñà‚ñà‚ñâ       | 145/500 [00:02<00:04, 72.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  31%|‚ñà‚ñà‚ñà       | 153/500 [00:02<00:05, 62.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  32%|‚ñà‚ñà‚ñà‚ñè      | 161/500 [00:02<00:05, 65.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  34%|‚ñà‚ñà‚ñà‚ñç      | 170/500 [00:02<00:04, 69.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  36%|‚ñà‚ñà‚ñà‚ñå      | 179/500 [00:02<00:04, 71.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:58 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 213/500 [00:03<00:04, 71.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 213/500 [00:03<00:04, 71.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 221/500 [00:03<00:04, 62.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 229/500 [00:03<00:04, 62.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 236/500 [00:03<00:05, 46.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 242/500 [00:03<00:05, 46.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:25:59 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 252/500 [00:03<00:04, 57.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 276/500 [00:04<00:03, 64.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 285/500 [00:04<00:03, 65.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 292/500 [00:04<00:03, 65.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 304/500 [00:04<00:02, 79.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 313/500 [00:04<00:02, 78.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 322/500 [00:04<00:02, 81.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:00 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 331/500 [00:04<00:02, 72.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 348/500 [00:05<00:02, 74.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 356/500 [00:05<00:02, 67.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:01 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 401/500 [00:05<00:01, 86.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 412/500 [00:05<00:00, 90.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 422/500 [00:06<00:00, 85.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 431/500 [00:06<00:00, 81.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 451/500 [00:06<00:00, 78.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 451/500 [00:06<00:00, 78.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 460/500 [00:06<00:00, 67.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16):  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 475/500 [00:06<00:00, 66.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:02 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (concurrency limit: 16): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:07<00:00, 70.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 0.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - Reusing cached LLM judge results (score: 1.0)\n",
      "16:26:03 - INFO - \n",
      "Summary written to: /Users/oktie/code/text2sql/text2sql-eval-toolkit/data/benchmarks/test_benchmarks/results/bird_mini_dev_sqlite_test_50-predictions_eval_summary.csv\n",
      "\n",
      "=== Evaluation Summary ===\n",
      "\n",
      ": wxai:meta-llama/llama-3-3-70b-instruct-greedy-zero-shot-chatapi\n",
      "  Total Records       : 50\n",
      "  Successfully Evaluated: 50\n",
      "  Number of Correct Non-Empty Data Frames: 31\n",
      "  Number of Correct Subset/Superset Non-Empty Data Frames: 32\n",
      "  Number of Correct Results According to LLM Judge: 48\n",
      "  Number of LLM Judge errors: 0\n",
      "  Evaluation Errors              : 0\n",
      "  Dataframe Errors              : 1\n",
      "  Token Usage Metrics:\n",
      "    Total Tokens                 : 81,126\n",
      "    Avg Tokens per Question      : 1622.52\n",
      "    Total Prompt Tokens          : 77,454\n",
      "    Total Completion Tokens      : 3,672\n",
      "  Performance Metrics:\n",
      "    Total Inference Time         : 238,729.15 ms\n",
      "    Avg Inference Time per Query : 4774.58 ms\n",
      "    Total Execution Time         : 2,295.07 ms\n",
      "    Avg Execution Time per Query : 45.90 ms\n",
      "  execution_accuracy             Avg: 0.6200  StdDev: 0.4903\n",
      "  non_empty_execution_accuracy   Avg: 0.6200  StdDev: 0.4903\n",
      "  subset_non_empty_execution_accuracy Avg: 0.6400  StdDev: 0.4849\n",
      "  logic_execution_accuracy       Avg: 0.6600  StdDev: 0.4785\n",
      "  bird_execution_accuracy        Avg: 0.6600  StdDev: 0.4785\n",
      "  is_sqlglot_parsable            Avg: 0.9800  StdDev: 0.1414\n",
      "  is_sqlparse_parsable           Avg: 1.0000  StdDev: 0.0000\n",
      "  sqlglot_equivalence            Avg: 0.2200  StdDev: 0.4185\n",
      "  sqlglot_optimized_equivalence  Avg: 0.2200  StdDev: 0.4185\n",
      "  sqlparse_equivalence           Avg: 0.0200  StdDev: 0.1414\n",
      "  sql_exact_match                Avg: 0.1600  StdDev: 0.3703\n",
      "  sql_syntactic_equivalence      Avg: 0.2400  StdDev: 0.4314\n",
      "  eval_error                     Avg: 0.0000  StdDev: 0.0000\n",
      "  df_error                       Avg: 0.0200  StdDev: 0.1414\n",
      "  prompt_tokens                  Avg: 1549.0800  StdDev: 713.2577\n",
      "  completion_tokens              Avg: 73.4400  StdDev: 47.9405\n",
      "  total_tokens                   Avg: 1622.5200  StdDev: 706.0793\n",
      "  llm_score                      Avg: 0.9600  StdDev: 0.1979\n",
      "\n",
      ": wxai:ibm/granite-4-h-small-greedy-zero-shot-chatapi\n",
      "  Total Records       : 50\n",
      "  Successfully Evaluated: 50\n",
      "  Number of Correct Non-Empty Data Frames: 28\n",
      "  Number of Correct Subset/Superset Non-Empty Data Frames: 29\n",
      "  Number of Correct Results According to LLM Judge: 37\n",
      "  Number of LLM Judge errors: 0\n",
      "  Evaluation Errors              : 0\n",
      "  Dataframe Errors              : 4\n",
      "  Token Usage Metrics:\n",
      "    Total Tokens                 : 80,121\n",
      "    Avg Tokens per Question      : 1602.42\n",
      "    Total Prompt Tokens          : 76,354\n",
      "    Total Completion Tokens      : 3,767\n",
      "  Performance Metrics:\n",
      "    Total Inference Time         : 198,817.26 ms\n",
      "    Avg Inference Time per Query : 3976.35 ms\n",
      "    Total Execution Time         : 1,945.93 ms\n",
      "    Avg Execution Time per Query : 38.92 ms\n",
      "  execution_accuracy             Avg: 0.5600  StdDev: 0.5014\n",
      "  non_empty_execution_accuracy   Avg: 0.5600  StdDev: 0.5014\n",
      "  subset_non_empty_execution_accuracy Avg: 0.5800  StdDev: 0.4986\n",
      "  logic_execution_accuracy       Avg: 0.5800  StdDev: 0.4986\n",
      "  bird_execution_accuracy        Avg: 0.5800  StdDev: 0.4986\n",
      "  is_sqlglot_parsable            Avg: 0.9800  StdDev: 0.1414\n",
      "  is_sqlparse_parsable           Avg: 1.0000  StdDev: 0.0000\n",
      "  sqlglot_equivalence            Avg: 0.1000  StdDev: 0.3030\n",
      "  sqlglot_optimized_equivalence  Avg: 0.0400  StdDev: 0.1979\n",
      "  sqlparse_equivalence           Avg: 0.0000  StdDev: 0.0000\n",
      "  sql_exact_match                Avg: 0.0400  StdDev: 0.1979\n",
      "  sql_syntactic_equivalence      Avg: 0.1000  StdDev: 0.3030\n",
      "  eval_error                     Avg: 0.0000  StdDev: 0.0000\n",
      "  df_error                       Avg: 0.0800  StdDev: 0.2740\n",
      "  prompt_tokens                  Avg: 1527.0800  StdDev: 713.2577\n",
      "  completion_tokens              Avg: 75.3400  StdDev: 67.2955\n",
      "  total_tokens                   Avg: 1602.4200  StdDev: 700.3520\n",
      "  llm_score                      Avg: 0.7400  StdDev: 0.4431\n",
      "\n",
      ": wxai:meta-llama/llama-4-maverick-17b-128e-instruct-fp8-greedy-zero-shot-chatapi\n",
      "  Total Records       : 50\n",
      "  Successfully Evaluated: 50\n",
      "  Number of Correct Non-Empty Data Frames: 31\n",
      "  Number of Correct Subset/Superset Non-Empty Data Frames: 33\n",
      "  Number of Correct Results According to LLM Judge: 46\n",
      "  Number of LLM Judge errors: 0\n",
      "  Evaluation Errors              : 0\n",
      "  Dataframe Errors              : 1\n",
      "  Token Usage Metrics:\n",
      "    Total Tokens                 : 80,365\n",
      "    Avg Tokens per Question      : 1607.30\n",
      "    Total Prompt Tokens          : 75,469\n",
      "    Total Completion Tokens      : 4,896\n",
      "  Performance Metrics:\n",
      "    Total Inference Time         : 111,471.25 ms\n",
      "    Avg Inference Time per Query : 2229.43 ms\n",
      "    Total Execution Time         : 2,505.46 ms\n",
      "    Avg Execution Time per Query : 50.11 ms\n",
      "  execution_accuracy             Avg: 0.6200  StdDev: 0.4903\n",
      "  non_empty_execution_accuracy   Avg: 0.6200  StdDev: 0.4903\n",
      "  subset_non_empty_execution_accuracy Avg: 0.6600  StdDev: 0.4785\n",
      "  logic_execution_accuracy       Avg: 0.6800  StdDev: 0.4712\n",
      "  bird_execution_accuracy        Avg: 0.6400  StdDev: 0.4849\n",
      "  is_sqlglot_parsable            Avg: 1.0000  StdDev: 0.0000\n",
      "  is_sqlparse_parsable           Avg: 1.0000  StdDev: 0.0000\n",
      "  sqlglot_equivalence            Avg: 0.2000  StdDev: 0.4041\n",
      "  sqlglot_optimized_equivalence  Avg: 0.2200  StdDev: 0.4185\n",
      "  sqlparse_equivalence           Avg: 0.0000  StdDev: 0.0000\n",
      "  sql_exact_match                Avg: 0.1800  StdDev: 0.3881\n",
      "  sql_syntactic_equivalence      Avg: 0.2200  StdDev: 0.4185\n",
      "  eval_error                     Avg: 0.0000  StdDev: 0.0000\n",
      "  df_error                       Avg: 0.0200  StdDev: 0.1414\n",
      "  prompt_tokens                  Avg: 1509.3800  StdDev: 692.2689\n",
      "  completion_tokens              Avg: 97.9200  StdDev: 97.6399\n",
      "  total_tokens                   Avg: 1607.3000  StdDev: 675.0479\n",
      "  llm_score                      Avg: 0.9200  StdDev: 0.2740\n",
      "\n",
      ": wxai:openai/gpt-oss-120b-greedy-zero-shot-chatapi\n",
      "  Total Records       : 50\n",
      "  Successfully Evaluated: 50\n",
      "  Number of Correct Non-Empty Data Frames: 28\n",
      "  Number of Correct Subset/Superset Non-Empty Data Frames: 30\n",
      "  Number of Correct Results According to LLM Judge: 47\n",
      "  Number of LLM Judge errors: 0\n",
      "  Evaluation Errors              : 0\n",
      "  Dataframe Errors              : 2\n",
      "  Token Usage Metrics:\n",
      "    Total Tokens                 : 94,770\n",
      "    Avg Tokens per Question      : 1895.40\n",
      "    Total Prompt Tokens          : 78,484\n",
      "    Total Completion Tokens      : 16,286\n",
      "  Performance Metrics:\n",
      "    Total Inference Time         : 190,011.67 ms\n",
      "    Avg Inference Time per Query : 3800.23 ms\n",
      "    Total Execution Time         : 1,555.95 ms\n",
      "    Avg Execution Time per Query : 31.12 ms\n",
      "  execution_accuracy             Avg: 0.5600  StdDev: 0.5014\n",
      "  non_empty_execution_accuracy   Avg: 0.5600  StdDev: 0.5014\n",
      "  subset_non_empty_execution_accuracy Avg: 0.6000  StdDev: 0.4949\n",
      "  logic_execution_accuracy       Avg: 0.6400  StdDev: 0.4849\n",
      "  bird_execution_accuracy        Avg: 0.5800  StdDev: 0.4986\n",
      "  is_sqlglot_parsable            Avg: 0.9600  StdDev: 0.1979\n",
      "  is_sqlparse_parsable           Avg: 1.0000  StdDev: 0.0000\n",
      "  sqlglot_equivalence            Avg: 0.0800  StdDev: 0.2740\n",
      "  sqlglot_optimized_equivalence  Avg: 0.0400  StdDev: 0.1979\n",
      "  sqlparse_equivalence           Avg: 0.0000  StdDev: 0.0000\n",
      "  sql_exact_match                Avg: 0.0400  StdDev: 0.1979\n",
      "  sql_syntactic_equivalence      Avg: 0.0800  StdDev: 0.2740\n",
      "  eval_error                     Avg: 0.0000  StdDev: 0.0000\n",
      "  df_error                       Avg: 0.0400  StdDev: 0.1979\n",
      "  prompt_tokens                  Avg: 1569.6800  StdDev: 693.3531\n",
      "  completion_tokens              Avg: 325.7200  StdDev: 199.7744\n",
      "  total_tokens                   Avg: 1895.4000  StdDev: 684.8560\n",
      "  llm_score                      Avg: 0.9400  StdDev: 0.2399\n",
      "\n",
      ": wxai:openai/gpt-oss-120b-agentic-baseline0-3attempts\n",
      "  Total Records       : 50\n",
      "  Successfully Evaluated: 50\n",
      "  Number of Correct Non-Empty Data Frames: 20\n",
      "  Number of Correct Subset/Superset Non-Empty Data Frames: 25\n",
      "  Number of Correct Results According to LLM Judge: 44\n",
      "  Number of LLM Judge errors: 0\n",
      "  Evaluation Errors              : 0\n",
      "  Dataframe Errors              : 1\n",
      "  Token Usage Metrics:\n",
      "    Total Tokens                 : 119,077\n",
      "    Avg Tokens per Question      : 2381.54\n",
      "    Total Prompt Tokens          : 92,574\n",
      "    Total Completion Tokens      : 26,503\n",
      "  Performance Metrics:\n",
      "    Total Inference Time         : 262,836.03 ms\n",
      "    Avg Inference Time per Query : 5256.72 ms\n",
      "  execution_accuracy             Avg: 0.4000  StdDev: 0.4949\n",
      "  non_empty_execution_accuracy   Avg: 0.4000  StdDev: 0.4949\n",
      "  subset_non_empty_execution_accuracy Avg: 0.5000  StdDev: 0.5051\n",
      "  logic_execution_accuracy       Avg: 0.5400  StdDev: 0.5035\n",
      "  bird_execution_accuracy        Avg: 0.4000  StdDev: 0.4949\n",
      "  is_sqlglot_parsable            Avg: 0.9800  StdDev: 0.1414\n",
      "  is_sqlparse_parsable           Avg: 1.0000  StdDev: 0.0000\n",
      "  sqlglot_equivalence            Avg: 0.0600  StdDev: 0.2399\n",
      "  sqlglot_optimized_equivalence  Avg: 0.0400  StdDev: 0.1979\n",
      "  sqlparse_equivalence           Avg: 0.0000  StdDev: 0.0000\n",
      "  sql_exact_match                Avg: 0.0400  StdDev: 0.1979\n",
      "  sql_syntactic_equivalence      Avg: 0.0600  StdDev: 0.2399\n",
      "  eval_error                     Avg: 0.0000  StdDev: 0.0000\n",
      "  df_error                       Avg: 0.0200  StdDev: 0.1414\n",
      "  prompt_tokens                  Avg: 1851.4800  StdDev: 1179.5140\n",
      "  completion_tokens              Avg: 530.0600  StdDev: 598.9165\n",
      "  total_tokens                   Avg: 2381.5400  StdDev: 1563.9125\n",
      "  llm_score                      Avg: 0.8800  StdDev: 0.3283\n",
      "\n",
      ": wxai:openai/gpt-oss-120b-agentic-baseline1-3attempts\n",
      "  Total Records       : 50\n",
      "  Successfully Evaluated: 50\n",
      "  Number of Correct Non-Empty Data Frames: 27\n",
      "  Number of Correct Subset/Superset Non-Empty Data Frames: 27\n",
      "  Number of Correct Results According to LLM Judge: 44\n",
      "  Number of LLM Judge errors: 0\n",
      "  Evaluation Errors              : 0\n",
      "  Dataframe Errors              : 1\n",
      "  Token Usage Metrics:\n",
      "    Total Tokens                 : 100,369\n",
      "    Avg Tokens per Question      : 2007.38\n",
      "    Total Prompt Tokens          : 81,148\n",
      "    Total Completion Tokens      : 19,221\n",
      "  Performance Metrics:\n",
      "    Total Inference Time         : 201,906.78 ms\n",
      "    Avg Inference Time per Query : 4038.14 ms\n",
      "  execution_accuracy             Avg: 0.5400  StdDev: 0.5035\n",
      "  non_empty_execution_accuracy   Avg: 0.5400  StdDev: 0.5035\n",
      "  subset_non_empty_execution_accuracy Avg: 0.5400  StdDev: 0.5035\n",
      "  logic_execution_accuracy       Avg: 0.5800  StdDev: 0.4986\n",
      "  bird_execution_accuracy        Avg: 0.5800  StdDev: 0.4986\n",
      "  is_sqlglot_parsable            Avg: 0.9800  StdDev: 0.1414\n",
      "  is_sqlparse_parsable           Avg: 1.0000  StdDev: 0.0000\n",
      "  sqlglot_equivalence            Avg: 0.0800  StdDev: 0.2740\n",
      "  sqlglot_optimized_equivalence  Avg: 0.0400  StdDev: 0.1979\n",
      "  sqlparse_equivalence           Avg: 0.0000  StdDev: 0.0000\n",
      "  sql_exact_match                Avg: 0.0400  StdDev: 0.1979\n",
      "  sql_syntactic_equivalence      Avg: 0.0800  StdDev: 0.2740\n",
      "  eval_error                     Avg: 0.0000  StdDev: 0.0000\n",
      "  df_error                       Avg: 0.0200  StdDev: 0.1414\n",
      "  prompt_tokens                  Avg: 1622.9600  StdDev: 852.0009\n",
      "  completion_tokens              Avg: 384.4200  StdDev: 432.4437\n",
      "  total_tokens                   Avg: 2007.3800  StdDev: 1047.0242\n",
      "  llm_score                      Avg: 0.8800  StdDev: 0.3283\n",
      "\n",
      ": wxai:openai/gpt-oss-120b-agentic-baseline2-3attempts\n",
      "  Total Records       : 50\n",
      "  Successfully Evaluated: 50\n",
      "  Number of Correct Non-Empty Data Frames: 27\n",
      "  Number of Correct Subset/Superset Non-Empty Data Frames: 28\n",
      "  Number of Correct Results According to LLM Judge: 44\n",
      "  Number of LLM Judge errors: 0\n",
      "  Evaluation Errors              : 0\n",
      "  Dataframe Errors              : 0\n",
      "  Token Usage Metrics:\n",
      "    Total Tokens                 : 98,607\n",
      "    Avg Tokens per Question      : 1972.14\n",
      "    Total Prompt Tokens          : 79,093\n",
      "    Total Completion Tokens      : 19,514\n",
      "  Performance Metrics:\n",
      "    Total Inference Time         : 225,459.78 ms\n",
      "    Avg Inference Time per Query : 4509.20 ms\n",
      "  execution_accuracy             Avg: 0.5400  StdDev: 0.5035\n",
      "  non_empty_execution_accuracy   Avg: 0.5400  StdDev: 0.5035\n",
      "  subset_non_empty_execution_accuracy Avg: 0.5600  StdDev: 0.5014\n",
      "  logic_execution_accuracy       Avg: 0.6000  StdDev: 0.4949\n",
      "  bird_execution_accuracy        Avg: 0.5400  StdDev: 0.5035\n",
      "  is_sqlglot_parsable            Avg: 1.0000  StdDev: 0.0000\n",
      "  is_sqlparse_parsable           Avg: 1.0000  StdDev: 0.0000\n",
      "  sqlglot_equivalence            Avg: 0.0800  StdDev: 0.2740\n",
      "  sqlglot_optimized_equivalence  Avg: 0.0400  StdDev: 0.1979\n",
      "  sqlparse_equivalence           Avg: 0.0000  StdDev: 0.0000\n",
      "  sql_exact_match                Avg: 0.0400  StdDev: 0.1979\n",
      "  sql_syntactic_equivalence      Avg: 0.0800  StdDev: 0.2740\n",
      "  eval_error                     Avg: 0.0000  StdDev: 0.0000\n",
      "  df_error                       Avg: 0.0000  StdDev: 0.0000\n",
      "  prompt_tokens                  Avg: 1581.8600  StdDev: 700.8538\n",
      "  completion_tokens              Avg: 390.2800  StdDev: 341.4247\n",
      "  total_tokens                   Avg: 1972.1400  StdDev: 824.4132\n",
      "  llm_score                      Avg: 0.8800  StdDev: 0.3283\n",
      "\n",
      ": wxai:openai/gpt-oss-120b-agentic-baseline3-3attempts\n",
      "  Total Records       : 50\n",
      "  Successfully Evaluated: 50\n",
      "  Number of Correct Non-Empty Data Frames: 0\n",
      "  Number of Correct Subset/Superset Non-Empty Data Frames: 1\n",
      "  Number of Correct Results According to LLM Judge: 3\n",
      "  Number of LLM Judge errors: 0\n",
      "  Evaluation Errors              : 0\n",
      "  Dataframe Errors              : 45\n",
      "  Token Usage Metrics:\n",
      "    Total Tokens                 : 299,717\n",
      "    Avg Tokens per Question      : 5994.34\n",
      "    Total Prompt Tokens          : 242,202\n",
      "    Total Completion Tokens      : 57,515\n",
      "  Performance Metrics:\n",
      "    Total Inference Time         : 1,737,440.72 ms\n",
      "    Avg Inference Time per Query : 34748.81 ms\n",
      "  execution_accuracy             Avg: 0.0000  StdDev: 0.0000\n",
      "  non_empty_execution_accuracy   Avg: 0.0000  StdDev: 0.0000\n",
      "  subset_non_empty_execution_accuracy Avg: 0.0200  StdDev: 0.1414\n",
      "  logic_execution_accuracy       Avg: 0.2000  StdDev: 0.4041\n",
      "  bird_execution_accuracy        Avg: 0.0000  StdDev: 0.0000\n",
      "  is_sqlglot_parsable            Avg: 1.0000  StdDev: 0.0000\n",
      "  is_sqlparse_parsable           Avg: 1.0000  StdDev: 0.0000\n",
      "  sqlglot_equivalence            Avg: 0.0600  StdDev: 0.2399\n",
      "  sqlglot_optimized_equivalence  Avg: 0.0400  StdDev: 0.1979\n",
      "  sqlparse_equivalence           Avg: 0.0000  StdDev: 0.0000\n",
      "  sql_exact_match                Avg: 0.0400  StdDev: 0.1979\n",
      "  sql_syntactic_equivalence      Avg: 0.0600  StdDev: 0.2399\n",
      "  eval_error                     Avg: 0.0000  StdDev: 0.0000\n",
      "  df_error                       Avg: 0.9000  StdDev: 0.3030\n",
      "  prompt_tokens                  Avg: 4844.0400  StdDev: 2119.1047\n",
      "  completion_tokens              Avg: 1150.3000  StdDev: 489.5573\n",
      "  total_tokens                   Avg: 5994.3400  StdDev: 2130.8894\n",
      "  llm_score                      Avg: 0.0600  StdDev: 0.2399\n",
      "\n",
      ": wxai:openai/gpt-oss-120b-agentic-baseline4-3attempts\n",
      "  Total Records       : 50\n",
      "  Successfully Evaluated: 46\n",
      "  Number of Correct Non-Empty Data Frames: 23\n",
      "  Number of Correct Subset/Superset Non-Empty Data Frames: 25\n",
      "  Number of Correct Results According to LLM Judge: 43\n",
      "  Number of LLM Judge errors: 0\n",
      "  Evaluation Errors              : 4\n",
      "  Dataframe Errors              : 5\n",
      "  Token Usage Metrics:\n",
      "    Total Tokens                 : 235,698\n",
      "    Avg Tokens per Question      : 4713.96\n",
      "    Total Prompt Tokens          : 200,787\n",
      "    Total Completion Tokens      : 34,911\n",
      "  Performance Metrics:\n",
      "    Total Inference Time         : 3,581,576.55 ms\n",
      "    Avg Inference Time per Query : 71631.53 ms\n",
      "  execution_accuracy             Avg: 0.4600  StdDev: 0.5055\n",
      "  non_empty_execution_accuracy   Avg: 0.4600  StdDev: 0.5055\n",
      "  subset_non_empty_execution_accuracy Avg: 0.5000  StdDev: 0.5036\n",
      "  logic_execution_accuracy       Avg: 0.5400  StdDev: 0.4978\n",
      "  bird_execution_accuracy        Avg: 0.4600  StdDev: 0.5055\n",
      "  is_sqlglot_parsable            Avg: 0.9200  StdDev: 0.0000\n",
      "  is_sqlparse_parsable           Avg: 0.9200  StdDev: 0.0000\n",
      "  sqlglot_equivalence            Avg: 0.0600  StdDev: 0.2496\n",
      "  sqlglot_optimized_equivalence  Avg: 0.0400  StdDev: 0.2062\n",
      "  sqlparse_equivalence           Avg: 0.0000  StdDev: 0.0000\n",
      "  sql_exact_match                Avg: 0.0400  StdDev: 0.2062\n",
      "  sql_syntactic_equivalence      Avg: 0.0600  StdDev: 0.2496\n",
      "  eval_error                     Avg: 0.0000  StdDev: 0.0000\n",
      "  df_error                       Avg: 0.0200  StdDev: 0.1474\n",
      "  prompt_tokens                  Avg: 4015.7400  StdDev: 1768.9105\n",
      "  completion_tokens              Avg: 698.2200  StdDev: 307.7106\n",
      "  total_tokens                   Avg: 4713.9600  StdDev: 1899.7283\n",
      "  llm_score                      Avg: 0.8600  StdDev: 0.2496\n",
      "\n",
      ": wxai:openai/gpt-oss-120b-agentic-baseline5-3attempts\n",
      "  Total Records       : 50\n",
      "  Successfully Evaluated: 46\n",
      "  Number of Correct Non-Empty Data Frames: 26\n",
      "  Number of Correct Subset/Superset Non-Empty Data Frames: 27\n",
      "  Number of Correct Results According to LLM Judge: 39\n",
      "  Number of LLM Judge errors: 0\n",
      "  Evaluation Errors              : 4\n",
      "  Dataframe Errors              : 6\n",
      "  Token Usage Metrics:\n",
      "    Total Tokens                 : 645,129\n",
      "    Avg Tokens per Question      : 12902.58\n",
      "    Total Prompt Tokens          : 580,628\n",
      "    Total Completion Tokens      : 64,501\n",
      "  Performance Metrics:\n",
      "    Total Inference Time         : 6,625,191.01 ms\n",
      "    Avg Inference Time per Query : 132503.82 ms\n",
      "  execution_accuracy             Avg: 0.5200  StdDev: 0.5012\n",
      "  non_empty_execution_accuracy   Avg: 0.5200  StdDev: 0.5012\n",
      "  subset_non_empty_execution_accuracy Avg: 0.5400  StdDev: 0.4978\n",
      "  logic_execution_accuracy       Avg: 0.6000  StdDev: 0.4815\n",
      "  bird_execution_accuracy        Avg: 0.5200  StdDev: 0.5012\n",
      "  is_sqlglot_parsable            Avg: 0.9200  StdDev: 0.0000\n",
      "  is_sqlparse_parsable           Avg: 0.9200  StdDev: 0.0000\n",
      "  sqlglot_equivalence            Avg: 0.0400  StdDev: 0.2062\n",
      "  sqlglot_optimized_equivalence  Avg: 0.0400  StdDev: 0.2062\n",
      "  sqlparse_equivalence           Avg: 0.0000  StdDev: 0.0000\n",
      "  sql_exact_match                Avg: 0.0400  StdDev: 0.2062\n",
      "  sql_syntactic_equivalence      Avg: 0.0400  StdDev: 0.2062\n",
      "  eval_error                     Avg: 0.0000  StdDev: 0.0000\n",
      "  df_error                       Avg: 0.0400  StdDev: 0.2062\n",
      "  prompt_tokens                  Avg: 11612.5600  StdDev: 6058.5316\n",
      "  completion_tokens              Avg: 1290.0200  StdDev: 593.9881\n",
      "  total_tokens                   Avg: 12902.5800  StdDev: 6496.6911\n",
      "  llm_score                      Avg: 0.7800  StdDev: 0.3632\n"
     ]
    }
   ],
   "source": [
    "# Running evaluation (saves the output as well)\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from text2sql_eval_toolkit.utils import get_benchmark_info\n",
    "from text2sql_eval_toolkit.evaluation.evaluation_tools import evaluate_predictions\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Need to set env variables for LLM as judge. Modify if needed:\n",
    "load_dotenv(os.path.expanduser(\"~/.env\"))\n",
    "\n",
    "for name in logging.root.manager.loggerDict:\n",
    "    logging.getLogger(name).setLevel(logging.INFO)\n",
    "\n",
    "benchmark_info = get_benchmark_info(benchmark_id)\n",
    "predictions_path = benchmark_info[\"predictions_path\"]\n",
    "pred_eval_data, summary_df = evaluate_predictions(\n",
    "    predictions_path, use_llm=True\n",
    ")  # Note: Setting use_llm to True will make the evaluation much slower due to LLM inference for the LLM judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24c3951c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Total</th>\n",
       "      <th>Evaluated</th>\n",
       "      <th>Number of Correct Non-Empty Data Frames</th>\n",
       "      <th>Number of Correct Subset/Superset Non-Empty Data Frames</th>\n",
       "      <th>Number of Correct Results According to LLM Judge</th>\n",
       "      <th>Evaluation Errors</th>\n",
       "      <th>Dataframe Errors</th>\n",
       "      <th>LLM Judge Errors</th>\n",
       "      <th>Total Tokens</th>\n",
       "      <th>...</th>\n",
       "      <th>sql_exact_match_avg</th>\n",
       "      <th>sql_syntactic_equivalence_avg</th>\n",
       "      <th>eval_error_avg</th>\n",
       "      <th>df_error_avg</th>\n",
       "      <th>prompt_tokens_avg</th>\n",
       "      <th>completion_tokens_avg</th>\n",
       "      <th>total_tokens_avg</th>\n",
       "      <th>inference_time_ms_avg</th>\n",
       "      <th>execution_time_ms_avg</th>\n",
       "      <th>llm_score_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wxai:meta-llama/llama-4-maverick-17b-128e-inst...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1509.38</td>\n",
       "      <td>97.92</td>\n",
       "      <td>1607.30</td>\n",
       "      <td>2229.4250</td>\n",
       "      <td>50.1092</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wxai:meta-llama/llama-3-3-70b-instruct-greedy-...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1549.08</td>\n",
       "      <td>73.44</td>\n",
       "      <td>1622.52</td>\n",
       "      <td>4774.5830</td>\n",
       "      <td>45.9014</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wxai:openai/gpt-oss-120b-greedy-zero-shot-chatapi</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>94770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1569.68</td>\n",
       "      <td>325.72</td>\n",
       "      <td>1895.40</td>\n",
       "      <td>3800.2334</td>\n",
       "      <td>31.1190</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wxai:ibm/granite-4-h-small-greedy-zero-shot-ch...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>80121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1527.08</td>\n",
       "      <td>75.34</td>\n",
       "      <td>1602.42</td>\n",
       "      <td>3976.3452</td>\n",
       "      <td>38.9186</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wxai:openai/gpt-oss-120b-agentic-baseline2-3at...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1581.86</td>\n",
       "      <td>390.28</td>\n",
       "      <td>1972.14</td>\n",
       "      <td>4509.1956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wxai:openai/gpt-oss-120b-agentic-baseline1-3at...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1622.96</td>\n",
       "      <td>384.42</td>\n",
       "      <td>2007.38</td>\n",
       "      <td>4038.1356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wxai:openai/gpt-oss-120b-agentic-baseline5-3at...</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>645129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>11612.56</td>\n",
       "      <td>1290.02</td>\n",
       "      <td>12902.58</td>\n",
       "      <td>132503.8202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wxai:openai/gpt-oss-120b-agentic-baseline0-3at...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1851.48</td>\n",
       "      <td>530.06</td>\n",
       "      <td>2381.54</td>\n",
       "      <td>5256.7206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wxai:openai/gpt-oss-120b-agentic-baseline4-3at...</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>235698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4015.74</td>\n",
       "      <td>698.22</td>\n",
       "      <td>4713.96</td>\n",
       "      <td>71631.5310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wxai:openai/gpt-oss-120b-agentic-baseline3-3at...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>299717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4844.04</td>\n",
       "      <td>1150.30</td>\n",
       "      <td>5994.34</td>\n",
       "      <td>34748.8144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  Total  Evaluated  \\\n",
       "2  wxai:meta-llama/llama-4-maverick-17b-128e-inst...     50         50   \n",
       "0  wxai:meta-llama/llama-3-3-70b-instruct-greedy-...     50         50   \n",
       "3  wxai:openai/gpt-oss-120b-greedy-zero-shot-chatapi     50         50   \n",
       "1  wxai:ibm/granite-4-h-small-greedy-zero-shot-ch...     50         50   \n",
       "6  wxai:openai/gpt-oss-120b-agentic-baseline2-3at...     50         50   \n",
       "5  wxai:openai/gpt-oss-120b-agentic-baseline1-3at...     50         50   \n",
       "9  wxai:openai/gpt-oss-120b-agentic-baseline5-3at...     50         46   \n",
       "4  wxai:openai/gpt-oss-120b-agentic-baseline0-3at...     50         50   \n",
       "8  wxai:openai/gpt-oss-120b-agentic-baseline4-3at...     50         46   \n",
       "7  wxai:openai/gpt-oss-120b-agentic-baseline3-3at...     50         50   \n",
       "\n",
       "   Number of Correct Non-Empty Data Frames  \\\n",
       "2                                       31   \n",
       "0                                       31   \n",
       "3                                       28   \n",
       "1                                       28   \n",
       "6                                       27   \n",
       "5                                       27   \n",
       "9                                       26   \n",
       "4                                       20   \n",
       "8                                       23   \n",
       "7                                        0   \n",
       "\n",
       "   Number of Correct Subset/Superset Non-Empty Data Frames  \\\n",
       "2                                                 33         \n",
       "0                                                 32         \n",
       "3                                                 30         \n",
       "1                                                 29         \n",
       "6                                                 28         \n",
       "5                                                 27         \n",
       "9                                                 27         \n",
       "4                                                 25         \n",
       "8                                                 25         \n",
       "7                                                  1         \n",
       "\n",
       "   Number of Correct Results According to LLM Judge  Evaluation Errors  \\\n",
       "2                                                46                  0   \n",
       "0                                                48                  0   \n",
       "3                                                47                  0   \n",
       "1                                                37                  0   \n",
       "6                                                44                  0   \n",
       "5                                                44                  0   \n",
       "9                                                39                  4   \n",
       "4                                                44                  0   \n",
       "8                                                43                  4   \n",
       "7                                                 3                  0   \n",
       "\n",
       "   Dataframe Errors  LLM Judge Errors  Total Tokens  ...  sql_exact_match_avg  \\\n",
       "2                 1                 0         80365  ...                 0.18   \n",
       "0                 1                 0         81126  ...                 0.16   \n",
       "3                 2                 0         94770  ...                 0.04   \n",
       "1                 4                 0         80121  ...                 0.04   \n",
       "6                 0                 0         98607  ...                 0.04   \n",
       "5                 1                 0        100369  ...                 0.04   \n",
       "9                 6                 0        645129  ...                 0.04   \n",
       "4                 1                 0        119077  ...                 0.04   \n",
       "8                 5                 0        235698  ...                 0.04   \n",
       "7                45                 0        299717  ...                 0.04   \n",
       "\n",
       "   sql_syntactic_equivalence_avg  eval_error_avg  df_error_avg  \\\n",
       "2                           0.22             0.0          0.02   \n",
       "0                           0.24             0.0          0.02   \n",
       "3                           0.08             0.0          0.04   \n",
       "1                           0.10             0.0          0.08   \n",
       "6                           0.08             0.0          0.00   \n",
       "5                           0.08             0.0          0.02   \n",
       "9                           0.04             0.0          0.04   \n",
       "4                           0.06             0.0          0.02   \n",
       "8                           0.06             0.0          0.02   \n",
       "7                           0.06             0.0          0.90   \n",
       "\n",
       "   prompt_tokens_avg completion_tokens_avg total_tokens_avg  \\\n",
       "2            1509.38                 97.92          1607.30   \n",
       "0            1549.08                 73.44          1622.52   \n",
       "3            1569.68                325.72          1895.40   \n",
       "1            1527.08                 75.34          1602.42   \n",
       "6            1581.86                390.28          1972.14   \n",
       "5            1622.96                384.42          2007.38   \n",
       "9           11612.56               1290.02         12902.58   \n",
       "4            1851.48                530.06          2381.54   \n",
       "8            4015.74                698.22          4713.96   \n",
       "7            4844.04               1150.30          5994.34   \n",
       "\n",
       "   inference_time_ms_avg  execution_time_ms_avg  llm_score_avg  \n",
       "2              2229.4250                50.1092           0.92  \n",
       "0              4774.5830                45.9014           0.96  \n",
       "3              3800.2334                31.1190           0.94  \n",
       "1              3976.3452                38.9186           0.74  \n",
       "6              4509.1956                    NaN           0.88  \n",
       "5              4038.1356                    NaN           0.88  \n",
       "9            132503.8202                    NaN           0.78  \n",
       "4              5256.7206                    NaN           0.88  \n",
       "8             71631.5310                    NaN           0.86  \n",
       "7             34748.8144                    NaN           0.06  \n",
       "\n",
       "[10 rows x 37 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df_filtered = summary_df.loc[:, ~summary_df.columns.str.endswith(\"std\")]\n",
    "summary_df_filtered.sort_values(\n",
    "    by=\"subset_non_empty_execution_accuracy_avg\", ascending=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4afcf7f",
   "metadata": {},
   "source": [
    "# 5. Error Analysis: Do the results make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1117e196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions: 50\n",
      "Number of evaluations: 50\n"
     ]
    }
   ],
   "source": [
    "with open(predictions_path, \"r\") as f:\n",
    "    predictions = json.load(f)\n",
    "print(f\"Number of predictions: {len(predictions)}\")\n",
    "print(f\"Number of evaluations: {len(pred_eval_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71048505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "from text2sql_eval_toolkit.utils import parse_dataframe\n",
    "\n",
    "\n",
    "def get_model_names(records):\n",
    "    return list(records[0][\"predictions\"].keys())\n",
    "\n",
    "\n",
    "def get_failed_records(records, pipeline_id, metric=\"execution_accuracy\"):\n",
    "    return [\n",
    "        r for r in records if r[\"predictions\"][pipeline_id][\"evaluation\"][metric] == 0\n",
    "    ]\n",
    "\n",
    "\n",
    "def safe_snippet(text, head=1000, tail=1000):\n",
    "    if len(text) <= head + tail:\n",
    "        return text\n",
    "    return text[:head] + \"\\n‚Ä¶\\n\" + text[-tail:]\n",
    "\n",
    "\n",
    "def show_failed_example(pipeline_id: str, failed: list[dict], example_index: int):\n",
    "    if not failed:\n",
    "        display(Markdown(f\"**No failed predictions found for model `{pipeline_id}`.**\"))\n",
    "        return\n",
    "    if example_index >= len(failed):\n",
    "        display(\n",
    "            Markdown(\n",
    "                f\"**Index {example_index} is out of range. Only {len(failed)} failed examples available.**\"\n",
    "            )\n",
    "        )\n",
    "        return\n",
    "\n",
    "    record = failed[example_index]\n",
    "    pred = record[\"predictions\"][pipeline_id]\n",
    "    \n",
    "    # Handle inference errors (when SQL generation fails)\n",
    "    if \"inference_error\" in pred:\n",
    "        clear_output(wait=True)\n",
    "        question_id = record.get(\"id\", record.get(\"_id\", f\"example_{example_index}\"))\n",
    "        utterance = (\n",
    "            record.get(\"page_content\")\n",
    "            or record.get(\"question\")\n",
    "            or record.get(\"utterance\", \"\")\n",
    "        )\n",
    "        display(\n",
    "            Markdown(\n",
    "                f\"### ‚ö†Ô∏è  Inference Failed - Question #{example_index} (of {len(failed)} examples) - Question ID: `{question_id}`\\n\\n**Question**: {utterance}\"\n",
    "            )\n",
    "        )\n",
    "        display(Markdown(\"### ‚ùå Inference Error\"))\n",
    "        display(Markdown(f\"```\\n{pred.get('inference_error', 'Unknown error')}\\n```\"))\n",
    "        \n",
    "        if pred.get('raw_response'):\n",
    "            display(Markdown(\"### üìÑ Raw Model Response\"))\n",
    "            display(Markdown(f\"```\\n{pred['raw_response']}\\n```\"))\n",
    "        \n",
    "        if pred.get('prompt'):\n",
    "            display(Markdown(\"### üìù Prompt Used\"))\n",
    "            display(Markdown(f\"```\\n{safe_snippet(pred['prompt'], head=500, tail=500)}\\n```\"))\n",
    "        return\n",
    "    \n",
    "    # Get ground truth SQL from multiple possible locations\n",
    "    gt_sqls = (\n",
    "        record.get(\"sql\")\n",
    "        or record.get(\"SQL\")\n",
    "        or record.get(\"metadata\", {}).get(\"sql\", [])\n",
    "    )\n",
    "    gt_sqls = [gt_sqls] if isinstance(gt_sqls, str) else gt_sqls\n",
    "\n",
    "    # Parse ground truth DFs\n",
    "    gt_dfs = []\n",
    "    raw_gt_dfs = record.get(\"gt_df\", [])\n",
    "    if isinstance(raw_gt_dfs, str):\n",
    "        gt_dfs = [parse_dataframe(raw_gt_dfs)]\n",
    "    else:\n",
    "        for df in record.get(\"gt_df\", []):\n",
    "            try:\n",
    "                gt_dfs.append(parse_dataframe(df))\n",
    "            except Exception as e:\n",
    "                gt_dfs.append(f\"‚ö†Ô∏è Error loading GT DF: {e}\")\n",
    "\n",
    "    pred_df = None\n",
    "    pred_df_error = None\n",
    "    if \"predicted_df\" in pred:\n",
    "        try:\n",
    "            pred_df = parse_dataframe(pred[\"predicted_df\"])\n",
    "        except Exception as e:\n",
    "            pred_df_error = f\"‚ö†Ô∏è Error loading predicted_df: {e}\"\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    utterance = (\n",
    "        record.get(\"page_content\")\n",
    "        or record.get(\"question\")\n",
    "        or record.get(\"utterance\", \"\")\n",
    "    )\n",
    "    question_id = record.get(\"id\", record.get(\"_id\", f\"example_{example_index}\"))\n",
    "    display(\n",
    "        Markdown(\n",
    "            f\"### ‚ùì Failed Question #{example_index} (out of {len(failed)}) - Question ID: {question_id}\\nQuestion: {utterance}\"\n",
    "        )\n",
    "    )\n",
    "    display(Markdown(\"### ‚úÖ Ground Truth SQL(s)\"))\n",
    "    for sql in gt_sqls:\n",
    "        display(Markdown(f\"```sql\\n{sql}\\n```\"))\n",
    "\n",
    "    display(Markdown(\"### ‚ùå Predicted SQL\"))\n",
    "    display(Markdown(f\"```sql\\n{pred['predicted_sql']}\\n```\"))\n",
    "\n",
    "    display(Markdown(\"### üìä Evaluation Metrics\"))\n",
    "    eval_df = pd.DataFrame([pred.get(\"evaluation\", {})])\n",
    "    llm_explanation = None\n",
    "    if \"llm_explanation\" in eval_df.columns:\n",
    "        llm_explanation = eval_df.at[0, \"llm_explanation\"]\n",
    "    columns_to_drop = [\"gt_sql\", \"gt_df\", \"llm_explanation\"]\n",
    "    eval_df.drop(columns=columns_to_drop, errors=\"ignore\", inplace=True)\n",
    "    display(eval_df)\n",
    "\n",
    "    display(Markdown(\"### üìò Ground Truth Result(s)\"))\n",
    "    for i, df in enumerate(gt_dfs):\n",
    "        display(Markdown(f\"**Result {i + 1}:**\"))\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            display(df)\n",
    "        else:\n",
    "            display(Markdown(df))\n",
    "\n",
    "    display(Markdown(\"### üìï Predicted Result\"))\n",
    "    if pred_df is not None:\n",
    "        display(pred_df)\n",
    "    elif pred_df_error:\n",
    "        display(Markdown(pred_df_error))\n",
    "\n",
    "    # Display agent trace for agentic pipelines, or prompt for standard baseline\n",
    "    if \"agent_trace\" in pred and pred[\"agent_trace\"]:\n",
    "        display(Markdown(\"### ü§ñ Agent Interaction Trace\"))\n",
    "        trace = pred[\"agent_trace\"]\n",
    "        if isinstance(trace, list):\n",
    "            for i, interaction in enumerate(trace, 1):\n",
    "                step_name = interaction.get(\"step\", f\"step_{i}\")\n",
    "                display(Markdown(f\"\\n**Step {i}: {step_name}**\\n\"))\n",
    "                \n",
    "                # Show messages (prompts sent to LLM)\n",
    "                if \"messages\" in interaction:\n",
    "                    display(Markdown(\"<details><summary>üìù Messages</summary>\\n\"))\n",
    "                    for msg in interaction[\"messages\"]:\n",
    "                        role = msg.get(\"role\", \"unknown\").capitalize()\n",
    "                        content = msg.get(\"content\", \"\").strip()\n",
    "                        display(Markdown(f\"**{role}:**\\n```\\n{safe_snippet(content, head=500, tail=500)}\\n```\\n\"))\n",
    "                    display(Markdown(\"</details>\\n\"))\n",
    "                \n",
    "                # Show response\n",
    "                if \"response\" in interaction:\n",
    "                    display(Markdown(f\"**Response:** `{safe_snippet(interaction['response'][:200])}`\\n\"))\n",
    "                \n",
    "                # Show parsed SQL if available\n",
    "                if \"parsed_sql\" in interaction:\n",
    "                    display(Markdown(f\"**Parsed SQL:** \\n```sql\\n{interaction['parsed_sql']}\\n```\\n\"))\n",
    "                \n",
    "                # Show LLM judge verdict if this is a validation step\n",
    "                if \"verdict\" in interaction:\n",
    "                    display(Markdown(f\"**Verdict:** {interaction['verdict']} (Confidence: {interaction.get('confidence', 'N/A')})\\n\"))\n",
    "                    if \"reasoning\" in interaction:\n",
    "                        display(Markdown(f\"**Reasoning:** {safe_snippet(interaction['reasoning'][:300])}\\n\"))\n",
    "                \n",
    "                # Show error if any\n",
    "                if \"error\" in interaction:\n",
    "                    display(Markdown(f\"**Error:** {interaction['error']}\\n\"))\n",
    "        else:\n",
    "            display(Markdown(f\"```\\n{str(trace)}\\n```\"))\n",
    "        \n",
    "        # Also show number of attempts if available\n",
    "        if \"agent_attempts\" in pred:\n",
    "            display(Markdown(f\"\\n**Total Attempts:** {pred['agent_attempts']}\"))\n",
    "    elif \"agent_reasoning\" in pred and pred[\"agent_reasoning\"]:\n",
    "        # Fallback to agent_reasoning if trace not available\n",
    "        display(Markdown(\"### ü§ñ Agent Reasoning\"))\n",
    "        reasoning_list = pred[\"agent_reasoning\"]\n",
    "        if isinstance(reasoning_list, list):\n",
    "            reasoning_text = \"\\n\".join(\n",
    "                f\"{i}. {reasoning}\" for i, reasoning in enumerate(reasoning_list, 1)\n",
    "            )\n",
    "            display(Markdown(f\"```\\n{reasoning_text}\\n```\"))\n",
    "        else:\n",
    "            display(Markdown(f\"```\\n{str(reasoning_list)}\\n```\"))\n",
    "        \n",
    "        # Also show number of attempts if available\n",
    "        if \"agent_attempts\" in pred:\n",
    "            display(Markdown(f\"\\n**Attempts:** {pred['agent_attempts']}\"))\n",
    "    elif \"prompt\" in pred:\n",
    "        display(Markdown(\"### üß† Prompt\"))\n",
    "        prompt = pred.get(\"prompt\", \"\")\n",
    "        if isinstance(prompt, list):\n",
    "            # Chat-style prompt\n",
    "            for msg in prompt:\n",
    "                role = msg.get(\"role\", \"unknown\").capitalize()\n",
    "                content = msg.get(\"content\", \"\").strip()\n",
    "                display(Markdown(f\"**{role}:**\\n```\\n{safe_snippet(content)}\\n```\\n\"))\n",
    "        else:\n",
    "            # String prompt\n",
    "            display(Markdown(f\"```\\n{safe_snippet(prompt)}\\n```\"))\n",
    "    else:\n",
    "        display(Markdown(\"### üß† Context\"))\n",
    "        display(Markdown(\"_No prompt or agent trace available_\"))\n",
    "    \n",
    "    if llm_explanation:\n",
    "        display(Markdown(f\"### ü§ñ LLM Judge Assessment\\nLLM judge score: `{eval_df.at[0, 'llm_score'] if 'llm_score' in eval_df.columns else 'N/A'}`\\n\"))\n",
    "        display(Markdown(\"LLM judge explanation (if applicable):\\n\"))\n",
    "        display(Markdown(f\"```\\n{llm_explanation}\\n```\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3048108b-7f20-4a42-aa79-76acbdd9c06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ‚ùì Failed Question #5 (out of 20) - Question ID: 1493\n",
       "Question: In February 2012, what percentage of customers consumed more than 528.3?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ‚úÖ Ground Truth SQL(s)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```sql\n",
       "SELECT CAST(SUM(IIF(Consumption > 528.3, 1, 0)) AS FLOAT) * 100 / COUNT(CustomerID) FROM yearmonth WHERE Date = '201202'\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ‚ùå Predicted SQL"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```sql\n",
       "SELECT \n",
       "    ROUND(100.0 * SUM(CASE WHEN Consumption > 528.3 THEN 1 ELSE 0 END) / COUNT(*), 2) AS percentage\n",
       "FROM yearmonth\n",
       "WHERE Date = '201202'\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üìä Evaluation Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>execution_accuracy</th>\n",
       "      <th>non_empty_execution_accuracy</th>\n",
       "      <th>subset_non_empty_execution_accuracy</th>\n",
       "      <th>logic_execution_accuracy</th>\n",
       "      <th>bird_execution_accuracy</th>\n",
       "      <th>is_sqlglot_parsable</th>\n",
       "      <th>is_sqlparse_parsable</th>\n",
       "      <th>sqlglot_equivalence</th>\n",
       "      <th>sqlglot_optimized_equivalence</th>\n",
       "      <th>sqlparse_equivalence</th>\n",
       "      <th>sql_exact_match</th>\n",
       "      <th>sql_syntactic_equivalence</th>\n",
       "      <th>eval_error</th>\n",
       "      <th>df_error</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>inference_time_ms</th>\n",
       "      <th>execution_time_ms</th>\n",
       "      <th>llm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1018</td>\n",
       "      <td>224</td>\n",
       "      <td>1242</td>\n",
       "      <td>3603.17</td>\n",
       "      <td>26.62</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   execution_accuracy  non_empty_execution_accuracy  \\\n",
       "0                   0                             0   \n",
       "\n",
       "   subset_non_empty_execution_accuracy  logic_execution_accuracy  \\\n",
       "0                                    0                         1   \n",
       "\n",
       "   bird_execution_accuracy  is_sqlglot_parsable  is_sqlparse_parsable  \\\n",
       "0                        0                    1                     1   \n",
       "\n",
       "   sqlglot_equivalence  sqlglot_optimized_equivalence  sqlparse_equivalence  \\\n",
       "0                    0                              0                     0   \n",
       "\n",
       "   sql_exact_match  sql_syntactic_equivalence  eval_error  df_error  \\\n",
       "0                0                          0           0         0   \n",
       "\n",
       "   prompt_tokens  completion_tokens  total_tokens  inference_time_ms  \\\n",
       "0           1018                224          1242            3603.17   \n",
       "\n",
       "   execution_time_ms  llm_score  \n",
       "0              26.62        1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üìò Ground Truth Result(s)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Result 1:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAST(SUM(IIF(Consumption &gt; 528.3, 1, 0)) AS FLOAT) * 100 / COUNT(CustomerID)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.623008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CAST(SUM(IIF(Consumption > 528.3, 1, 0)) AS FLOAT) * 100 / COUNT(CustomerID)\n",
       "0                                          66.623008                           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üìï Predicted Result"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   percentage\n",
       "0       66.62"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üß† Prompt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Your task is to convert a natural language question into an accurate SQL query using the given sqlite database schema.\n",
       "\n",
       "**Question:**:\n",
       "In February 2012, what percentage of customers consumed more than 528.3?\n",
       "\n",
       "**Database Engine / Dialect:**:\n",
       "sqlite\n",
       "\n",
       "**Schema:**\n",
       "Table: customers\n",
       "  Columns:\n",
       "    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\n",
       "    - Segment (TEXT) # Example values: SME, LAM, KAM\n",
       "    - Currency (TEXT) # Example values: EUR, CZK\n",
       "\n",
       "Table: gasstations\n",
       "  Columns:\n",
       "    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\n",
       "    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\n",
       "    - Country (TEXT) # Example values: CZE, SVK\n",
       "    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\n",
       "\n",
       "Table: products\n",
       "  Columns:\n",
       "    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\n",
       "    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\n",
       "\n",
       "Table: transactions_1k\n",
       "  Columns:\n",
       "    - \n",
       "‚Ä¶\n",
       "- CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\n",
       "    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\n",
       "    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\n",
       "\n",
       "\n",
       "**Instructions:**\n",
       "- Only use columns listed in the schema.\n",
       "- Do not use any other columns or tables not mentioned in the schema.\n",
       "- Ensure the SQL query is valid and executable.\n",
       "- Use proper SQL syntax and conventions.\n",
       "- Generate a complete SQL query that answers the question.\n",
       "- Use the correct SQL dialect for the database, i.e., sqlite.\n",
       "- Do not include any explanations or comments in the SQL output.\n",
       "- Your output must start with ```sql and end with ```.\n",
       "\n",
       "***Hints***\n",
       "- February 2012 refers to '201202' in yearmonth.date\n",
       "- The first 4 strings of the Date values in the yearmonth table can represent year\n",
       "- The 5th and 6th string of the date can refer to month.\n",
       "\n",
       "Question: In February 2012, what percentage of customers consumed more than 528.3?\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ü§ñ LLM Judge Assessment\n",
       "LLM judge score: `1.0`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "LLM judge explanation (if applicable):\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Yes\n",
       "\n",
       "The predicted SQL query is correct. It accurately calculates the percentage of customers who consumed more than 528.3 in February 2012. \n",
       "\n",
       "Here's a breakdown of why the predicted SQL is correct:\n",
       "1. The query filters the `yearmonth` table for the date '201202', which corresponds to February 2012.\n",
       "2. It uses a `CASE` statement within the `SUM` function to count the number of customers who consumed more than 528.3. This is equivalent to the `IIF` function used in the ground truth SQL.\n",
       "3. The result is then divided by the total count of customers (`COUNT(*)`) and multiplied by 100 to get the percentage.\n",
       "4. The `ROUND` function is used to round the result to 2 decimal places, which is a reasonable formatting choice.\n",
       "\n",
       "The predicted result (66.62) matches the ground truth result (66.623008) when rounded to 2 decimal places, which further confirms the correctness of the predicted SQL query. \n",
       "\n",
       "Overall, the predicted SQL query is a valid and reasonable interpretation of the natural language question, and it produces the correct result. Therefore, the verdict is \"Yes\". \n",
       "```sql\n",
       "```\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_id = \"wxai:openai/gpt-oss-120b-greedy-zero-shot-chatapi\"\n",
    "failed_examples = get_failed_records(\n",
    "    pred_eval_data, pipeline_id, \"subset_non_empty_execution_accuracy\"\n",
    ")\n",
    "show_failed_example(pipeline_id, failed_examples, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f1b439d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error analysis for pipeline: wxai:openai/gpt-oss-120b-agentic-baseline2-3attempts\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ‚ùì Failed Question #5 (of 22 examples) - Question ID: `1500`\n",
       "\n",
       "\n",
       "**Question**: Please list the product description of the products consumed in September, 2013.\n",
       "\n",
       "\n",
       "### ‚úÖ Ground Truth SQL(s)\n",
       "\n",
       "```sql\n",
       "SELECT T3.Description FROM transactions_1k AS T1 INNER JOIN yearmonth AS T2 ON T1.CustomerID = T2.CustomerID INNER JOIN products AS T3 ON T1.ProductID = T3.ProductID WHERE T2.Date = '201309'\n",
       "```\n",
       "\n",
       "### ‚ùå Predicted SQL\n",
       "\n",
       "```sql\n",
       "SELECT DISTINCT p.Description\n",
       "FROM products p\n",
       "JOIN transactions_1k t ON p.ProductID = t.ProductID\n",
       "WHERE t.Date >= '2013-09-01' AND t.Date < '2013-10-01'\n",
       "```\n",
       "\n",
       "### üìä Evaluation Metrics\n",
       "\n",
       "|   execution_accuracy |   non_empty_execution_accuracy |   subset_non_empty_execution_accuracy |   logic_execution_accuracy |   bird_execution_accuracy |   is_sqlglot_parsable |   is_sqlparse_parsable |   sqlglot_equivalence |   sqlglot_optimized_equivalence |   sqlparse_equivalence |   sql_exact_match |   sql_syntactic_equivalence |   eval_error |   df_error |   prompt_tokens |   completion_tokens |   total_tokens |   inference_time_ms |   llm_score |\n",
       "|---------------------:|-------------------------------:|--------------------------------------:|---------------------------:|--------------------------:|----------------------:|-----------------------:|----------------------:|--------------------------------:|-----------------------:|------------------:|----------------------------:|-------------:|-----------:|----------------:|--------------------:|---------------:|--------------------:|------------:|\n",
       "|                    0 |                              0 |                                     0 |                          0 |                         0 |                     1 |                      1 |                     0 |                               0 |                      0 |                 0 |                           0 |            0 |          0 |             958 |                 247 |           1205 |              4029.6 |           0 |\n",
       "\n",
       "### üìò Ground Truth Result(s)\n",
       "\n",
       "**Result 1:**\n",
       "\n",
       "| Description     |\n",
       "|:----------------|\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "| Provoz.n√°pl.    |\n",
       "| Natural         |\n",
       "| Nafta           |\n",
       "| Natural         |\n",
       "| Natural         |\n",
       "| Nemrz.kapal.    |\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "| Natural         |\n",
       "| Natural         |\n",
       "| Oleje,tuky      |\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "| ...             |\n",
       "| ... (truncated) |\n",
       "| ...             |\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "| Diesel +        |\n",
       "| Natural         |\n",
       "| Natural         |\n",
       "| Natural         |\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "| Natural         |\n",
       "| Natural         |\n",
       "| Natural         |\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "| Nafta           |\n",
       "\n",
       "### üìï Predicted Result\n",
       "\n",
       "| Description   |\n",
       "|---------------|\n",
       "\n",
       "### ü§ñ Agent Interaction Trace\n",
       "\n",
       "\n",
       "**Step 1: generate_sql_attempt_1**\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "<summary>üìù Messages</summary>\n",
       "\n",
       "\n",
       "\n",
       "## Full Chat Prompt Conversation\n",
       "\n",
       "<div style=\"max-height: 400px; overflow-y: auto; border: 1px solid #ccc; padding: 10px; background-color: #f9f9f9; font-family: monospace;\">\n",
       "<div style='margin-bottom: 15px;'>\n",
       "<strong>System Message 1:</strong>\n",
       "<pre style='margin: 5px 0; padding: 10px; background-color: #ffffff; border-left: 3px solid #007acc; white-space: pre-wrap; word-wrap: break-word;'>You are a SQL expert. Your task is to convert natural language questions into accurate SQL queries using the given database schema and instructions.</pre>\n",
       "</div>\n",
       "<div style='margin-bottom: 15px;'>\n",
       "<strong>User Message 2:</strong>\n",
       "<pre style='margin: 5px 0; padding: 10px; background-color: #ffffff; border-left: 3px solid #007acc; white-space: pre-wrap; word-wrap: break-word;'>Your task is to convert a natural language question into an accurate SQL query using the given sqlite database schema.\n",
       "\n",
       "**Question:**:\n",
       "Please list the product description of the products consumed in September, 2013.\n",
       "\n",
       "**Database Engine / Dialect:**:\n",
       "sqlite\n",
       "\n",
       "**Schema:**\n",
       "Table: customers\n",
       "  Columns:\n",
       "    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\n",
       "    - Segment (TEXT) # Example values: SME, LAM, KAM\n",
       "    - Currency (TEXT) # Example values: EUR, CZK\n",
       "\n",
       "Table: gasstations\n",
       "  Columns:\n",
       "    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\n",
       "    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\n",
       "    - Country (TEXT) # Example values: CZE, SVK\n",
       "    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\n",
       "\n",
       "Table: products\n",
       "  Columns:\n",
       "    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\n",
       "    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\n",
       "\n",
       "Table: transactions_1k\n",
       "  Columns:\n",
       "    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\n",
       "    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\n",
       "    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\n",
       "    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\n",
       "    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\n",
       "    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\n",
       "    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\n",
       "    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\n",
       "    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\n",
       "\n",
       "Table: sqlite_sequence\n",
       "  Columns:\n",
       "    - name (TEXT) # Example values: transactions_1k\n",
       "    - seq (TEXT) # Example values: 1000\n",
       "\n",
       "Table: yearmonth\n",
       "  Columns:\n",
       "    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\n",
       "    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\n",
       "    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\n",
       "\n",
       "\n",
       "**Instructions:**\n",
       "- Only use columns listed in the schema.\n",
       "- Do not use any other columns or tables not mentioned in the schema.\n",
       "- Ensure the SQL query is valid and executable.\n",
       "- Use proper SQL syntax and conventions.\n",
       "- Generate a complete SQL query that answers the question.\n",
       "- Use the correct SQL dialect for the database, i.e., sqlite.\n",
       "- Do not include any explanations or comments in the SQL output.\n",
       "- Your output must start with ```sql and end with ```.\n",
       "\n",
       "Question: Please list the product description of the products consumed in September, 2013.</pre>\n",
       "</div>\n",
       "</div>\n",
       "\n",
       "\n",
       "</details>\n",
       "\n",
       "\n",
       "**Response:** `SELECT DISTINCT p.Description\n",
       "FROM products p\n",
       "JOIN transactions_1k t ON p.ProductID = t.ProductID\n",
       "WHERE t.Date >= '2013-09-01' AND t.Date < '2013-10-01'`\n",
       "\n",
       "\n",
       "**Parsed SQL:** \n",
       "```sql\n",
       "SELECT DISTINCT p.Description\n",
       "FROM products p\n",
       "JOIN transactions_1k t ON p.ProductID = t.ProductID\n",
       "WHERE t.Date >= '2013-09-01' AND t.Date < '2013-10-01'\n",
       "```\n",
       "\n",
       "\n",
       "\n",
       "**Total Attempts:** 1\n",
       "\n",
       "### ü§ñ LLM Judge Assessment\n",
       "LLM judge score: `0.0`\n",
       "\n",
       "\n",
       "LLM judge explanation (if applicable):\n",
       "\n",
       "\n",
       "<pre>No\n",
       "\n",
       "The predicted SQL query does not match the ground truth SQL query. Although the predicted query attempts to filter transactions by date, it does so in a manner that is inconsistent with the ground truth query. The ground truth query joins the `transactions_1k` table with the `yearmonth` table on the `CustomerID` column and filters the results to include only transactions where the `Date` column in the `yearmonth` table is `&#x27;201309&#x27;`. In contrast, the predicted query filters the `transactions_1k` table directly based on the `Date` column, which may not accurately reflect the desired date range.\n",
       "\n",
       "Furthermore, the predicted result is an empty dataframe, which suggests that the query did not return any matching rows. This is likely due to the fact that the `Date` column in the `transactions_1k` table may not contain dates in the format `&#x27;2013-09-01&#x27;` or `&#x27;2013-10-01&#x27;`, or that the dates in the table do not fall within the specified range.\n",
       "\n",
       "In contrast, the ground truth result contains a list of product descriptions, which suggests that the ground truth query was able to successfully retrieve the desired data. Therefore, based on the differences between the predicted and ground truth queries, as well as the empty predicted result, I conclude that the predicted SQL query is incorrect. \n",
       "\n",
       "Note: The empty predicted result could also be due to the data in the `transactions_1k` table, but without more information about the data, it&#x27;s impossible to say for certain. However, given the differences between the predicted and ground truth queries, it&#x27;s likely that the predicted query is the cause of the empty result. \n",
       "\n",
       "The best answer is No.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Alternatively, use the built-in display function\n",
    "from text2sql_eval_toolkit.analysis.error_analysis import (\n",
    "    get_failed_records,\n",
    "    format_failed_example,\n",
    ")\n",
    "\n",
    "pipeline_id = pipeline_ids[0]\n",
    "print(f\"Error analysis for pipeline: {pipeline_id}\")\n",
    "failed_records = get_failed_records(\n",
    "    pred_eval_data, pipeline_id, metric=\"subset_non_empty_execution_accuracy\"\n",
    ")\n",
    "failed_record_index = 5\n",
    "display(\n",
    "    Markdown(\n",
    "        format_failed_example(\n",
    "            failed_records[failed_record_index - 1],\n",
    "            pipeline_id,\n",
    "            failed_record_index,\n",
    "            len(failed_records),\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec41d39",
   "metadata": {},
   "source": [
    "## LLM as a judge to dig deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14b34bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': 1480,\n",
       " 'db_id': 'debit_card_specializing',\n",
       " 'question': 'What was the gas consumption peak month for SME customers in 2013?',\n",
       " 'evidence': 'Year 2013 can be presented as Between 201301 And 201312; The first 4 strings of the Date values in the yearmonth table can represent year; The 5th and 6th string of the date can refer to month.',\n",
       " 'SQL': \"SELECT SUBSTR(T2.Date, 5, 2) FROM customers AS T1 INNER JOIN yearmonth AS T2 ON T1.CustomerID = T2.CustomerID WHERE SUBSTR(T2.Date, 1, 4) = '2013' AND T1.Segment = 'SME' GROUP BY SUBSTR(T2.Date, 5, 2) ORDER BY SUM(T2.Consumption) DESC LIMIT 1\",\n",
       " 'difficulty': 'moderate',\n",
       " 'sql': [\"SELECT SUBSTR(T2.Date, 5, 2) FROM customers AS T1 INNER JOIN yearmonth AS T2 ON T1.CustomerID = T2.CustomerID WHERE SUBSTR(T2.Date, 1, 4) = '2013' AND T1.Segment = 'SME' GROUP BY SUBSTR(T2.Date, 5, 2) ORDER BY SUM(T2.Consumption) DESC LIMIT 1\"],\n",
       " 'meta': {'features': {'query_table_count': 2,\n",
       "   'query_column_count': 7,\n",
       "   'query_nested_count': 0,\n",
       "   'query_aggregate_count': 1,\n",
       "   'query_sort_count': 1,\n",
       "   'query_window_func_count': 0,\n",
       "   'query_join_count': 1},\n",
       "  'categories': ['has_aggregation',\n",
       "   'has_join',\n",
       "   'has_sorting',\n",
       "   'multi_table_simple',\n",
       "   'difficulty_moderate']},\n",
       " 'id': 1480,\n",
       " 'utterance': 'What was the gas consumption peak month for SME customers in 2013?',\n",
       " 'predictions': {'wxai:meta-llama/llama-3-3-70b-instruct-greedy-zero-shot-chatapi': {'predicted_sql': \"SELECT Date \\nFROM yearmonth \\nWHERE CustomerID IN (SELECT CustomerID FROM customers WHERE Segment = 'SME') \\n  AND Date BETWEEN 201301 AND 201312 \\nORDER BY Consumption DESC \\nLIMIT 1\",\n",
       "   'prompt': 'Your task is to convert a natural language question into an accurate SQL query using the given sqlite database schema.\\n\\n**Question:**:\\nWhat was the gas consumption peak month for SME customers in 2013?\\n\\n**Database Engine / Dialect:**:\\nsqlite\\n\\n**Schema:**\\nTable: customers\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\\n    - Segment (TEXT) # Example values: SME, LAM, KAM\\n    - Currency (TEXT) # Example values: EUR, CZK\\n\\nTable: gasstations\\n  Columns:\\n    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\\n    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\\n    - Country (TEXT) # Example values: CZE, SVK\\n    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\\n\\nTable: products\\n  Columns:\\n    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\\n\\nTable: transactions_1k\\n  Columns:\\n    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\\n    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\\n    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\\n    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\\n    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\\n    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\\n    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\\n    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\\n\\nTable: sqlite_sequence\\n  Columns:\\n    - name (TEXT) # Example values: transactions_1k\\n    - seq (TEXT) # Example values: 1000\\n\\nTable: yearmonth\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\\n    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\\n    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\\n\\n\\n**Instructions:**\\n- Only use columns listed in the schema.\\n- Do not use any other columns or tables not mentioned in the schema.\\n- Ensure the SQL query is valid and executable.\\n- Use proper SQL syntax and conventions.\\n- Generate a complete SQL query that answers the question.\\n- Use the correct SQL dialect for the database, i.e., sqlite.\\n- Do not include any explanations or comments in the SQL output.\\n- Your output must start with ```sql and end with ```.\\n\\n***Hints***\\n- Year 2013 can be presented as Between 201301 And 201312\\n- The first 4 strings of the Date values in the yearmonth table can represent year\\n- The 5th and 6th string of the date can refer to month.\\n\\nQuestion: What was the gas consumption peak month for SME customers in 2013?',\n",
       "   'model_name': 'wxai:meta-llama/llama-3-3-70b-instruct',\n",
       "   'model_parameters': {'decoding_method': 'greedy',\n",
       "    'max_new_tokens': 1024,\n",
       "    'stop_sequences': []},\n",
       "   'token_usage': {'prompt_tokens': 977,\n",
       "    'completion_tokens': 51,\n",
       "    'total_tokens': 1028},\n",
       "   'inference_time_ms': 2606.53,\n",
       "   'logic_sql': \"SELECT SUBSTRING(T2.Date, 5, 2) FROM yearmonth WHERE CustomerID IN (SELECT CustomerID FROM customers WHERE Segment = 'SME') AND Date BETWEEN 201301 AND 201312 ORDER BY Consumption DESC LIMIT 1\",\n",
       "   'predicted_df': '{\"columns\":[\"Date\"],\"index\":[0],\"data\":[[201304]]}',\n",
       "   'execution_time_ms': 119.32,\n",
       "   'logic_sql_execution_error': 'Error running SQL: Error running query: no such column: T2.Date',\n",
       "   'logic_execution_time_ms': None,\n",
       "   'evaluation': {'execution_accuracy': 0,\n",
       "    'non_empty_execution_accuracy': 0,\n",
       "    'subset_non_empty_execution_accuracy': 0,\n",
       "    'logic_execution_accuracy': 0,\n",
       "    'bird_execution_accuracy': 0,\n",
       "    'is_sqlglot_parsable': 1,\n",
       "    'is_sqlparse_parsable': 1,\n",
       "    'sqlglot_equivalence': 0,\n",
       "    'sqlglot_optimized_equivalence': 0,\n",
       "    'sqlparse_equivalence': 0,\n",
       "    'sql_exact_match': 0,\n",
       "    'sql_syntactic_equivalence': 0,\n",
       "    'eval_error': 0,\n",
       "    'df_error': 0,\n",
       "    'prompt_tokens': 977,\n",
       "    'completion_tokens': 51,\n",
       "    'total_tokens': 1028,\n",
       "    'inference_time_ms': 2606.53,\n",
       "    'execution_time_ms': 119.32,\n",
       "    'llm_score': 1.0,\n",
       "    'llm_explanation': 'Yes\\n\\nThe predicted SQL query is correct. It first filters the `yearmonth` table to include only rows where the `CustomerID` corresponds to an SME customer and the date falls within the year 2013. Then, it orders the remaining rows by consumption in descending order and selects the top row, which corresponds to the month with the highest gas consumption.\\n\\nThe predicted result, `201304`, indicates that the peak month for SME customers in 2013 was April (04). This is consistent with the ground truth result, which also identifies April as the peak month.\\n\\nAlthough the predicted SQL query differs from the ground truth SQL, it achieves the same result and is a reasonable interpretation of the natural language question. The use of `BETWEEN` to filter the dates and `IN` to filter the customer IDs is a valid and efficient approach. Overall, the predicted SQL query is correct and effectively answers the question. \\n\\nNote: The ground truth SQL uses `SUBSTR` to extract the month from the `Date` column, whereas the predicted SQL uses the `BETWEEN` operator to filter the dates. Both approaches are valid, but the predicted SQL is more concise and easier to read. \\n\\nIn conclusion, the predicted SQL query is a correct and reasonable interpretation of the natural language question, and the verdict is \"Yes\". \\n```sql\\n```'}},\n",
       "  'wxai:ibm/granite-4-h-small-greedy-zero-shot-chatapi': {'predicted_sql': \"SELECT \\n    substr(Date, 5, 2) AS month\\nFROM \\n    yearmonth\\nWHERE \\n    CustomerID IN (SELECT CustomerID FROM customers WHERE Segment = 'SME')\\n    AND substr(Date, 1, 4) = '2013'\\nORDER BY \\n    Consumption DESC\\nLIMIT 1\",\n",
       "   'prompt': 'Your task is to convert a natural language question into an accurate SQL query using the given sqlite database schema.\\n\\n**Question:**:\\nWhat was the gas consumption peak month for SME customers in 2013?\\n\\n**Database Engine / Dialect:**:\\nsqlite\\n\\n**Schema:**\\nTable: customers\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\\n    - Segment (TEXT) # Example values: SME, LAM, KAM\\n    - Currency (TEXT) # Example values: EUR, CZK\\n\\nTable: gasstations\\n  Columns:\\n    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\\n    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\\n    - Country (TEXT) # Example values: CZE, SVK\\n    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\\n\\nTable: products\\n  Columns:\\n    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\\n\\nTable: transactions_1k\\n  Columns:\\n    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\\n    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\\n    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\\n    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\\n    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\\n    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\\n    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\\n    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\\n\\nTable: sqlite_sequence\\n  Columns:\\n    - name (TEXT) # Example values: transactions_1k\\n    - seq (TEXT) # Example values: 1000\\n\\nTable: yearmonth\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\\n    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\\n    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\\n\\n\\n**Instructions:**\\n- Only use columns listed in the schema.\\n- Do not use any other columns or tables not mentioned in the schema.\\n- Ensure the SQL query is valid and executable.\\n- Use proper SQL syntax and conventions.\\n- Generate a complete SQL query that answers the question.\\n- Use the correct SQL dialect for the database, i.e., sqlite.\\n- Do not include any explanations or comments in the SQL output.\\n- Your output must start with ```sql and end with ```.\\n\\n***Hints***\\n- Year 2013 can be presented as Between 201301 And 201312\\n- The first 4 strings of the Date values in the yearmonth table can represent year\\n- The 5th and 6th string of the date can refer to month.\\n\\nQuestion: What was the gas consumption peak month for SME customers in 2013?',\n",
       "   'model_name': 'wxai:ibm/granite-4-h-small',\n",
       "   'model_parameters': {'decoding_method': 'greedy',\n",
       "    'max_new_tokens': 1024,\n",
       "    'stop_sequences': []},\n",
       "   'token_usage': {'prompt_tokens': 955,\n",
       "    'completion_tokens': 72,\n",
       "    'total_tokens': 1027},\n",
       "   'inference_time_ms': 2090.92,\n",
       "   'logic_sql': \"SELECT SUBSTRING(T2.Date, 5, 2) FROM yearmonth WHERE CustomerID IN (SELECT CustomerID FROM customers WHERE Segment = 'SME') AND SUBSTRING(Date, 1, 4) = '2013' ORDER BY Consumption DESC LIMIT 1\",\n",
       "   'predicted_df': '{\"columns\":[\"month\"],\"index\":[0],\"data\":[[4]]}',\n",
       "   'execution_time_ms': 60.2,\n",
       "   'logic_sql_execution_error': 'Error running SQL: Error running query: no such column: T2.Date',\n",
       "   'logic_execution_time_ms': None,\n",
       "   'evaluation': {'execution_accuracy': 1,\n",
       "    'non_empty_execution_accuracy': 1,\n",
       "    'subset_non_empty_execution_accuracy': 1,\n",
       "    'logic_execution_accuracy': 1,\n",
       "    'bird_execution_accuracy': 1,\n",
       "    'is_sqlglot_parsable': 1,\n",
       "    'is_sqlparse_parsable': 1,\n",
       "    'sqlglot_equivalence': 0,\n",
       "    'sqlglot_optimized_equivalence': 0,\n",
       "    'sqlparse_equivalence': 0,\n",
       "    'sql_exact_match': 0,\n",
       "    'sql_syntactic_equivalence': 0,\n",
       "    'eval_error': 0,\n",
       "    'df_error': 0,\n",
       "    'prompt_tokens': 955,\n",
       "    'completion_tokens': 72,\n",
       "    'total_tokens': 1027,\n",
       "    'inference_time_ms': 2090.92,\n",
       "    'execution_time_ms': 60.2,\n",
       "    'llm_score': 1.0,\n",
       "    'llm_explanation': 'N/A (did not use LLM due to subset match)',\n",
       "    'gt_sql': \"SELECT SUBSTR(T2.Date, 5, 2) FROM customers AS T1 INNER JOIN yearmonth AS T2 ON T1.CustomerID = T2.CustomerID WHERE SUBSTR(T2.Date, 1, 4) = '2013' AND T1.Segment = 'SME' GROUP BY SUBSTR(T2.Date, 5, 2) ORDER BY SUM(T2.Consumption) DESC LIMIT 1\",\n",
       "    'gt_df': '{\"columns\":[\"SUBSTR(T2.Date, 5, 2)\"],\"index\":[0],\"data\":[[4]]}'}},\n",
       "  'wxai:meta-llama/llama-4-maverick-17b-128e-instruct-fp8-greedy-zero-shot-chatapi': {'predicted_sql': \"SELECT Date \\nFROM yearmonth \\nWHERE CustomerID IN (\\n  SELECT CustomerID \\n  FROM customers \\n  WHERE Segment = 'SME'\\n) \\nAND Date BETWEEN '201301' AND '201312' \\nORDER BY Consumption DESC \\nLIMIT 1\",\n",
       "   'prompt': 'Your task is to convert a natural language question into an accurate SQL query using the given sqlite database schema.\\n\\n**Question:**:\\nWhat was the gas consumption peak month for SME customers in 2013?\\n\\n**Database Engine / Dialect:**:\\nsqlite\\n\\n**Schema:**\\nTable: customers\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\\n    - Segment (TEXT) # Example values: SME, LAM, KAM\\n    - Currency (TEXT) # Example values: EUR, CZK\\n\\nTable: gasstations\\n  Columns:\\n    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\\n    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\\n    - Country (TEXT) # Example values: CZE, SVK\\n    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\\n\\nTable: products\\n  Columns:\\n    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\\n\\nTable: transactions_1k\\n  Columns:\\n    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\\n    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\\n    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\\n    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\\n    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\\n    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\\n    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\\n    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\\n\\nTable: sqlite_sequence\\n  Columns:\\n    - name (TEXT) # Example values: transactions_1k\\n    - seq (TEXT) # Example values: 1000\\n\\nTable: yearmonth\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\\n    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\\n    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\\n\\n\\n**Instructions:**\\n- Only use columns listed in the schema.\\n- Do not use any other columns or tables not mentioned in the schema.\\n- Ensure the SQL query is valid and executable.\\n- Use proper SQL syntax and conventions.\\n- Generate a complete SQL query that answers the question.\\n- Use the correct SQL dialect for the database, i.e., sqlite.\\n- Do not include any explanations or comments in the SQL output.\\n- Your output must start with ```sql and end with ```.\\n\\n***Hints***\\n- Year 2013 can be presented as Between 201301 And 201312\\n- The first 4 strings of the Date values in the yearmonth table can represent year\\n- The 5th and 6th string of the date can refer to month.\\n\\nQuestion: What was the gas consumption peak month for SME customers in 2013?',\n",
       "   'model_name': 'wxai:meta-llama/llama-4-maverick-17b-128e-instruct-fp8',\n",
       "   'model_parameters': {'decoding_method': 'greedy',\n",
       "    'max_new_tokens': 1024,\n",
       "    'stop_sequences': []},\n",
       "   'token_usage': {'prompt_tokens': 955,\n",
       "    'completion_tokens': 58,\n",
       "    'total_tokens': 1013},\n",
       "   'inference_time_ms': 1159.37,\n",
       "   'logic_sql': \"SELECT SUBSTRING(T2.Date, 5, 2) FROM yearmonth WHERE CustomerID IN (SELECT CustomerID FROM customers WHERE Segment = 'SME') AND Date BETWEEN '201301' AND '201312' ORDER BY Consumption DESC LIMIT 1\",\n",
       "   'predicted_df': '{\"columns\":[\"Date\"],\"index\":[0],\"data\":[[201304]]}',\n",
       "   'execution_time_ms': 136.25,\n",
       "   'logic_sql_execution_error': 'Error running SQL: Error running query: no such column: T2.Date',\n",
       "   'logic_execution_time_ms': None,\n",
       "   'evaluation': {'execution_accuracy': 0,\n",
       "    'non_empty_execution_accuracy': 0,\n",
       "    'subset_non_empty_execution_accuracy': 0,\n",
       "    'logic_execution_accuracy': 0,\n",
       "    'bird_execution_accuracy': 0,\n",
       "    'is_sqlglot_parsable': 1,\n",
       "    'is_sqlparse_parsable': 1,\n",
       "    'sqlglot_equivalence': 0,\n",
       "    'sqlglot_optimized_equivalence': 0,\n",
       "    'sqlparse_equivalence': 0,\n",
       "    'sql_exact_match': 0,\n",
       "    'sql_syntactic_equivalence': 0,\n",
       "    'eval_error': 0,\n",
       "    'df_error': 0,\n",
       "    'prompt_tokens': 955,\n",
       "    'completion_tokens': 58,\n",
       "    'total_tokens': 1013,\n",
       "    'inference_time_ms': 1159.37,\n",
       "    'execution_time_ms': 136.25,\n",
       "    'llm_score': 1.0,\n",
       "    'llm_explanation': 'Yes\\n\\nThe predicted SQL query is correct. It first filters the customers who are SME customers, then it filters the yearmonth table to only include rows where the CustomerID is an SME customer and the date is in 2013. It then orders the results by consumption in descending order and limits the result to the top row, which corresponds to the peak month. \\n\\nThe predicted result, 201304, indicates that the peak month for SME customers in 2013 was April (04). \\n\\nThe ground truth SQL query and the predicted SQL query achieve the same goal but use slightly different methods. The ground truth query uses a join and groups the results by month, while the predicted query uses a subquery to filter the CustomerID and then orders the results by consumption. \\n\\nBoth queries are valid and correct, and the predicted query is a reasonable interpretation of the natural language question. Therefore, the verdict is \"Yes\". \\n\\nNote: The ground truth result shows the month as \\'4\\', while the predicted result shows the full date \\'201304\\'. Both results indicate that the peak month is April, but they are presented in different formats. This difference in format does not affect the correctness of the predicted query. \\n\\nIn conclusion, the predicted SQL query is correct and effectively answers the natural language question. The difference in format between the ground truth result and the predicted result does not impact the verdict. \\n\\nTherefore, the final answer is \"Yes\". \\n\\nThe predicted SQL query is a valid and correct interpretation of the natural language question, and it achieves the same goal as the ground truth query. \\n\\nThe verdict is \"Yes\" because the predicted query is correct, and it provides the correct result, which is the peak month for SME customers in 2013. \\n\\nThe predicted query is a reasonable interpretation of the natural language question, and it is a valid and correct SQL query. \\n\\nThe final answer is \"Yes\". \\n\\nThe predicted SQL query is correct, and it provides the correct result. \\n\\nThe verdict is \"Yes\". \\n\\nThe predicted query is a valid and correct interpretation of the natural language question. \\n\\nThe final answer is \"Yes\". \\n\\nThe predicted SQL query is correct. \\n\\nThe verdict is \"Yes\". \\n\\nThe predicted query is a reasonable interpretation of the natural language question. \\n\\nThe final answer is \"Yes\". \\n\\nThe predicted SQL query is correct, and it provides the correct result. \\n\\nThe verdict is \"Yes\". \\n\\nThe predicted query is a valid and correct interpretation of the natural language question. \\n\\nThe final answer is'}},\n",
       "  'wxai:openai/gpt-oss-120b-greedy-zero-shot-chatapi': {'predicted_sql': \"SELECT ym.Date\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE ym.Date BETWEEN '201301' AND '201312'\\n  AND c.Segment = 'SME'\\nGROUP BY ym.Date\\nORDER BY SUM(ym.Consumption) DESC\\nLIMIT 1\",\n",
       "   'prompt': 'Your task is to convert a natural language question into an accurate SQL query using the given sqlite database schema.\\n\\n**Question:**:\\nWhat was the gas consumption peak month for SME customers in 2013?\\n\\n**Database Engine / Dialect:**:\\nsqlite\\n\\n**Schema:**\\nTable: customers\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\\n    - Segment (TEXT) # Example values: SME, LAM, KAM\\n    - Currency (TEXT) # Example values: EUR, CZK\\n\\nTable: gasstations\\n  Columns:\\n    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\\n    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\\n    - Country (TEXT) # Example values: CZE, SVK\\n    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\\n\\nTable: products\\n  Columns:\\n    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\\n\\nTable: transactions_1k\\n  Columns:\\n    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\\n    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\\n    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\\n    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\\n    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\\n    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\\n    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\\n    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\\n\\nTable: sqlite_sequence\\n  Columns:\\n    - name (TEXT) # Example values: transactions_1k\\n    - seq (TEXT) # Example values: 1000\\n\\nTable: yearmonth\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\\n    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\\n    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\\n\\n\\n**Instructions:**\\n- Only use columns listed in the schema.\\n- Do not use any other columns or tables not mentioned in the schema.\\n- Ensure the SQL query is valid and executable.\\n- Use proper SQL syntax and conventions.\\n- Generate a complete SQL query that answers the question.\\n- Use the correct SQL dialect for the database, i.e., sqlite.\\n- Do not include any explanations or comments in the SQL output.\\n- Your output must start with ```sql and end with ```.\\n\\n***Hints***\\n- Year 2013 can be presented as Between 201301 And 201312\\n- The first 4 strings of the Date values in the yearmonth table can represent year\\n- The 5th and 6th string of the date can refer to month.\\n\\nQuestion: What was the gas consumption peak month for SME customers in 2013?',\n",
       "   'model_name': 'wxai:openai/gpt-oss-120b',\n",
       "   'model_parameters': {'decoding_method': 'greedy',\n",
       "    'max_new_tokens': 1024,\n",
       "    'stop_sequences': []},\n",
       "   'token_usage': {'prompt_tokens': 1014,\n",
       "    'completion_tokens': 331,\n",
       "    'total_tokens': 1345},\n",
       "   'inference_time_ms': 2683.12,\n",
       "   'logic_sql': \"SELECT SUBSTRING(T2.Date, 5, 2) FROM yearmonth AS ym JOIN customers AS c ON ym.CustomerID = c.CustomerID WHERE ym.Date BETWEEN '201301' AND '201312' AND c.Segment = 'SME' GROUP BY ym.Date ORDER BY SUM(ym.Consumption) DESC LIMIT 1\",\n",
       "   'predicted_df': '{\"columns\":[\"Date\"],\"index\":[0],\"data\":[[201304]]}',\n",
       "   'execution_time_ms': 134.5,\n",
       "   'logic_sql_execution_error': 'Error running SQL: Error running query: no such column: T2.Date',\n",
       "   'logic_execution_time_ms': None,\n",
       "   'evaluation': {'execution_accuracy': 0,\n",
       "    'non_empty_execution_accuracy': 0,\n",
       "    'subset_non_empty_execution_accuracy': 0,\n",
       "    'logic_execution_accuracy': 0,\n",
       "    'bird_execution_accuracy': 0,\n",
       "    'is_sqlglot_parsable': 1,\n",
       "    'is_sqlparse_parsable': 1,\n",
       "    'sqlglot_equivalence': 0,\n",
       "    'sqlglot_optimized_equivalence': 0,\n",
       "    'sqlparse_equivalence': 0,\n",
       "    'sql_exact_match': 0,\n",
       "    'sql_syntactic_equivalence': 0,\n",
       "    'eval_error': 0,\n",
       "    'df_error': 0,\n",
       "    'prompt_tokens': 1014,\n",
       "    'completion_tokens': 331,\n",
       "    'total_tokens': 1345,\n",
       "    'inference_time_ms': 2683.12,\n",
       "    'execution_time_ms': 134.5,\n",
       "    'llm_score': 1.0,\n",
       "    'llm_explanation': 'Yes\\n\\nThe predicted SQL query is correct. It joins the `yearmonth` table with the `customers` table on the `CustomerID` column, filters the results to only include rows where the `Date` is between \\'201301\\' and \\'201312\\' (i.e., the year 2013) and the `Segment` is \\'SME\\'. The results are then grouped by the `Date` column, ordered by the sum of the `Consumption` column in descending order, and limited to the top row (i.e., the month with the highest consumption).\\n\\nThe predicted result, \\'201304\\', indicates that the peak month for gas consumption by SME customers in 2013 was April (04). This is consistent with the ground truth result, which also indicates that the peak month was April (although the ground truth result only shows the month as \\'4\\', while the predicted result shows the full date as \\'201304\\').\\n\\nOverall, the predicted SQL query is a reasonable interpretation of the natural language question, and the predicted result is consistent with the ground truth result. Therefore, the verdict is \"Yes\". \\n\\nNote: The difference in the format of the predicted result and the ground truth result does not affect the correctness of the predicted SQL query. The predicted result is still a valid answer to the question, and it is consistent with the ground truth result. \\n\\nAlso, note that the predicted SQL uses the `BETWEEN` operator to filter the dates, which is a more concise and readable way to specify the date range than using the `SUBSTR` function to extract the year from the date string. However, both approaches are valid and produce the same result. \\n\\nIn conclusion, the predicted SQL query is correct, and the predicted result is consistent with the ground truth result. Therefore, the verdict is \"Yes\". \\n\\nThe final answer is: $\\\\boxed{Yes}$ \\n\\nPlease let me know if you need any further clarification or details. \\n\\nI hope it is correct. \\n\\nLet me know if I can help with anything else. \\n\\nBest regards. \\n\\nPlease let me know if you need any further assistance. \\n\\nI hope this revised response meets your requirements. \\n\\nBest regards. \\n\\nPlease let me know if you need any further clarification or details. \\n\\nI hope it is correct. \\n\\nLet me know if I can help with anything else. \\n\\nBest regards. \\n\\nPlease let me know if you need any further assistance. \\n\\nI hope this revised response meets your requirements. \\n\\nBest regards. \\n\\nPlease'}},\n",
       "  'wxai:openai/gpt-oss-120b-agentic-baseline0-3attempts': {'predicted_sql': \"SELECT \\n    ym.Date AS YearMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth AS ym\\nJOIN customers   AS c  ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME'               -- only SME customers\\n  AND ym.Date LIKE '2013%'            -- only months in 2013\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1;                               -- peak month\",\n",
       "   'predicted_df': '{\"columns\":[\"YearMonth\",\"TotalConsumption\"],\"index\":[0],\"data\":[[201304,126047776.9200000018]]}',\n",
       "   'sql_execution_error': None,\n",
       "   'model_name': 'wxai:openai/gpt-oss-120b',\n",
       "   'model_parameters': {'decoding_method': 'greedy',\n",
       "    'max_new_tokens': 1024,\n",
       "    'stop_sequences': []},\n",
       "   'agent_attempts': 1,\n",
       "   'agent_reasoning': [\"Generated SQL (attempt 1): SELECT \\n    ym.Date AS YearMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth AS ym\\nJOIN customers   AS c  ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME'               -- only SME customers\\n  AND ym.Date LIKE '2013%'            -- only months in 2013\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1;                               -- peak month\",\n",
       "    'Query executed successfully and returned 1 rows.'],\n",
       "   'inference_time_ms': 2821.93,\n",
       "   'agent_trace': [{'step': 'generate_sql_attempt_1',\n",
       "     'messages': [{'role': 'system',\n",
       "       'content': 'You are an expert SQL assistant that helps convert natural language questions into accurate SQL queries.\\n\\nYour capabilities:\\n1. Generate SQL queries from natural language questions\\n2. Analyze SQL errors and fix them\\n3. Probe database schema when information is missing\\n4. Validate query results for correctness\\n\\nYou have access to:\\n- The database schema\\n- The ability to execute SQL queries\\n- The ability to probe the database for additional schema information\\n- Previous attempts and errors (if any)\\n\\nWhen you encounter an error:\\n1. Analyze the error message carefully\\n2. Check if the error is due to missing schema information\\n3. If needed, probe the database for more information\\n4. Fix the SQL query based on the error and try again\\n\\nWhen you generate SQL:\\n- Use only columns and tables mentioned in the schema\\n- Follow the correct SQL dialect for the database\\n- Ensure the query is syntactically correct\\n- Make sure the query answers the question accurately'},\n",
       "      {'role': 'user',\n",
       "       'content': '**Question:** What was the gas consumption peak month for SME customers in 2013?\\n\\n**Database Type:** sqlite\\n\\n**Schema:**\\nTable: customers\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\\n    - Segment (TEXT) # Example values: SME, LAM, KAM\\n    - Currency (TEXT) # Example values: EUR, CZK\\n\\nTable: gasstations\\n  Columns:\\n    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\\n    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\\n    - Country (TEXT) # Example values: CZE, SVK\\n    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\\n\\nTable: products\\n  Columns:\\n    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\\n\\nTable: transactions_1k\\n  Columns:\\n    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\\n    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\\n    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\\n    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\\n    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\\n    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\\n    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\\n    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\\n\\nTable: sqlite_sequence\\n  Columns:\\n    - name (TEXT) # Example values: transactions_1k\\n    - seq (TEXT) # Example values: 1000\\n\\nTable: yearmonth\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\\n    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\\n    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\\n\\n\\n**Attempt:** 1 of 3'},\n",
       "      {'role': 'user',\n",
       "       'content': 'Generate a SQL query to answer the question.'}],\n",
       "     'response': \"SELECT \\n    ym.Date AS YearMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth AS ym\\nJOIN customers   AS c  ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME'               -- only SME customers\\n  AND ym.Date LIKE '2013%'            -- only months in 2013\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1;                               -- peak month\",\n",
       "     'parsed_sql': \"SELECT \\n    ym.Date AS YearMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth AS ym\\nJOIN customers   AS c  ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME'               -- only SME customers\\n  AND ym.Date LIKE '2013%'            -- only months in 2013\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1;                               -- peak month\",\n",
       "     'token_usage': {'prompt_tokens': 1004,\n",
       "      'completion_tokens': 370,\n",
       "      'total_tokens': 1374}}],\n",
       "   'token_usage': {'prompt_tokens': 1004,\n",
       "    'completion_tokens': 370,\n",
       "    'total_tokens': 1374},\n",
       "   'token_usage_per_attempt': [{'prompt_tokens': 1004,\n",
       "     'completion_tokens': 370,\n",
       "     'total_tokens': 1374}],\n",
       "   'logic_sql': \"SELECT SUBSTRING(T2.Date, 5, 2) FROM yearmonth AS ym JOIN customers AS c ON ym.CustomerID = c.CustomerID WHERE c.Segment = 'SME' /* only SME customers */ AND ym.Date LIKE '2013%' /* only months in 2013 */ GROUP BY ym.Date ORDER BY TotalConsumption DESC LIMIT 1\",\n",
       "   'logic_sql_execution_error': 'Error running SQL: Error running query: no such column: T2.Date',\n",
       "   'logic_execution_time_ms': None,\n",
       "   'evaluation': {'execution_accuracy': 0,\n",
       "    'non_empty_execution_accuracy': 0,\n",
       "    'subset_non_empty_execution_accuracy': 0,\n",
       "    'logic_execution_accuracy': 0,\n",
       "    'bird_execution_accuracy': 0,\n",
       "    'is_sqlglot_parsable': 1,\n",
       "    'is_sqlparse_parsable': 1,\n",
       "    'sqlglot_equivalence': 0,\n",
       "    'sqlglot_optimized_equivalence': 0,\n",
       "    'sqlparse_equivalence': 0,\n",
       "    'sql_exact_match': 0,\n",
       "    'sql_syntactic_equivalence': 0,\n",
       "    'eval_error': 0,\n",
       "    'df_error': 0,\n",
       "    'prompt_tokens': 1004,\n",
       "    'completion_tokens': 370,\n",
       "    'total_tokens': 1374,\n",
       "    'inference_time_ms': 2821.93,\n",
       "    'llm_score': 1.0,\n",
       "    'llm_explanation': \"Yes\\n\\nThe predicted SQL query is correct. It accurately answers the natural language question by identifying the gas consumption peak month for SME customers in 2013. \\n\\nHere's why:\\n1. **Correct Join and Filtering**: The predicted SQL joins the `yearmonth` table with the `customers` table on `CustomerID` and correctly filters for SME customers and the year 2013.\\n2. **Appropriate Aggregation and Sorting**: It groups the data by the `Date` column (which represents the month) and calculates the total consumption for each month. The results are then sorted in descending order by total consumption, ensuring that the month with the highest consumption appears first.\\n3. **Limiting to the Peak Month**: By using `LIMIT 1`, the query returns only the month with the highest gas consumption, which directly answers the question.\\n\\nThe difference in the result format between the ground truth and the predicted result (e.g., `201304` vs. `4`) can be attributed to how the date is represented and extracted. The ground truth SQL uses `SUBSTR(T2.Date, 5, 2)` to extract the month, resulting in a numeric value representing the month (e.g., `4` for April), whereas the predicted SQL returns the full date string in the format `YYYYMM`. Both approaches are valid, but they represent the answer in different formats. The essence of the answer, however, is the same: identifying the month with the peak gas consumption for SME customers in 2013. \\n\\nTherefore, despite minor differences in representation, the predicted SQL query is a correct and reasonable interpretation of the natural language question. \\n```sql\\n```<|eom_id|>\"}},\n",
       "  'wxai:openai/gpt-oss-120b-agentic-baseline1-3attempts': {'predicted_sql': \"SELECT\\n    ym.Date AS Month,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME'\\n  AND ym.Date LIKE '2013%'\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\",\n",
       "   'predicted_df': '{\"columns\":[\"Month\",\"TotalConsumption\"],\"index\":[0],\"data\":[[201304,126047776.9200000018]]}',\n",
       "   'sql_execution_error': None,\n",
       "   'model_name': 'wxai:openai/gpt-oss-120b',\n",
       "   'model_parameters': {'decoding_method': 'greedy',\n",
       "    'max_new_tokens': 1024,\n",
       "    'stop_sequences': []},\n",
       "   'agent_attempts': 1,\n",
       "   'agent_reasoning': [\"Generated SQL (attempt 1): SELECT\\n    ym.Date AS Month,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME'\\n  AND ym.Date LIKE '2013%'\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\",\n",
       "    'Query executed successfully and returned 1 rows.'],\n",
       "   'inference_time_ms': 3099.01,\n",
       "   'agent_trace': [{'step': 'generate_sql_attempt_1',\n",
       "     'messages': [{'role': 'system',\n",
       "       'content': 'You are a SQL expert. Your task is to convert natural language questions into accurate SQL queries using the given database schema and instructions.'},\n",
       "      {'role': 'user',\n",
       "       'content': 'Your task is to convert a natural language question into an accurate SQL query using the given sqlite database schema.\\n\\n**Question:**:\\nWhat was the gas consumption peak month for SME customers in 2013?\\n\\n**Database Engine / Dialect:**:\\nsqlite\\n\\n**Schema:**\\nTable: customers\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\\n    - Segment (TEXT) # Example values: SME, LAM, KAM\\n    - Currency (TEXT) # Example values: EUR, CZK\\n\\nTable: gasstations\\n  Columns:\\n    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\\n    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\\n    - Country (TEXT) # Example values: CZE, SVK\\n    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\\n\\nTable: products\\n  Columns:\\n    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\\n\\nTable: transactions_1k\\n  Columns:\\n    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\\n    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\\n    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\\n    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\\n    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\\n    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\\n    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\\n    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\\n\\nTable: sqlite_sequence\\n  Columns:\\n    - name (TEXT) # Example values: transactions_1k\\n    - seq (TEXT) # Example values: 1000\\n\\nTable: yearmonth\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\\n    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\\n    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\\n\\n\\n**Instructions:**\\n- Only use columns listed in the schema.\\n- Do not use any other columns or tables not mentioned in the schema.\\n- Ensure the SQL query is valid and executable.\\n- Use proper SQL syntax and conventions.\\n- Generate a complete SQL query that answers the question.\\n- Use the correct SQL dialect for the database, i.e., sqlite.\\n- Do not include any explanations or comments in the SQL output.\\n- Your output must start with ```sql and end with ```.\\n\\nQuestion: What was the gas consumption peak month for SME customers in 2013?'}],\n",
       "     'response': \"SELECT\\n    ym.Date AS Month,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME'\\n  AND ym.Date LIKE '2013%'\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\",\n",
       "     'parsed_sql': \"SELECT\\n    ym.Date AS Month,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME'\\n  AND ym.Date LIKE '2013%'\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\",\n",
       "     'token_usage': {'prompt_tokens': 956,\n",
       "      'completion_tokens': 270,\n",
       "      'total_tokens': 1226}}],\n",
       "   'token_usage': {'prompt_tokens': 956,\n",
       "    'completion_tokens': 270,\n",
       "    'total_tokens': 1226},\n",
       "   'token_usage_per_attempt': [{'prompt_tokens': 956,\n",
       "     'completion_tokens': 270,\n",
       "     'total_tokens': 1226}],\n",
       "   'logic_sql': \"SELECT SUBSTRING(T2.Date, 5, 2) FROM yearmonth AS ym JOIN customers AS c ON ym.CustomerID = c.CustomerID WHERE c.Segment = 'SME' AND ym.Date LIKE '2013%' GROUP BY ym.Date ORDER BY TotalConsumption DESC LIMIT 1\",\n",
       "   'logic_sql_execution_error': 'Error running SQL: Error running query: no such column: T2.Date',\n",
       "   'logic_execution_time_ms': None,\n",
       "   'evaluation': {'execution_accuracy': 0,\n",
       "    'non_empty_execution_accuracy': 0,\n",
       "    'subset_non_empty_execution_accuracy': 0,\n",
       "    'logic_execution_accuracy': 0,\n",
       "    'bird_execution_accuracy': 0,\n",
       "    'is_sqlglot_parsable': 1,\n",
       "    'is_sqlparse_parsable': 1,\n",
       "    'sqlglot_equivalence': 0,\n",
       "    'sqlglot_optimized_equivalence': 0,\n",
       "    'sqlparse_equivalence': 0,\n",
       "    'sql_exact_match': 0,\n",
       "    'sql_syntactic_equivalence': 0,\n",
       "    'eval_error': 0,\n",
       "    'df_error': 0,\n",
       "    'prompt_tokens': 956,\n",
       "    'completion_tokens': 270,\n",
       "    'total_tokens': 1226,\n",
       "    'inference_time_ms': 3099.01,\n",
       "    'llm_score': 1.0,\n",
       "    'llm_explanation': \"Yes\\n\\nThe predicted SQL query is correct. It accurately identifies the gas consumption peak month for SME customers in 2013. \\n\\nThe query joins the `yearmonth` table with the `customers` table on the `CustomerID` column, filters the results to only include SME customers and dates in 2013, groups the results by date, and orders them by total consumption in descending order. The `LIMIT 1` clause ensures that only the peak month is returned.\\n\\nThe predicted result shows the peak month as '201304', which corresponds to April 2013, and the total consumption for that month. \\n\\nThe ground truth SQL and result are slightly different, but they essentially achieve the same goal. The ground truth SQL uses `SUBSTR` to extract the month from the date, whereas the predicted SQL returns the full date. However, both queries correctly identify the peak month. \\n\\nTherefore, the predicted SQL query is a reasonable interpretation of the natural language question and is considered correct. \\n\\nNote: The difference in the results (full date vs month only) is due to the way the date is handled in the queries, but it does not affect the correctness of the predicted SQL query. \\n\\nThe final answer is: $\\\\boxed{Yes}$\"}},\n",
       "  'wxai:openai/gpt-oss-120b-agentic-baseline2-3attempts': {'predicted_sql': \"SELECT y.Date AS Month, SUM(y.Consumption) AS TotalConsumption\\nFROM yearmonth y\\nJOIN customers c ON y.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME' AND y.Date LIKE '2013%'\\nGROUP BY y.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\",\n",
       "   'predicted_df': '{\"columns\":[\"Month\",\"TotalConsumption\"],\"index\":[0],\"data\":[[201304,126047776.9200000018]]}',\n",
       "   'sql_execution_error': None,\n",
       "   'model_name': 'wxai:openai/gpt-oss-120b',\n",
       "   'model_parameters': {'decoding_method': 'greedy',\n",
       "    'max_new_tokens': 1024,\n",
       "    'stop_sequences': []},\n",
       "   'agent_attempts': 1,\n",
       "   'agent_reasoning': [\"Generated SQL (attempt 1): SELECT y.Date AS Month, SUM(y.Consumption) AS TotalConsumption\\nFROM yearmonth y\\nJOIN customers c ON y.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME' AND y.Date LIKE '2013%'\\nGROUP BY y.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\",\n",
       "    'Query executed successfully and returned 1 rows.'],\n",
       "   'inference_time_ms': 2830.6,\n",
       "   'agent_trace': [{'step': 'generate_sql_attempt_1',\n",
       "     'messages': [{'role': 'system',\n",
       "       'content': 'You are a SQL expert. Your task is to convert natural language questions into accurate SQL queries using the given database schema and instructions.'},\n",
       "      {'role': 'user',\n",
       "       'content': 'Your task is to convert a natural language question into an accurate SQL query using the given sqlite database schema.\\n\\n**Question:**:\\nWhat was the gas consumption peak month for SME customers in 2013?\\n\\n**Database Engine / Dialect:**:\\nsqlite\\n\\n**Schema:**\\nTable: customers\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\\n    - Segment (TEXT) # Example values: SME, LAM, KAM\\n    - Currency (TEXT) # Example values: EUR, CZK\\n\\nTable: gasstations\\n  Columns:\\n    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\\n    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\\n    - Country (TEXT) # Example values: CZE, SVK\\n    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\\n\\nTable: products\\n  Columns:\\n    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\\n\\nTable: transactions_1k\\n  Columns:\\n    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\\n    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\\n    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\\n    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\\n    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\\n    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\\n    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\\n    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\\n\\nTable: sqlite_sequence\\n  Columns:\\n    - name (TEXT) # Example values: transactions_1k\\n    - seq (TEXT) # Example values: 1000\\n\\nTable: yearmonth\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\\n    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\\n    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\\n\\n\\n**Instructions:**\\n- Only use columns listed in the schema.\\n- Do not use any other columns or tables not mentioned in the schema.\\n- Ensure the SQL query is valid and executable.\\n- Use proper SQL syntax and conventions.\\n- Generate a complete SQL query that answers the question.\\n- Use the correct SQL dialect for the database, i.e., sqlite.\\n- Do not include any explanations or comments in the SQL output.\\n- Your output must start with ```sql and end with ```.\\n\\nQuestion: What was the gas consumption peak month for SME customers in 2013?'}],\n",
       "     'response': \"SELECT y.Date AS Month, SUM(y.Consumption) AS TotalConsumption\\nFROM yearmonth y\\nJOIN customers c ON y.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME' AND y.Date LIKE '2013%'\\nGROUP BY y.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\",\n",
       "     'parsed_sql': \"SELECT y.Date AS Month, SUM(y.Consumption) AS TotalConsumption\\nFROM yearmonth y\\nJOIN customers c ON y.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME' AND y.Date LIKE '2013%'\\nGROUP BY y.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\",\n",
       "     'token_usage': {'prompt_tokens': 956,\n",
       "      'completion_tokens': 355,\n",
       "      'total_tokens': 1311}}],\n",
       "   'token_usage': {'prompt_tokens': 956,\n",
       "    'completion_tokens': 355,\n",
       "    'total_tokens': 1311},\n",
       "   'token_usage_per_attempt': [{'prompt_tokens': 956,\n",
       "     'completion_tokens': 355,\n",
       "     'total_tokens': 1311}],\n",
       "   'logic_sql': \"SELECT SUBSTRING(T2.Date, 5, 2) FROM yearmonth AS y JOIN customers AS c ON y.CustomerID = c.CustomerID WHERE c.Segment = 'SME' AND y.Date LIKE '2013%' GROUP BY y.Date ORDER BY TotalConsumption DESC LIMIT 1\",\n",
       "   'logic_sql_execution_error': 'Error running SQL: Error running query: no such column: T2.Date',\n",
       "   'logic_execution_time_ms': None,\n",
       "   'evaluation': {'execution_accuracy': 0,\n",
       "    'non_empty_execution_accuracy': 0,\n",
       "    'subset_non_empty_execution_accuracy': 0,\n",
       "    'logic_execution_accuracy': 0,\n",
       "    'bird_execution_accuracy': 0,\n",
       "    'is_sqlglot_parsable': 1,\n",
       "    'is_sqlparse_parsable': 1,\n",
       "    'sqlglot_equivalence': 0,\n",
       "    'sqlglot_optimized_equivalence': 0,\n",
       "    'sqlparse_equivalence': 0,\n",
       "    'sql_exact_match': 0,\n",
       "    'sql_syntactic_equivalence': 0,\n",
       "    'eval_error': 0,\n",
       "    'df_error': 0,\n",
       "    'prompt_tokens': 956,\n",
       "    'completion_tokens': 355,\n",
       "    'total_tokens': 1311,\n",
       "    'inference_time_ms': 2830.6,\n",
       "    'llm_score': 1.0,\n",
       "    'llm_explanation': \"Yes\\n\\nThe predicted SQL query is correct. It accurately identifies the gas consumption peak month for SME customers in 2013. \\n\\nHere's a breakdown of why the predicted SQL is correct:\\n1. **Joining tables**: The predicted SQL joins the `yearmonth` table with the `customers` table on the `CustomerID` column, which is necessary to filter the data for SME customers.\\n2. **Filtering SME customers**: The query correctly filters the data to only include SME customers by using the condition `c.Segment = 'SME'`.\\n3. **Filtering 2013 data**: The query uses the condition `y.Date LIKE '2013%'` to filter the data to only include dates from the year 2013.\\n4. **Grouping and ordering**: The query groups the data by the `Date` column and orders the results by the total consumption in descending order, which allows it to identify the peak month.\\n5. **Limiting to peak month**: The query uses `LIMIT 1` to return only the peak month.\\n\\nThe predicted result shows the peak month as '201304', which corresponds to April 2013, and the total consumption for that month. \\n\\nThe ground truth SQL and result are slightly different, but they achieve the same goal. The ground truth SQL uses `SUBSTR` to extract the month from the date, whereas the predicted SQL returns the full date. However, both queries correctly identify the peak month for SME customers in 2013. \\n\\nTherefore, the predicted SQL query is a reasonable interpretation of the natural language question and is considered correct. \\n```sql\\n```<|eom_id|>\"}},\n",
       "  'wxai:openai/gpt-oss-120b-agentic-baseline3-3attempts': {'predicted_sql': \"SELECT\\n    ym.Date AS PeakMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME'\\n  AND ym.Date LIKE '2013%'\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\",\n",
       "   'predicted_df': None,\n",
       "   'sql_execution_error': None,\n",
       "   'model_name': 'wxai:openai/gpt-oss-120b',\n",
       "   'model_parameters': {'decoding_method': 'greedy',\n",
       "    'max_new_tokens': 1024,\n",
       "    'stop_sequences': []},\n",
       "   'agent_attempts': 3,\n",
       "   'agent_reasoning': [\"Generated SQL (attempt 1): SELECT\\n    ym.Date AS PeakMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME'\\n  AND ym.Date LIKE '2013%'\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\",\n",
       "    'Query executed successfully and returned 1 rows.',\n",
       "    'LLM Judge: RETRY (Confidence: LOW)',\n",
       "    'Generated SQL (attempt 2): SELECT\\n    ym.\"Date\" AS PeakMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = \\'SME\\'\\n  AND ym.\"Date\" LIKE \\'2013%\\'\\nGROUP BY ym.\"Date\"\\nORDER BY TotalConsumption DESC\\nLIMIT 1',\n",
       "    'Query executed successfully and returned 1 rows.',\n",
       "    'LLM Judge: RETRY (Confidence: LOW)',\n",
       "    \"Generated SQL (attempt 3): SELECT\\n    ym.Date AS PeakMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME'\\n  AND ym.Date LIKE '2013%'\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\",\n",
       "    'Query executed successfully and returned 1 rows.',\n",
       "    'LLM Judge: RETRY (Confidence: LOW)'],\n",
       "   'inference_time_ms': 31944.32,\n",
       "   'agent_trace': [{'step': 'generate_sql_attempt_1',\n",
       "     'messages': [{'role': 'system',\n",
       "       'content': 'You are a SQL expert. Your task is to convert natural language questions into accurate SQL queries using the given database schema and instructions.'},\n",
       "      {'role': 'user',\n",
       "       'content': 'Your task is to convert a natural language question into an accurate SQL query using the given sqlite database schema.\\n\\n**Question:**:\\nWhat was the gas consumption peak month for SME customers in 2013?\\n\\n**Database Engine / Dialect:**:\\nsqlite\\n\\n**Schema:**\\nTable: customers\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\\n    - Segment (TEXT) # Example values: SME, LAM, KAM\\n    - Currency (TEXT) # Example values: EUR, CZK\\n\\nTable: gasstations\\n  Columns:\\n    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\\n    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\\n    - Country (TEXT) # Example values: CZE, SVK\\n    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\\n\\nTable: products\\n  Columns:\\n    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\\n\\nTable: transactions_1k\\n  Columns:\\n    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\\n    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\\n    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\\n    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\\n    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\\n    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\\n    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\\n    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\\n\\nTable: sqlite_sequence\\n  Columns:\\n    - name (TEXT) # Example values: transactions_1k\\n    - seq (TEXT) # Example values: 1000\\n\\nTable: yearmonth\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\\n    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\\n    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\\n\\n\\n**Instructions:**\\n- Only use columns listed in the schema.\\n- Do not use any other columns or tables not mentioned in the schema.\\n- Ensure the SQL query is valid and executable.\\n- Use proper SQL syntax and conventions.\\n- Generate a complete SQL query that answers the question.\\n- Use the correct SQL dialect for the database, i.e., sqlite.\\n- Do not include any explanations or comments in the SQL output.\\n- Your output must start with ```sql and end with ```.\\n\\nQuestion: What was the gas consumption peak month for SME customers in 2013?'}],\n",
       "     'response': \"SELECT\\n    ym.Date AS PeakMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME'\\n  AND ym.Date LIKE '2013%'\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\",\n",
       "     'parsed_sql': \"SELECT\\n    ym.Date AS PeakMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME'\\n  AND ym.Date LIKE '2013%'\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\",\n",
       "     'token_usage': {'prompt_tokens': 956,\n",
       "      'completion_tokens': 344,\n",
       "      'total_tokens': 1300}},\n",
       "    {'step': 'llm_judge_validation_attempt_1',\n",
       "     'messages': [{'role': 'system',\n",
       "       'content': 'You are an expert SQL validator and data analyst. Your task is to assess whether a generated SQL query and its results correctly and accurately answer a given natural language question.'},\n",
       "      {'role': 'user',\n",
       "       'content': 'You are validating a text-to-SQL system\\'s output. Your task is to determine if the generated SQL query and its results correctly and accurately answer the user\\'s question.\\n\\n**Original Question:**\\nWhat was the gas consumption peak month for SME customers in 2013?\\n\\n**Database Type:** sqlite\\n\\n**Database Schema:**\\nTable: customers\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\\n    - Segment (TEXT) # Example values: SME, LAM, KAM\\n    - Currency (TEXT) # Example values: EUR, CZK\\n\\nTable: gasstations\\n  Columns:\\n    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\\n    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\\n    - Country (TEXT) # Example values: CZE, SVK\\n    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\\n\\nTable: products\\n  Columns:\\n    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\\n\\nTable: transactions_1k\\n  Columns:\\n    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\\n    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\\n    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\\n    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\\n    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\\n    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\\n    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\\n    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\\n\\nTable: sqlite_sequence\\n  Columns:\\n    - name (TEXT) # Example values: transactions_1k\\n    - seq (TEXT) # Example values: 1000\\n\\nTable: yearmonth\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\\n    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\\n    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\\n\\n\\n**Generated SQL Query:**\\n```sql\\nSELECT\\n    ym.Date AS PeakMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = \\'SME\\'\\n  AND ym.Date LIKE \\'2013%\\'\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\\n```\\n\\n**Query Execution Results:**\\n PeakMonth  TotalConsumption\\n    201304      126047776.92\\n\\n**Total Rows Returned:** 1\\n\\n**Your Task:**\\nCarefully analyze whether the SQL query and its results correctly and accurately answer the original question. Consider:\\n\\n1. **Query Correctness:**\\n   - Does the SQL query target the right tables and columns?\\n   - Are the JOINs, WHERE clauses, and filters appropriate for the question?\\n   - Does the query logic match what the question is asking for?\\n   - Are aggregations (COUNT, SUM, AVG, etc.) used correctly if needed?\\n   - Is the GROUP BY clause correct if aggregation is used?\\n\\n2. **Result Validation:**\\n   - Do the returned results make sense for the question?\\n   - Is the number of rows reasonable? (e.g., if asking for \"the top 5\", are there 5 or fewer rows?)\\n   - Are the column names in the result relevant to what was asked?\\n   - Do the data values look appropriate for the question?\\n\\n3. **Completeness:**\\n   - Does the query return all the information requested in the question?\\n   - Are there any missing columns or filters that should be included?\\n\\n4. **Common Issues to Check:**\\n   - Missing or incorrect filters (WHERE clauses)\\n   - Wrong aggregation level (GROUP BY issues)\\n   - Incorrect JOINs or missing tables\\n   - Wrong sorting (ORDER BY) or limits\\n   - Overly broad results (too many rows when specific answer expected)\\n   - Empty results when data should exist\\n\\n**Response Format:**\\nProvide your assessment in the following format:\\n\\nVERDICT: [ACCEPT or RETRY]\\n\\nCONFIDENCE: [HIGH, MEDIUM, or LOW]\\n\\nREASONING:\\n[Provide detailed reasoning for your decision. If RETRY, explain what seems wrong and what should be fixed.]\\n\\n**Guidelines:**\\n- Use ACCEPT if the SQL and results correctly answer the question, even if the format could be improved.\\n- Use RETRY if there are clear errors, missing information, or the results don\\'t match what was asked.\\n- Be strict but fair - minor formatting differences are acceptable, but logical errors require RETRY.\\n- If results are empty but the question suggests data should exist, consider RETRY.\\n- If you\\'re uncertain, provide MEDIUM or LOW confidence and explain your concerns.\\n'}],\n",
       "     'response': [\"VERDICT: ACCEPT  \\n\\nCONFIDENCE: HIGH  \\n\\nREASONING:  \\n- **Query targets the correct tables**: It joins `yearmonth` (which holds monthly consumption) with `customers` to filter on the SME segment.  \\n- **Filters are appropriate**: The `WHERE` clause restricts to SME customers (`c.Segment = 'SME'`) and to the year 2013 (`ym.Date LIKE '2013%'`).  \\n- **Aggregation matches the question**: `SUM(ym.Consumption)` aggregates total gas consumption per month, and `GROUP BY ym.Date` computes this for each month.  \\n- **Peak month identification**: Ordering by the summed consumption descending and limiting to 1 correctly selects the month with the highest total consumption.  \\n- **Result relevance**: The output provides the month identifier (`201304`, i.e., April\\u202f2013) and the total consumption for that month, directly answering ‚Äúwhat was the gas consumption peak month‚Äù.  \\n- **No missing information**: All required information (the peak month and its consumption) is returned.  \\n\\nThus, the SQL query correctly implements the logic needed to answer the original question, and the returned result aligns with that logic.\",\n",
       "      {'prompt_tokens': 1426, 'completion_tokens': 609, 'total_tokens': 2035}],\n",
       "     'verdict': 'RETRY',\n",
       "     'confidence': 'LOW',\n",
       "     'reasoning': [\"VERDICT: ACCEPT  \\n\\nCONFIDENCE: HIGH  \\n\\nREASONING:  \\n- **Query targets the correct tables**: It joins `yearmonth` (which holds monthly consumption) with `customers` to filter on the SME segment.  \\n- **Filters are appropriate**: The `WHERE` clause restricts to SME customers (`c.Segment = 'SME'`) and to the year 2013 (`ym.Date LIKE '2013%'`).  \\n- **Aggregation matches the question**: `SUM(ym.Consumption)` aggregates total gas consumption per month, and `GROUP BY ym.Date` computes this for each month.  \\n- **Peak month identification**: Ordering by the summed consumption descending and limiting to 1 correctly selects the month with the highest total consumption.  \\n- **Result relevance**: The output provides the month identifier (`201304`, i.e., April\\u202f2013) and the total consumption for that month, directly answering ‚Äúwhat was the gas consumption peak month‚Äù.  \\n- **No missing information**: All required information (the peak month and its consumption) is returned.  \\n\\nThus, the SQL query correctly implements the logic needed to answer the original question, and the returned result aligns with that logic.\",\n",
       "      {'prompt_tokens': 1426,\n",
       "       'completion_tokens': 609,\n",
       "       'total_tokens': 2035}]},\n",
       "    {'step': 'generate_sql_attempt_2',\n",
       "     'messages': [{'role': 'system',\n",
       "       'content': 'You are a SQL expert. Your task is to convert natural language questions into accurate SQL queries using the given database schema and instructions.'},\n",
       "      {'role': 'user',\n",
       "       'content': '**Question:** What was the gas consumption peak month for SME customers in 2013?\\n\\n**Database Type:** sqlite\\n\\n**Schema:**\\nTable: customers\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\\n    - Segment (TEXT) # Example values: SME, LAM, KAM\\n    - Currency (TEXT) # Example values: EUR, CZK\\n\\nTable: gasstations\\n  Columns:\\n    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\\n    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\\n    - Country (TEXT) # Example values: CZE, SVK\\n    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\\n\\nTable: products\\n  Columns:\\n    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\\n\\nTable: transactions_1k\\n  Columns:\\n    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\\n    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\\n    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\\n    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\\n    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\\n    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\\n    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\\n    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\\n\\nTable: sqlite_sequence\\n  Columns:\\n    - name (TEXT) # Example values: transactions_1k\\n    - seq (TEXT) # Example values: 1000\\n\\nTable: yearmonth\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\\n    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\\n    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\\n\\n\\n\\n**Previous SQL (failed):**\\n```sql\\nSELECT\\n    ym.Date AS PeakMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = \\'SME\\'\\n  AND ym.Date LIKE \\'2013%\\'\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\\n```\\n\\n**Error:**\\nLLM Judge Feedback: (\"VERDICT: ACCEPT  \\\\n\\\\nCONFIDENCE: HIGH  \\\\n\\\\nREASONING:  \\\\n- **Query targets the correct tables**: It joins `yearmonth` (which holds monthly consumption) with `customers` to filter on the SME segment.  \\\\n- **Filters are appropriate**: The `WHERE` clause restricts to SME customers (`c.Segment = \\'SME\\'`) and to the year 2013 (`ym.Date LIKE \\'2013%\\'`).  \\\\n- **Aggregation matches the question**: `SUM(ym.Consumption)` aggregates total gas consumption per month, and `GROUP BY ym.Date` computes this for each month.  \\\\n- **Peak month identification**: Ordering by the summed consumption descending and limiting to 1 correctly selects the month with the highest total consumption.  \\\\n- **Result relevance**: The output provides the month identifier (`201304`, i.e., April\\\\u202f2013) and the total consumption for that month, directly answering ‚Äúwhat was the gas consumption peak month‚Äù.  \\\\n- **No missing information**: All required information (the peak month and its consumption) is returned.  \\\\n\\\\nThus, the SQL query correctly implements the logic needed to answer the original question, and the returned result aligns with that logic.\", {\\'prompt_tokens\\': 1426, \\'completion_tokens\\': 609, \\'total_tokens\\': 2035})\\n\\n**Instructions:**\\n- Make a minimal fix to the previous SQL\\n- Only change what\\'s needed to fix the error\\n- Keep the rest of the query structure the same\\n- Only use columns and tables from the schema\\n- Use sqlite syntax\\n- Your output must start with ```sql and end with ```.\\n'}],\n",
       "     'response': 'SELECT\\n    ym.\"Date\" AS PeakMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = \\'SME\\'\\n  AND ym.\"Date\" LIKE \\'2013%\\'\\nGROUP BY ym.\"Date\"\\nORDER BY TotalConsumption DESC\\nLIMIT 1',\n",
       "     'parsed_sql': 'SELECT\\n    ym.\"Date\" AS PeakMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = \\'SME\\'\\n  AND ym.\"Date\" LIKE \\'2013%\\'\\nGROUP BY ym.\"Date\"\\nORDER BY TotalConsumption DESC\\nLIMIT 1',\n",
       "     'token_usage': {'prompt_tokens': 1265,\n",
       "      'completion_tokens': 638,\n",
       "      'total_tokens': 1903}},\n",
       "    {'step': 'llm_judge_validation_attempt_2',\n",
       "     'messages': [{'role': 'system',\n",
       "       'content': 'You are an expert SQL validator and data analyst. Your task is to assess whether a generated SQL query and its results correctly and accurately answer a given natural language question.'},\n",
       "      {'role': 'user',\n",
       "       'content': 'You are validating a text-to-SQL system\\'s output. Your task is to determine if the generated SQL query and its results correctly and accurately answer the user\\'s question.\\n\\n**Original Question:**\\nWhat was the gas consumption peak month for SME customers in 2013?\\n\\n**Database Type:** sqlite\\n\\n**Database Schema:**\\nTable: customers\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\\n    - Segment (TEXT) # Example values: SME, LAM, KAM\\n    - Currency (TEXT) # Example values: EUR, CZK\\n\\nTable: gasstations\\n  Columns:\\n    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\\n    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\\n    - Country (TEXT) # Example values: CZE, SVK\\n    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\\n\\nTable: products\\n  Columns:\\n    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\\n\\nTable: transactions_1k\\n  Columns:\\n    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\\n    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\\n    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\\n    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\\n    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\\n    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\\n    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\\n    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\\n\\nTable: sqlite_sequence\\n  Columns:\\n    - name (TEXT) # Example values: transactions_1k\\n    - seq (TEXT) # Example values: 1000\\n\\nTable: yearmonth\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\\n    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\\n    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\\n\\n\\n**Generated SQL Query:**\\n```sql\\nSELECT\\n    ym.\"Date\" AS PeakMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = \\'SME\\'\\n  AND ym.\"Date\" LIKE \\'2013%\\'\\nGROUP BY ym.\"Date\"\\nORDER BY TotalConsumption DESC\\nLIMIT 1\\n```\\n\\n**Query Execution Results:**\\n PeakMonth  TotalConsumption\\n    201304      126047776.92\\n\\n**Total Rows Returned:** 1\\n\\n**Your Task:**\\nCarefully analyze whether the SQL query and its results correctly and accurately answer the original question. Consider:\\n\\n1. **Query Correctness:**\\n   - Does the SQL query target the right tables and columns?\\n   - Are the JOINs, WHERE clauses, and filters appropriate for the question?\\n   - Does the query logic match what the question is asking for?\\n   - Are aggregations (COUNT, SUM, AVG, etc.) used correctly if needed?\\n   - Is the GROUP BY clause correct if aggregation is used?\\n\\n2. **Result Validation:**\\n   - Do the returned results make sense for the question?\\n   - Is the number of rows reasonable? (e.g., if asking for \"the top 5\", are there 5 or fewer rows?)\\n   - Are the column names in the result relevant to what was asked?\\n   - Do the data values look appropriate for the question?\\n\\n3. **Completeness:**\\n   - Does the query return all the information requested in the question?\\n   - Are there any missing columns or filters that should be included?\\n\\n4. **Common Issues to Check:**\\n   - Missing or incorrect filters (WHERE clauses)\\n   - Wrong aggregation level (GROUP BY issues)\\n   - Incorrect JOINs or missing tables\\n   - Wrong sorting (ORDER BY) or limits\\n   - Overly broad results (too many rows when specific answer expected)\\n   - Empty results when data should exist\\n\\n**Response Format:**\\nProvide your assessment in the following format:\\n\\nVERDICT: [ACCEPT or RETRY]\\n\\nCONFIDENCE: [HIGH, MEDIUM, or LOW]\\n\\nREASONING:\\n[Provide detailed reasoning for your decision. If RETRY, explain what seems wrong and what should be fixed.]\\n\\n**Guidelines:**\\n- Use ACCEPT if the SQL and results correctly answer the question, even if the format could be improved.\\n- Use RETRY if there are clear errors, missing information, or the results don\\'t match what was asked.\\n- Be strict but fair - minor formatting differences are acceptable, but logical errors require RETRY.\\n- If results are empty but the question suggests data should exist, consider RETRY.\\n- If you\\'re uncertain, provide MEDIUM or LOW confidence and explain your concerns.\\n'}],\n",
       "     'response': ['VERDICT: ACCEPT  \\n\\nCONFIDENCE: HIGH  \\n\\nREASONING:  \\n- **Correct tables/columns:** The query joins `yearmonth` (which holds monthly consumption) with `customers` to filter on the SME segment, exactly matching the requirement.  \\n- **Appropriate filtering:** It limits the data to the year 2013 using `LIKE \\'2013%\\'` and to SME customers via `c.Segment = \\'SME\\'`.  \\n- **Aggregation logic:** It aggregates (`SUM`) consumption per month, groups by the month (`ym.\"Date\"`), orders by the summed consumption in descending order, and picks the top‚Äëmost row with `LIMIT 1`. This directly yields the month with the highest total gas consumption for SME customers in 2013.  \\n- **Result relevance:** The single returned row provides the month (`201304`) and the corresponding total consumption, which answers the question ‚Äúwhat was the gas consumption peak month‚Äù.  \\n- **No missing information or logical errors:** All required filters are present, the grouping level is correct, and the ordering/limit correctly isolates the peak month.  \\n\\nThus the SQL query correctly implements the requested analysis and the result appropriately answers the original question.',\n",
       "      {'prompt_tokens': 1431, 'completion_tokens': 622, 'total_tokens': 2053}],\n",
       "     'verdict': 'RETRY',\n",
       "     'confidence': 'LOW',\n",
       "     'reasoning': ['VERDICT: ACCEPT  \\n\\nCONFIDENCE: HIGH  \\n\\nREASONING:  \\n- **Correct tables/columns:** The query joins `yearmonth` (which holds monthly consumption) with `customers` to filter on the SME segment, exactly matching the requirement.  \\n- **Appropriate filtering:** It limits the data to the year 2013 using `LIKE \\'2013%\\'` and to SME customers via `c.Segment = \\'SME\\'`.  \\n- **Aggregation logic:** It aggregates (`SUM`) consumption per month, groups by the month (`ym.\"Date\"`), orders by the summed consumption in descending order, and picks the top‚Äëmost row with `LIMIT 1`. This directly yields the month with the highest total gas consumption for SME customers in 2013.  \\n- **Result relevance:** The single returned row provides the month (`201304`) and the corresponding total consumption, which answers the question ‚Äúwhat was the gas consumption peak month‚Äù.  \\n- **No missing information or logical errors:** All required filters are present, the grouping level is correct, and the ordering/limit correctly isolates the peak month.  \\n\\nThus the SQL query correctly implements the requested analysis and the result appropriately answers the original question.',\n",
       "      {'prompt_tokens': 1431,\n",
       "       'completion_tokens': 622,\n",
       "       'total_tokens': 2053}]},\n",
       "    {'step': 'generate_sql_attempt_3',\n",
       "     'messages': [{'role': 'system',\n",
       "       'content': 'You are a SQL expert. Your task is to convert natural language questions into accurate SQL queries using the given database schema and instructions.'},\n",
       "      {'role': 'user',\n",
       "       'content': '**Question:** What was the gas consumption peak month for SME customers in 2013?\\n\\n**Database Type:** sqlite\\n\\n**Schema:**\\nTable: customers\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\\n    - Segment (TEXT) # Example values: SME, LAM, KAM\\n    - Currency (TEXT) # Example values: EUR, CZK\\n\\nTable: gasstations\\n  Columns:\\n    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\\n    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\\n    - Country (TEXT) # Example values: CZE, SVK\\n    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\\n\\nTable: products\\n  Columns:\\n    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\\n\\nTable: transactions_1k\\n  Columns:\\n    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\\n    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\\n    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\\n    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\\n    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\\n    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\\n    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\\n    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\\n\\nTable: sqlite_sequence\\n  Columns:\\n    - name (TEXT) # Example values: transactions_1k\\n    - seq (TEXT) # Example values: 1000\\n\\nTable: yearmonth\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\\n    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\\n    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\\n\\n\\n\\n**Previous SQL (failed):**\\n```sql\\nSELECT\\n    ym.\"Date\" AS PeakMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = \\'SME\\'\\n  AND ym.\"Date\" LIKE \\'2013%\\'\\nGROUP BY ym.\"Date\"\\nORDER BY TotalConsumption DESC\\nLIMIT 1\\n```\\n\\n**Error:**\\nLLM Judge Feedback: (\\'VERDICT: ACCEPT  \\\\n\\\\nCONFIDENCE: HIGH  \\\\n\\\\nREASONING:  \\\\n- **Correct tables/columns:** The query joins `yearmonth` (which holds monthly consumption) with `customers` to filter on the SME segment, exactly matching the requirement.  \\\\n- **Appropriate filtering:** It limits the data to the year 2013 using `LIKE \\\\\\'2013%\\\\\\'` and to SME customers via `c.Segment = \\\\\\'SME\\\\\\'`.  \\\\n- **Aggregation logic:** It aggregates (`SUM`) consumption per month, groups by the month (`ym.\"Date\"`), orders by the summed consumption in descending order, and picks the top‚Äëmost row with `LIMIT 1`. This directly yields the month with the highest total gas consumption for SME customers in 2013.  \\\\n- **Result relevance:** The single returned row provides the month (`201304`) and the corresponding total consumption, which answers the question ‚Äúwhat was the gas consumption peak month‚Äù.  \\\\n- **No missing information or logical errors:** All required filters are present, the grouping level is correct, and the ordering/limit correctly isolates the peak month.  \\\\n\\\\nThus the SQL query correctly implements the requested analysis and the result appropriately answers the original question.\\', {\\'prompt_tokens\\': 1431, \\'completion_tokens\\': 622, \\'total_tokens\\': 2053})\\n\\n**Instructions:**\\n- Make a minimal fix to the previous SQL\\n- Only change what\\'s needed to fix the error\\n- Keep the rest of the query structure the same\\n- Only use columns and tables from the schema\\n- Use sqlite syntax\\n- Your output must start with ```sql and end with ```.\\n'}],\n",
       "     'response': \"SELECT\\n    ym.Date AS PeakMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME'\\n  AND ym.Date LIKE '2013%'\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\",\n",
       "     'parsed_sql': \"SELECT\\n    ym.Date AS PeakMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME'\\n  AND ym.Date LIKE '2013%'\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\",\n",
       "     'token_usage': {'prompt_tokens': 1264,\n",
       "      'completion_tokens': 289,\n",
       "      'total_tokens': 1553}},\n",
       "    {'step': 'llm_judge_validation_attempt_3',\n",
       "     'messages': [{'role': 'system',\n",
       "       'content': 'You are an expert SQL validator and data analyst. Your task is to assess whether a generated SQL query and its results correctly and accurately answer a given natural language question.'},\n",
       "      {'role': 'user',\n",
       "       'content': 'You are validating a text-to-SQL system\\'s output. Your task is to determine if the generated SQL query and its results correctly and accurately answer the user\\'s question.\\n\\n**Original Question:**\\nWhat was the gas consumption peak month for SME customers in 2013?\\n\\n**Database Type:** sqlite\\n\\n**Database Schema:**\\nTable: customers\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\\n    - Segment (TEXT) # Example values: SME, LAM, KAM\\n    - Currency (TEXT) # Example values: EUR, CZK\\n\\nTable: gasstations\\n  Columns:\\n    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\\n    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\\n    - Country (TEXT) # Example values: CZE, SVK\\n    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\\n\\nTable: products\\n  Columns:\\n    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\\n\\nTable: transactions_1k\\n  Columns:\\n    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\\n    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\\n    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\\n    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\\n    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\\n    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\\n    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\\n    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\\n\\nTable: sqlite_sequence\\n  Columns:\\n    - name (TEXT) # Example values: transactions_1k\\n    - seq (TEXT) # Example values: 1000\\n\\nTable: yearmonth\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\\n    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\\n    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\\n\\n\\n**Generated SQL Query:**\\n```sql\\nSELECT\\n    ym.Date AS PeakMonth,\\n    SUM(ym.Consumption) AS TotalConsumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = \\'SME\\'\\n  AND ym.Date LIKE \\'2013%\\'\\nGROUP BY ym.Date\\nORDER BY TotalConsumption DESC\\nLIMIT 1\\n```\\n\\n**Query Execution Results:**\\n PeakMonth  TotalConsumption\\n    201304      126047776.92\\n\\n**Total Rows Returned:** 1\\n\\n**Your Task:**\\nCarefully analyze whether the SQL query and its results correctly and accurately answer the original question. Consider:\\n\\n1. **Query Correctness:**\\n   - Does the SQL query target the right tables and columns?\\n   - Are the JOINs, WHERE clauses, and filters appropriate for the question?\\n   - Does the query logic match what the question is asking for?\\n   - Are aggregations (COUNT, SUM, AVG, etc.) used correctly if needed?\\n   - Is the GROUP BY clause correct if aggregation is used?\\n\\n2. **Result Validation:**\\n   - Do the returned results make sense for the question?\\n   - Is the number of rows reasonable? (e.g., if asking for \"the top 5\", are there 5 or fewer rows?)\\n   - Are the column names in the result relevant to what was asked?\\n   - Do the data values look appropriate for the question?\\n\\n3. **Completeness:**\\n   - Does the query return all the information requested in the question?\\n   - Are there any missing columns or filters that should be included?\\n\\n4. **Common Issues to Check:**\\n   - Missing or incorrect filters (WHERE clauses)\\n   - Wrong aggregation level (GROUP BY issues)\\n   - Incorrect JOINs or missing tables\\n   - Wrong sorting (ORDER BY) or limits\\n   - Overly broad results (too many rows when specific answer expected)\\n   - Empty results when data should exist\\n\\n**Response Format:**\\nProvide your assessment in the following format:\\n\\nVERDICT: [ACCEPT or RETRY]\\n\\nCONFIDENCE: [HIGH, MEDIUM, or LOW]\\n\\nREASONING:\\n[Provide detailed reasoning for your decision. If RETRY, explain what seems wrong and what should be fixed.]\\n\\n**Guidelines:**\\n- Use ACCEPT if the SQL and results correctly answer the question, even if the format could be improved.\\n- Use RETRY if there are clear errors, missing information, or the results don\\'t match what was asked.\\n- Be strict but fair - minor formatting differences are acceptable, but logical errors require RETRY.\\n- If results are empty but the question suggests data should exist, consider RETRY.\\n- If you\\'re uncertain, provide MEDIUM or LOW confidence and explain your concerns.\\n'}],\n",
       "     'response': [\"VERDICT: ACCEPT\\n\\nCONFIDENCE: HIGH\\n\\nREASONING:\\n- The query correctly joins the **yearmonth** table (which holds monthly consumption) with **customers** to filter only SME segment customers.\\n- It filters the dates to the year 2013 with `ym.Date LIKE '2013%'`, which matches the required year.\\n- It aggregates consumption per month (`SUM(ym.Consumption)`) and orders the totals descending, selecting the top‚Äëmost month with `LIMIT 1`. This directly answers ‚Äúthe gas consumption peak month‚Äù.\\n- The returned result provides the month (`201304`) and the total consumption for that month, which is exactly the information requested (the month; the extra total consumption value is harmless).\\n- No missing filters, incorrect joins, or aggregation mistakes are apparent.\\n\\nTherefore, the SQL and its result accurately answer the original question.\",\n",
       "      {'prompt_tokens': 1426, 'completion_tokens': 474, 'total_tokens': 1900}],\n",
       "     'verdict': 'RETRY',\n",
       "     'confidence': 'LOW',\n",
       "     'reasoning': [\"VERDICT: ACCEPT\\n\\nCONFIDENCE: HIGH\\n\\nREASONING:\\n- The query correctly joins the **yearmonth** table (which holds monthly consumption) with **customers** to filter only SME segment customers.\\n- It filters the dates to the year 2013 with `ym.Date LIKE '2013%'`, which matches the required year.\\n- It aggregates consumption per month (`SUM(ym.Consumption)`) and orders the totals descending, selecting the top‚Äëmost month with `LIMIT 1`. This directly answers ‚Äúthe gas consumption peak month‚Äù.\\n- The returned result provides the month (`201304`) and the total consumption for that month, which is exactly the information requested (the month; the extra total consumption value is harmless).\\n- No missing filters, incorrect joins, or aggregation mistakes are apparent.\\n\\nTherefore, the SQL and its result accurately answer the original question.\",\n",
       "      {'prompt_tokens': 1426,\n",
       "       'completion_tokens': 474,\n",
       "       'total_tokens': 1900}]}],\n",
       "   'token_usage': {'prompt_tokens': 3485,\n",
       "    'completion_tokens': 1271,\n",
       "    'total_tokens': 4756},\n",
       "   'token_usage_per_attempt': [{'prompt_tokens': 956,\n",
       "     'completion_tokens': 344,\n",
       "     'total_tokens': 1300},\n",
       "    {'prompt_tokens': 1265, 'completion_tokens': 638, 'total_tokens': 1903},\n",
       "    {'prompt_tokens': 1264, 'completion_tokens': 289, 'total_tokens': 1553}],\n",
       "   'logic_sql': \"SELECT SUBSTRING(T2.Date, 5, 2) FROM yearmonth AS ym JOIN customers AS c ON ym.CustomerID = c.CustomerID WHERE c.Segment = 'SME' AND ym.Date LIKE '2013%' GROUP BY ym.Date ORDER BY TotalConsumption DESC LIMIT 1\",\n",
       "   'logic_sql_execution_error': 'Error running SQL: Error running query: no such column: T2.Date',\n",
       "   'logic_execution_time_ms': None,\n",
       "   'evaluation': {'df_error_message': None,\n",
       "    'execution_accuracy': 0,\n",
       "    'non_empty_execution_accuracy': 0,\n",
       "    'subset_non_empty_execution_accuracy': 0,\n",
       "    'logic_execution_accuracy': 0,\n",
       "    'bird_execution_accuracy': 0,\n",
       "    'is_sqlglot_parsable': 1,\n",
       "    'is_sqlparse_parsable': 1,\n",
       "    'sqlglot_equivalence': 0,\n",
       "    'sqlglot_optimized_equivalence': 0,\n",
       "    'sqlparse_equivalence': 0,\n",
       "    'sql_exact_match': 0,\n",
       "    'sql_syntactic_equivalence': 0,\n",
       "    'eval_error': 0,\n",
       "    'df_error': 1,\n",
       "    'prompt_tokens': 3485,\n",
       "    'completion_tokens': 1271,\n",
       "    'total_tokens': 4756,\n",
       "    'inference_time_ms': 31944.32,\n",
       "    'llm_score': 0.0,\n",
       "    'llm_explanation': 'N/A (did not use LLM due to missing prediction dataframe)'}},\n",
       "  'wxai:openai/gpt-oss-120b-agentic-baseline4-3attempts': {'predicted_sql': \"SELECT ym.Date AS month, SUM(ym.Consumption) AS total_consumption\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME'\\n  AND ym.Date LIKE '2013%'\\nGROUP BY ym.Date\\nORDER BY total_consumption DESC\\nLIMIT 1;\",\n",
       "   'predicted_df': '{\"columns\":[\"month\",\"total_consumption\"],\"index\":[0],\"data\":[[201304,126047776.9200000018]]}',\n",
       "   'sql_execution_error': None,\n",
       "   'model_name': 'wxai:openai/gpt-oss-120b',\n",
       "   'model_parameters': {'decoding_method': 'greedy',\n",
       "    'max_new_tokens': 1024,\n",
       "    'stop_sequences': []},\n",
       "   'agent_attempts': 2,\n",
       "   'agent_reasoning': [\"[Action 1] We need to sum monthly consumption for SME customers in 2013 and return the month with the highest total. This requires joining yearmonth with customers, filtering Segment='SME' and Date starting with '2013', grouping by month, ordering by total consumption descending, and limiting to one row.\",\n",
       "    '[Action 2] The query successfully returned the month with the highest total consumption for SME customers in 2013. I will now submit the final answer with the SQL query and a brief explanation.',\n",
       "    'Final answer submitted with high confidence: The query joins the yearmonth table with customers to filter for SME segment, restricts rows to the year 2013, aggregates consumption per month, orders by total consumption descending, and returns the top month, which is the consumption peak month for SME customers in 2013.'],\n",
       "   'inference_time_ms': 91275.5,\n",
       "   'agent_trace': [{'action_num': 1,\n",
       "     'messages': [{'role': 'system',\n",
       "       'content': 'You are an expert SQL agent tasked with converting natural language questions into SQL queries.\\n\\nYou have access to the following tools that let you interact with the database:\\n\\n1. **probe_schema**(table_name: str, reason: str)\\n   - Query the database to get detailed schema information about a specific table\\n   - Use when you need to know exact column names, data types, or sample data\\n   \\n2. **generate_sql**(sql: str, reasoning: str)\\n   - Generate and execute a SQL query\\n   - The query will be automatically executed and you\\'ll get results or errors\\n   \\n3. **analyze_error**(analysis: str, fixable: bool)\\n   - Analyze an error from a failed SQL query\\n   - Determine what went wrong and if it can be fixed\\n   \\n4. **submit_final_answer**(sql: str, confidence: \"high\"|\"medium\"|\"low\", explanation: str)\\n   - Submit your final SQL query\\n   - Use when you have a working query or have exhausted attempts\\n\\n**Database Schema:**\\nTable: customers\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\\n    - Segment (TEXT) # Example values: SME, LAM, KAM\\n    - Currency (TEXT) # Example values: EUR, CZK\\n\\nTable: gasstations\\n  Columns:\\n    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\\n    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\\n    - Country (TEXT) # Example values: CZE, SVK\\n    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\\n\\nTable: products\\n  Columns:\\n    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\\n\\nTable: transactions_1k\\n  Columns:\\n    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\\n    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\\n    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\\n    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\\n    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\\n    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\\n    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\\n    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\\n\\nTable: sqlite_sequence\\n  Columns:\\n    - name (TEXT) # Example values: transactions_1k\\n    - seq (TEXT) # Example values: 1000\\n\\nTable: yearmonth\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\\n    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\\n    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\\n\\n\\n**Instructions:**\\n1. Think step-by-step using a ReAct (Reasoning + Acting) approach\\n2. You must respond with ONLY a JSON object in this exact format:\\n   {\\n     \"thought\": \"Your reasoning about what to do next\",\\n     \"action\": \"tool_name\",\\n     \"action_input\": {...tool parameters...}\\n   }\\n\\n3. After each action, you\\'ll receive the result and can choose your next action\\n4. You have 3 total attempts - use them wisely\\n5. Always start by generating SQL unless you\\'re missing critical schema information\\n\\n**Example Response Format:**\\n{\\n  \"thought\": \"I need to find the average salary by department. The schema shows a salary column in the employees table and a department_id. I\\'ll write a GROUP BY query.\",\\n  \"action\": \"generate_sql\",\\n  \"action_input\": {\\n    \"sql\": \"SELECT department_id, AVG(salary) FROM employees GROUP BY department_id\",\\n    \"reasoning\": \"Grouping by department and calculating average salary\"\\n  }\\n}\\n\\nRemember: Respond ONLY with valid JSON. No extra text before or after.'},\n",
       "      {'role': 'user',\n",
       "       'content': 'Question: What was the gas consumption peak month for SME customers in 2013?\\n\\nPlease help me write the SQL query to answer this question.'}],\n",
       "     'response': '{\\n  \"thought\": \"We need to sum monthly consumption for SME customers in 2013 and return the month with the highest total. This requires joining yearmonth with customers, filtering Segment=\\'SME\\' and Date starting with \\'2013\\', grouping by month, ordering by total consumption descending, and limiting to one row.\",\\n  \"action\": \"generate_sql\",\\n  \"action_input\": {\\n    \"sql\": \"SELECT ym.Date AS month, SUM(ym.Consumption) AS total_consumption\\\\nFROM yearmonth ym\\\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\\\nWHERE c.Segment = \\'SME\\'\\\\n  AND ym.Date LIKE \\'2013%\\'\\\\nGROUP BY ym.Date\\\\nORDER BY total_consumption DESC\\\\nLIMIT 1;\",\\n    \"reasoning\": \"Join yearmonth with customers to filter SME segment, restrict to 2013 months, aggregate consumption per month, then select the month with the highest consumption.\"\\n  }\\n}',\n",
       "     'token_usage': {'prompt_tokens': 1231,\n",
       "      'completion_tokens': 412,\n",
       "      'total_tokens': 1643}},\n",
       "    {'action_num': 2,\n",
       "     'messages': [{'role': 'system',\n",
       "       'content': 'You are an expert SQL agent tasked with converting natural language questions into SQL queries.\\n\\nYou have access to the following tools that let you interact with the database:\\n\\n1. **probe_schema**(table_name: str, reason: str)\\n   - Query the database to get detailed schema information about a specific table\\n   - Use when you need to know exact column names, data types, or sample data\\n   \\n2. **generate_sql**(sql: str, reasoning: str)\\n   - Generate and execute a SQL query\\n   - The query will be automatically executed and you\\'ll get results or errors\\n   \\n3. **analyze_error**(analysis: str, fixable: bool)\\n   - Analyze an error from a failed SQL query\\n   - Determine what went wrong and if it can be fixed\\n   \\n4. **submit_final_answer**(sql: str, confidence: \"high\"|\"medium\"|\"low\", explanation: str)\\n   - Submit your final SQL query\\n   - Use when you have a working query or have exhausted attempts\\n\\n**Database Schema:**\\nTable: customers\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\\n    - Segment (TEXT) # Example values: SME, LAM, KAM\\n    - Currency (TEXT) # Example values: EUR, CZK\\n\\nTable: gasstations\\n  Columns:\\n    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\\n    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\\n    - Country (TEXT) # Example values: CZE, SVK\\n    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\\n\\nTable: products\\n  Columns:\\n    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\\n\\nTable: transactions_1k\\n  Columns:\\n    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\\n    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\\n    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\\n    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\\n    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\\n    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\\n    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\\n    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\\n\\nTable: sqlite_sequence\\n  Columns:\\n    - name (TEXT) # Example values: transactions_1k\\n    - seq (TEXT) # Example values: 1000\\n\\nTable: yearmonth\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\\n    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\\n    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\\n\\n\\n**Instructions:**\\n1. Think step-by-step using a ReAct (Reasoning + Acting) approach\\n2. You must respond with ONLY a JSON object in this exact format:\\n   {\\n     \"thought\": \"Your reasoning about what to do next\",\\n     \"action\": \"tool_name\",\\n     \"action_input\": {...tool parameters...}\\n   }\\n\\n3. After each action, you\\'ll receive the result and can choose your next action\\n4. You have 3 total attempts - use them wisely\\n5. Always start by generating SQL unless you\\'re missing critical schema information\\n\\n**Example Response Format:**\\n{\\n  \"thought\": \"I need to find the average salary by department. The schema shows a salary column in the employees table and a department_id. I\\'ll write a GROUP BY query.\",\\n  \"action\": \"generate_sql\",\\n  \"action_input\": {\\n    \"sql\": \"SELECT department_id, AVG(salary) FROM employees GROUP BY department_id\",\\n    \"reasoning\": \"Grouping by department and calculating average salary\"\\n  }\\n}\\n\\nRemember: Respond ONLY with valid JSON. No extra text before or after.'},\n",
       "      {'role': 'user',\n",
       "       'content': 'Question: What was the gas consumption peak month for SME customers in 2013?\\n\\nPlease help me write the SQL query to answer this question.'},\n",
       "      {'role': 'assistant',\n",
       "       'content': '{\\n  \"thought\": \"We need to sum monthly consumption for SME customers in 2013 and return the month with the highest total. This requires joining yearmonth with customers, filtering Segment=\\'SME\\' and Date starting with \\'2013\\', grouping by month, ordering by total consumption descending, and limiting to one row.\",\\n  \"action\": \"generate_sql\",\\n  \"action_input\": {\\n    \"sql\": \"SELECT ym.Date AS month, SUM(ym.Consumption) AS total_consumption\\\\nFROM yearmonth ym\\\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\\\nWHERE c.Segment = \\'SME\\'\\\\n  AND ym.Date LIKE \\'2013%\\'\\\\nGROUP BY ym.Date\\\\nORDER BY total_consumption DESC\\\\nLIMIT 1;\",\\n    \"reasoning\": \"Join yearmonth with customers to filter SME segment, restrict to 2013 months, aggregate consumption per month, then select the month with the highest consumption.\"\\n  }\\n}'},\n",
       "      {'role': 'user',\n",
       "       'content': \"Observation: ‚úÖ Success! Query executed successfully.\\nRows returned: 1\\nResult preview: \\n\\nWhat's your next action?\"}],\n",
       "     'response': '{\\n  \"thought\": \"The query successfully returned the month with the highest total consumption for SME customers in 2013. I will now submit the final answer with the SQL query and a brief explanation.\",\\n  \"action\": \"submit_final_answer\",\\n  \"action_input\": {\\n    \"sql\": \"SELECT ym.Date AS month, SUM(ym.Consumption) AS total_consumption\\\\nFROM yearmonth ym\\\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\\\nWHERE c.Segment = \\'SME\\'\\\\n  AND ym.Date LIKE \\'2013%\\'\\\\nGROUP BY ym.Date\\\\nORDER BY total_consumption DESC\\\\nLIMIT 1;\",\\n    \"confidence\": \"high\",\\n    \"explanation\": \"The query joins the yearmonth table with customers to filter for SME segment, restricts rows to the year 2013, aggregates consumption per month, orders by total consumption descending, and returns the top month, which is the consumption peak month for SME customers in 2013.\"\\n  }\\n}',\n",
       "     'token_usage': {'prompt_tokens': 1459,\n",
       "      'completion_tokens': 294,\n",
       "      'total_tokens': 1753}}],\n",
       "   'token_usage': {'prompt_tokens': 2690,\n",
       "    'completion_tokens': 706,\n",
       "    'total_tokens': 3396},\n",
       "   'token_usage_per_attempt': [{'prompt_tokens': 1231,\n",
       "     'completion_tokens': 412,\n",
       "     'total_tokens': 1643},\n",
       "    {'prompt_tokens': 1459, 'completion_tokens': 294, 'total_tokens': 1753}],\n",
       "   'logic_sql': \"SELECT SUBSTRING(T2.Date, 5, 2) FROM yearmonth AS ym JOIN customers AS c ON ym.CustomerID = c.CustomerID WHERE c.Segment = 'SME' AND ym.Date LIKE '2013%' GROUP BY ym.Date ORDER BY total_consumption DESC LIMIT 1\",\n",
       "   'logic_sql_execution_error': 'Error running SQL: Error running query: no such column: T2.Date',\n",
       "   'logic_execution_time_ms': None,\n",
       "   'evaluation': {'execution_accuracy': 0,\n",
       "    'non_empty_execution_accuracy': 0,\n",
       "    'subset_non_empty_execution_accuracy': 0,\n",
       "    'logic_execution_accuracy': 0,\n",
       "    'bird_execution_accuracy': 0,\n",
       "    'is_sqlglot_parsable': 1,\n",
       "    'is_sqlparse_parsable': 1,\n",
       "    'sqlglot_equivalence': 0,\n",
       "    'sqlglot_optimized_equivalence': 0,\n",
       "    'sqlparse_equivalence': 0,\n",
       "    'sql_exact_match': 0,\n",
       "    'sql_syntactic_equivalence': 0,\n",
       "    'eval_error': 0,\n",
       "    'df_error': 0,\n",
       "    'prompt_tokens': 2690,\n",
       "    'completion_tokens': 706,\n",
       "    'total_tokens': 3396,\n",
       "    'inference_time_ms': 91275.5,\n",
       "    'llm_score': 1.0,\n",
       "    'llm_explanation': 'Yes\\n\\nThe predicted SQL query is correct. It joins the `yearmonth` and `customers` tables on `CustomerID`, filters for SME customers in 2013, groups the results by month, and orders them by total consumption in descending order, finally limiting the output to the top row, which corresponds to the month with the highest total consumption.\\n\\nThe predicted result matches the expected format, providing the month with the highest consumption and the total consumption for that month. Although the ground truth SQL uses a different approach to extract the month from the date (using `SUBSTR`), the predicted SQL achieves the same goal by using the `LIKE` operator to filter dates starting with \\'2013\\' and grouping by the full date, which implicitly includes the month.\\n\\nThe key difference between the ground truth and predicted SQL is how they handle the date. The ground truth SQL extracts the month as a two-digit value (e.g., \\'04\\' for April), while the predicted SQL keeps the full date format (e.g., \\'201304\\'). However, both approaches correctly identify the peak consumption month for SME customers in 2013.\\n\\nGiven that the predicted SQL query accurately answers the natural language question and the result aligns with the expected outcome, despite minor differences in implementation, the verdict is \"Yes\". The predicted SQL is a reasonable interpretation and achieves the desired result. \\n\\nNote: The minor differences in date handling do not affect the correctness of identifying the peak month, as both methods effectively isolate the month of interest within the specified year. \\n\\nTherefore, the predicted SQL query is deemed correct based on its ability to accurately answer the question posed. \\n\\nThe final answer is: $\\\\boxed{Yes}$'}},\n",
       "  'wxai:openai/gpt-oss-120b-agentic-baseline5-3attempts': {'predicted_sql': \"SELECT SUBSTR(ym.Date, 5, 2) AS month\\nFROM yearmonth ym\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\nWHERE c.Segment = 'SME' AND SUBSTR(ym.Date, 1, 4) = '2013'\\nGROUP BY SUBSTR(ym.Date, 5, 2)\\nORDER BY SUM(ym.Consumption) DESC\\nLIMIT 1;\",\n",
       "   'predicted_df': '{\"columns\":[\"month\"],\"index\":[0],\"data\":[[4]]}',\n",
       "   'sql_execution_error': None,\n",
       "   'model_name': 'wxai:openai/gpt-oss-120b',\n",
       "   'model_parameters': {'decoding_method': 'greedy',\n",
       "    'max_new_tokens': 1024,\n",
       "    'stop_sequences': []},\n",
       "   'agent_attempts': 1,\n",
       "   'agent_reasoning': [\"[Action 1] The question asks for the month (peak month) when gas consumption was highest for SME customers in 2013. I need to understand the schema of the 'yearmonth' table, especially the format of its Date column, to extract the year and month correctly.\",\n",
       "    'Probed database for additional schema information',\n",
       "    '[Action 2] Using the yearmonth table (Date stored as YYYYMM) joined with customers to filter SME segment and year 2013, I will sum consumption per month, order descending, and return only the month (MM) of the peak.',\n",
       "    'Final answer submitted with high confidence: Extracts month (MM) from the YYYYMM date string, filters SME customers for 2013, aggregates consumption per month, and returns only the month with the highest total consumption.'],\n",
       "   'inference_time_ms': 77447.82,\n",
       "   'agent_trace': [{'action_num': 1,\n",
       "     'messages': [{'role': 'system',\n",
       "       'content': 'You are an expert SQL agent tasked with converting natural language questions into SQL queries.\\n\\n‚ö†Ô∏è IMPORTANT: Take a systematic, multi-step approach. Submitting on your first try is rarely optimal - you have 3 attempts, use them to explore, validate, and refine!\\n\\n**SYSTEMATIC PROCESS (Follow These Steps):**\\n\\n1. **ANALYZE** - Understand exactly what the question is asking\\n   - What specific data is requested?\\n   - What is the expected format of the answer?\\n   - Are there any implicit requirements (e.g., \"which month\" means return ONLY month, not full date)?\\n\\n2. **EXPLORE** - Use probe_schema to understand the database\\n   - ALWAYS probe relevant tables before generating SQL\\n   - Understand column formats (e.g., is Date stored as YYYYMM string or timestamp?)\\n   - Verify table/column names and data types\\n   - Check for sample data if unsure\\n\\n3. **PLAN** - Think through your SQL logic\\n   - What tables do I need?\\n   - What joins are required?\\n   - What filters/aggregations?\\n   - **CRITICAL:** What columns should the SELECT return? (No extras!)\\n\\n4. **GENERATE** - Create the SQL query\\n   - Write clean, correct SQL\\n   - Match the database dialect\\n\\n5. **VALIDATE** - Before submitting, check:\\n   ‚òê Does SELECT return ONLY what the question asks for?\\n   ‚òê No extra columns (like intermediate calculations)?\\n   ‚òê Correct granularity (e.g., month vs full date)?\\n   ‚òê Proper aggregation level?\\n   ‚òê Correct ordering if question asks for \"first\", \"highest\", \"least\", etc.?\\n\\n6. **SUBMIT** - Only when confident\\n\\n**Available Tools:**\\n\\n1. **probe_schema**(table_name: str, reason: str)\\n   - Query database for detailed schema information about a table\\n   - **USE THIS FIRST** before generating SQL\\n   - Helps understand column formats, types, and sample data\\n\\n2. **generate_sql**(sql: str, reasoning: str)\\n   - Generate and execute a SQL query\\n   - Will be automatically executed and you\\'ll get results or errors\\n\\n3. **analyze_error**(analysis: str, fixable: bool)\\n   - Analyze errors from failed SQL queries\\n   - Determine what went wrong and if it\\'s fixable\\n\\n4. **submit_final_answer**(sql: str, confidence: \"high\"|\"medium\"|\"low\", explanation: str)\\n   - Submit your final SQL query\\n   - Only use after validation or when attempts exhausted\\n\\n**Database Schema (High-Level Overview):**\\nTable: customers\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\\n    - Segment (TEXT) # Example values: SME, LAM, KAM\\n    - Currency (TEXT) # Example values: EUR, CZK\\n\\nTable: gasstations\\n  Columns:\\n    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\\n    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\\n    - Country (TEXT) # Example values: CZE, SVK\\n    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\\n\\nTable: products\\n  Columns:\\n    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\\n\\nTable: transactions_1k\\n  Columns:\\n    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\\n    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\\n    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\\n    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\\n    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\\n    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\\n    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\\n    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\\n\\nTable: sqlite_sequence\\n  Columns:\\n    - name (TEXT) # Example values: transactions_1k\\n    - seq (TEXT) # Example values: 1000\\n\\nTable: yearmonth\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\\n    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\\n    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\\n\\n\\n**Column Selection Rules (CRITICAL):**\\n- If question asks \"which month?\", return ONLY the month column (not month + count/consumption)\\n- If question asks \"who?\", return ONLY the identifier (CustomerID, not CustomerID + aggregate)\\n- If question asks \"how many?\", return ONLY the count (not count + other columns)\\n- Match the question\\'s specificity exactly\\n- Use SUBSTR, DATE functions as needed to extract specific parts (e.g., month from YYYYMM)\\n\\n**Response Format:**\\nYou MUST respond with ONLY a JSON object:\\n{\\n  \"thought\": \"Before taking action, I need to [what I\\'m trying to learn/accomplish]. This will help me [why this is the right step].\",\\n  \"action\": \"tool_name\",\\n  \"action_input\": {...tool parameters...}\\n}\\n\\n**Example Good Flow:**\\nStep 1:\\n{\\n  \"thought\": \"The question asks about \\'peak month for SME customers in 2013\\'. Before generating SQL, I need to understand how the Date column is formatted in the yearmonth table - is it YYYYMM string, full timestamp, or separate year/month columns? This will help me write the correct date extraction logic.\",\\n  \"action\": \"probe_schema\",\\n  \"action_input\": {\\n    \"table_name\": \"yearmonth\",\\n    \"reason\": \"Need to understand Date column format to extract month correctly\"\\n  }\\n}\\n\\nStep 2 (after seeing Date is YYYYMM string):\\n{\\n  \"thought\": \"Now I know Date is stored as YYYYMM string like \\'201301\\'. The question asks \\'what was the peak month\\' so I need to return ONLY the month (MM), not the full date or consumption amount. I\\'ll use SUBSTR(Date, 5, 2) to extract just the month digits, filter for SME and 2013, group by month, order by total consumption DESC, and LIMIT 1.\",\\n  \"action\": \"generate_sql\",\\n  \"action_input\": {\\n    \"sql\": \"SELECT SUBSTR(Date, 5, 2) AS month FROM yearmonth ym JOIN customers c ON ym.CustomerID = c.CustomerID WHERE c.Segment = \\'SME\\' AND SUBSTR(Date, 1, 4) = \\'2013\\' GROUP BY SUBSTR(Date, 5, 2) ORDER BY SUM(ym.Consumption) DESC LIMIT 1\",\\n    \"reasoning\": \"Extract only month (MM) from YYYYMM date string, filter for SME in 2013, find month with highest total consumption. Returns only month as requested.\"\\n  }\\n}\\n\\nStep 3 (after SQL executes successfully):\\n{\\n  \"thought\": \"The SQL executed successfully and returned the month. Let me verify: (1) Does it return only the month column? Yes. (2) Is the logic correct for finding the peak? Yes, I\\'m grouping by month and ordering by SUM(Consumption) DESC with LIMIT 1. (3) Are filters correct? Yes, SME segment and year 2013. I\\'m confident this is correct.\",\\n  \"action\": \"submit_final_answer\",\\n  \"action_input\": {\\n    \"sql\": \"SELECT SUBSTR(Date, 5, 2) AS month FROM yearmonth ym JOIN customers c ON ym.CustomerID = c.CustomerID WHERE c.Segment = \\'SME\\' AND SUBSTR(Date, 1, 4) = \\'2013\\' GROUP BY SUBSTR(Date, 5, 2) ORDER BY SUM(ym.Consumption) DESC LIMIT 1\",\\n    \"confidence\": \"high\",\\n    \"explanation\": \"Returns only the month (MM) with highest SME consumption in 2013, correctly handling YYYYMM date format\"\\n  }\\n}\\n\\n‚ö†Ô∏è Remember: \\n- ALWAYS probe schema first\\n- Think carefully about what columns to return\\n- Don\\'t rush - validate before submitting\\n- Respond ONLY with valid JSON, no extra text'},\n",
       "      {'role': 'user',\n",
       "       'content': 'Question: What was the gas consumption peak month for SME customers in 2013?\\n\\nPlease help me write the SQL query to answer this question.'}],\n",
       "     'response': '{\\n  \"thought\": \"The question asks for the month (peak month) when gas consumption was highest for SME customers in 2013. I need to understand the schema of the \\'yearmonth\\' table, especially the format of its Date column, to extract the year and month correctly.\",\\n  \"action\": \"probe_schema\",\\n  \"action_input\": {\\n    \"table_name\": \"yearmonth\",\\n    \"reason\": \"Determine data type and format of Date column to extract year and month\"\\n  }\\n}',\n",
       "     'token_usage': {'prompt_tokens': 2139,\n",
       "      'completion_tokens': 197,\n",
       "      'total_tokens': 2336}},\n",
       "    {'action_num': 2,\n",
       "     'messages': [{'role': 'system',\n",
       "       'content': 'You are an expert SQL agent tasked with converting natural language questions into SQL queries.\\n\\n‚ö†Ô∏è IMPORTANT: Take a systematic, multi-step approach. Submitting on your first try is rarely optimal - you have 3 attempts, use them to explore, validate, and refine!\\n\\n**SYSTEMATIC PROCESS (Follow These Steps):**\\n\\n1. **ANALYZE** - Understand exactly what the question is asking\\n   - What specific data is requested?\\n   - What is the expected format of the answer?\\n   - Are there any implicit requirements (e.g., \"which month\" means return ONLY month, not full date)?\\n\\n2. **EXPLORE** - Use probe_schema to understand the database\\n   - ALWAYS probe relevant tables before generating SQL\\n   - Understand column formats (e.g., is Date stored as YYYYMM string or timestamp?)\\n   - Verify table/column names and data types\\n   - Check for sample data if unsure\\n\\n3. **PLAN** - Think through your SQL logic\\n   - What tables do I need?\\n   - What joins are required?\\n   - What filters/aggregations?\\n   - **CRITICAL:** What columns should the SELECT return? (No extras!)\\n\\n4. **GENERATE** - Create the SQL query\\n   - Write clean, correct SQL\\n   - Match the database dialect\\n\\n5. **VALIDATE** - Before submitting, check:\\n   ‚òê Does SELECT return ONLY what the question asks for?\\n   ‚òê No extra columns (like intermediate calculations)?\\n   ‚òê Correct granularity (e.g., month vs full date)?\\n   ‚òê Proper aggregation level?\\n   ‚òê Correct ordering if question asks for \"first\", \"highest\", \"least\", etc.?\\n\\n6. **SUBMIT** - Only when confident\\n\\n**Available Tools:**\\n\\n1. **probe_schema**(table_name: str, reason: str)\\n   - Query database for detailed schema information about a table\\n   - **USE THIS FIRST** before generating SQL\\n   - Helps understand column formats, types, and sample data\\n\\n2. **generate_sql**(sql: str, reasoning: str)\\n   - Generate and execute a SQL query\\n   - Will be automatically executed and you\\'ll get results or errors\\n\\n3. **analyze_error**(analysis: str, fixable: bool)\\n   - Analyze errors from failed SQL queries\\n   - Determine what went wrong and if it\\'s fixable\\n\\n4. **submit_final_answer**(sql: str, confidence: \"high\"|\"medium\"|\"low\", explanation: str)\\n   - Submit your final SQL query\\n   - Only use after validation or when attempts exhausted\\n\\n**Database Schema (High-Level Overview):**\\nTable: customers\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\\n    - Segment (TEXT) # Example values: SME, LAM, KAM\\n    - Currency (TEXT) # Example values: EUR, CZK\\n\\nTable: gasstations\\n  Columns:\\n    - GasStationID (INTEGER) (Primary Key) # Example values: 44, 45, 46, 47, 48\\n    - ChainID (INTEGER) # Example values: 13, 6, 23, 33, 4\\n    - Country (TEXT) # Example values: CZE, SVK\\n    - Segment (TEXT) # Example values: Value for money, Premium, Other, Noname, Discount\\n\\nTable: products\\n  Columns:\\n    - ProductID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Description (TEXT) # Example values: Rucn√≠ zad√°n√≠, Nafta, Special, Super, Natural\\n\\nTable: transactions_1k\\n  Columns:\\n    - TransactionID (INTEGER) (Primary Key) # Example values: 1, 2, 3, 4, 5\\n    - Date (DATE) # Example values: 2012-08-24, 2012-08-23, 2012-08-25, 2012-08-26\\n    - Time (TEXT) # Example values: 09:41:00, 10:03:00, 13:53:00, 08:49:00, 08:53:00\\n    - CustomerID (INTEGER) # Example values: 31543, 46707, 7654, 17373, 7881\\n    - CardID (INTEGER) # Example values: 486621, 550134, 684220, 536109, 99745\\n    - GasStationID (INTEGER) # Example values: 3704, 656, 741, 1152, 636\\n    - ProductID (INTEGER) # Example values: 2, 23, 5, 11, 7\\n    - Amount (INTEGER) # Example values: 28, 18, 1, 5, 4\\n    - Price (REAL) # Example values: 672.64, 430.72, 121.99, 120.74, 645.05\\n\\nTable: sqlite_sequence\\n  Columns:\\n    - name (TEXT) # Example values: transactions_1k\\n    - seq (TEXT) # Example values: 1000\\n\\nTable: yearmonth\\n  Columns:\\n    - CustomerID (INTEGER) (Primary Key) # Example values: 39, 63, 172, 603, 1492\\n    - Date (TEXT) (Primary Key) # Example values: 201112, 201201, 201202, 201203, 201204\\n    - Consumption (REAL) # Example values: 528.3, 1598.28, 1931.36, 1497.14, 51.06\\n\\n\\n**Column Selection Rules (CRITICAL):**\\n- If question asks \"which month?\", return ONLY the month column (not month + count/consumption)\\n- If question asks \"who?\", return ONLY the identifier (CustomerID, not CustomerID + aggregate)\\n- If question asks \"how many?\", return ONLY the count (not count + other columns)\\n- Match the question\\'s specificity exactly\\n- Use SUBSTR, DATE functions as needed to extract specific parts (e.g., month from YYYYMM)\\n\\n**Response Format:**\\nYou MUST respond with ONLY a JSON object:\\n{\\n  \"thought\": \"Before taking action, I need to [what I\\'m trying to learn/accomplish]. This will help me [why this is the right step].\",\\n  \"action\": \"tool_name\",\\n  \"action_input\": {...tool parameters...}\\n}\\n\\n**Example Good Flow:**\\nStep 1:\\n{\\n  \"thought\": \"The question asks about \\'peak month for SME customers in 2013\\'. Before generating SQL, I need to understand how the Date column is formatted in the yearmonth table - is it YYYYMM string, full timestamp, or separate year/month columns? This will help me write the correct date extraction logic.\",\\n  \"action\": \"probe_schema\",\\n  \"action_input\": {\\n    \"table_name\": \"yearmonth\",\\n    \"reason\": \"Need to understand Date column format to extract month correctly\"\\n  }\\n}\\n\\nStep 2 (after seeing Date is YYYYMM string):\\n{\\n  \"thought\": \"Now I know Date is stored as YYYYMM string like \\'201301\\'. The question asks \\'what was the peak month\\' so I need to return ONLY the month (MM), not the full date or consumption amount. I\\'ll use SUBSTR(Date, 5, 2) to extract just the month digits, filter for SME and 2013, group by month, order by total consumption DESC, and LIMIT 1.\",\\n  \"action\": \"generate_sql\",\\n  \"action_input\": {\\n    \"sql\": \"SELECT SUBSTR(Date, 5, 2) AS month FROM yearmonth ym JOIN customers c ON ym.CustomerID = c.CustomerID WHERE c.Segment = \\'SME\\' AND SUBSTR(Date, 1, 4) = \\'2013\\' GROUP BY SUBSTR(Date, 5, 2) ORDER BY SUM(ym.Consumption) DESC LIMIT 1\",\\n    \"reasoning\": \"Extract only month (MM) from YYYYMM date string, filter for SME in 2013, find month with highest total consumption. Returns only month as requested.\"\\n  }\\n}\\n\\nStep 3 (after SQL executes successfully):\\n{\\n  \"thought\": \"The SQL executed successfully and returned the month. Let me verify: (1) Does it return only the month column? Yes. (2) Is the logic correct for finding the peak? Yes, I\\'m grouping by month and ordering by SUM(Consumption) DESC with LIMIT 1. (3) Are filters correct? Yes, SME segment and year 2013. I\\'m confident this is correct.\",\\n  \"action\": \"submit_final_answer\",\\n  \"action_input\": {\\n    \"sql\": \"SELECT SUBSTR(Date, 5, 2) AS month FROM yearmonth ym JOIN customers c ON ym.CustomerID = c.CustomerID WHERE c.Segment = \\'SME\\' AND SUBSTR(Date, 1, 4) = \\'2013\\' GROUP BY SUBSTR(Date, 5, 2) ORDER BY SUM(ym.Consumption) DESC LIMIT 1\",\\n    \"confidence\": \"high\",\\n    \"explanation\": \"Returns only the month (MM) with highest SME consumption in 2013, correctly handling YYYYMM date format\"\\n  }\\n}\\n\\n‚ö†Ô∏è Remember: \\n- ALWAYS probe schema first\\n- Think carefully about what columns to return\\n- Don\\'t rush - validate before submitting\\n- Respond ONLY with valid JSON, no extra text'},\n",
       "      {'role': 'user',\n",
       "       'content': 'Question: What was the gas consumption peak month for SME customers in 2013?\\n\\nPlease help me write the SQL query to answer this question.'},\n",
       "      {'role': 'assistant',\n",
       "       'content': '{\\n  \"thought\": \"The question asks for the month (peak month) when gas consumption was highest for SME customers in 2013. I need to understand the schema of the \\'yearmonth\\' table, especially the format of its Date column, to extract the year and month correctly.\",\\n  \"action\": \"probe_schema\",\\n  \"action_input\": {\\n    \"table_name\": \"yearmonth\",\\n    \"reason\": \"Determine data type and format of Date column to extract year and month\"\\n  }\\n}'},\n",
       "      {'role': 'user',\n",
       "       'content': \"Observation: Schema information for 'yearmonth':\\nAdditional schema information from database:\\n\\nTable: customers\\n  - CustomerID (INTEGER)\\n  - Segment (TEXT)\\n  - Currency (TEXT)\\n\\nTable: gasstations\\n  - GasStationID (INTEGER)\\n  - ChainID (INTEGER)\\n  - Country (TEXT)\\n  - Segment (TEXT)\\n\\nTable: products\\n  - ProductID (INTEGER)\\n  - Description (TEXT)\\n\\nTable: transactions_1k\\n  - TransactionID (INTEGER)\\n  - Date (DATE)\\n  - Time (TEXT)\\n  - CustomerID (INTEGER)\\n  - CardID (INTEGER)\\n  - GasStationID (INTEGER)\\n  - ProductID (INTEGER)\\n  - Amount (INTEGER)\\n\\n\\nWhat's your next action?\"}],\n",
       "     'response': '{\\n  \"thought\": \"Using the yearmonth table (Date stored as YYYYMM) joined with customers to filter SME segment and year 2013, I will sum consumption per month, order descending, and return only the month (MM) of the peak.\",\\n  \"action\": \"submit_final_answer\",\\n  \"action_input\": {\\n    \"sql\": \"SELECT SUBSTR(ym.Date, 5, 2) AS month\\\\nFROM yearmonth ym\\\\nJOIN customers c ON ym.CustomerID = c.CustomerID\\\\nWHERE c.Segment = \\'SME\\' AND SUBSTR(ym.Date, 1, 4) = \\'2013\\'\\\\nGROUP BY SUBSTR(ym.Date, 5, 2)\\\\nORDER BY SUM(ym.Consumption) DESC\\\\nLIMIT 1;\",\\n    \"confidence\": \"high\",\\n    \"explanation\": \"Extracts month (MM) from the YYYYMM date string, filters SME customers for 2013, aggregates consumption per month, and returns only the month with the highest total consumption.\"\\n  }\\n}',\n",
       "     'token_usage': {'prompt_tokens': 2404,\n",
       "      'completion_tokens': 526,\n",
       "      'total_tokens': 2930}}],\n",
       "   'token_usage': {'prompt_tokens': 4543,\n",
       "    'completion_tokens': 723,\n",
       "    'total_tokens': 5266},\n",
       "   'token_usage_per_attempt': [{'prompt_tokens': 2139,\n",
       "     'completion_tokens': 197,\n",
       "     'total_tokens': 2336},\n",
       "    {'prompt_tokens': 2404, 'completion_tokens': 526, 'total_tokens': 2930}],\n",
       "   'logic_sql': \"SELECT SUBSTRING(T2.Date, 5, 2) FROM yearmonth AS ym JOIN customers AS c ON ym.CustomerID = c.CustomerID WHERE c.Segment = 'SME' AND SUBSTRING(ym.Date, 1, 4) = '2013' GROUP BY SUBSTRING(ym.Date, 5, 2) ORDER BY SUM(ym.Consumption) DESC LIMIT 1\",\n",
       "   'logic_sql_execution_error': 'Error running SQL: Error running query: no such column: T2.Date',\n",
       "   'logic_execution_time_ms': None,\n",
       "   'evaluation': {'execution_accuracy': 1,\n",
       "    'non_empty_execution_accuracy': 1,\n",
       "    'subset_non_empty_execution_accuracy': 1,\n",
       "    'logic_execution_accuracy': 1,\n",
       "    'bird_execution_accuracy': 1,\n",
       "    'is_sqlglot_parsable': 1,\n",
       "    'is_sqlparse_parsable': 1,\n",
       "    'sqlglot_equivalence': 0,\n",
       "    'sqlglot_optimized_equivalence': 0,\n",
       "    'sqlparse_equivalence': 0,\n",
       "    'sql_exact_match': 0,\n",
       "    'sql_syntactic_equivalence': 0,\n",
       "    'eval_error': 0,\n",
       "    'df_error': 0,\n",
       "    'prompt_tokens': 4543,\n",
       "    'completion_tokens': 723,\n",
       "    'total_tokens': 5266,\n",
       "    'inference_time_ms': 77447.82,\n",
       "    'llm_score': 1.0,\n",
       "    'llm_explanation': 'N/A (did not use LLM due to subset match)',\n",
       "    'gt_sql': \"SELECT SUBSTR(T2.Date, 5, 2) FROM customers AS T1 INNER JOIN yearmonth AS T2 ON T1.CustomerID = T2.CustomerID WHERE SUBSTR(T2.Date, 1, 4) = '2013' AND T1.Segment = 'SME' GROUP BY SUBSTR(T2.Date, 5, 2) ORDER BY SUM(T2.Consumption) DESC LIMIT 1\",\n",
       "    'gt_df': '{\"columns\":[\"SUBSTR(T2.Date, 5, 2)\"],\"index\":[0],\"data\":[[4]]}'}}},\n",
       " 'gt_df': '{\"columns\":[\"SUBSTR(T2.Date, 5, 2)\"],\"index\":[0],\"data\":[[4]]}'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b51e2920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verdict': 'Yes',\n",
       " 'score': 1.0,\n",
       " 'explanation': 'Yes\\n\\nThe predicted SQL query is correct. It joins the `yearmonth` table with the `customers` table on the `CustomerID` column, filters the results to only include rows where the `Date` is between \\'201301\\' and \\'201312\\' (i.e., the year 2013) and the `Segment` is \\'SME\\'. The results are then grouped by the `Date` column, ordered by the sum of the `Consumption` column in descending order, and limited to the top row (i.e., the peak month).\\n\\nThe predicted result, [201304], indicates that the peak month for SME customers in 2013 was April (04). This is a reasonable interpretation of the question, as the `Date` column in the `yearmonth` table appears to be in the format \\'YYYYMM\\'.\\n\\nThe ground truth SQL query uses a different approach, extracting the month from the `Date` column using the `SUBSTR` function and grouping by the resulting month. However, the predicted SQL query is more straightforward and easier to understand, and it produces a similar result. Therefore, the predicted SQL query is correct. \\n\\nNote: The predicted result [201304] and the ground truth result [4] are essentially the same, as they both indicate that the peak month was April. The difference in format is due to the different approaches used in the two SQL queries. \\n\\nIn conclusion, the predicted SQL query is a reasonable interpretation of the question and produces a correct result, so the verdict is \"Yes\". \\n\\nNote: The predicted SQL query could be improved by extracting the month from the `Date` column, as in the ground truth SQL query, to make it clearer that the result is a month. However, this is not necessary to produce the correct result, and the predicted SQL query is still correct as it is. \\n\\nIn summary, the predicted SQL query is correct, and the verdict is \"Yes\". \\n\\nThe final answer is: $\\\\boxed{Yes}$ \\n\\nPlease let me know if you need further clarification or details. \\n\\nI hope it is correct. \\n\\nLet me know if I can help with anything else. \\n\\nBest regards. \\nYes. \\n\\nI hope it is correct. \\n\\nLet me know if I can help with anything else. \\n\\nBest regards. \\nYes. \\n\\nI hope it is correct. \\n\\nLet me know if I can help with anything else. \\n\\nBest regards. \\nYes. \\n\\nI hope it is correct. \\n\\nLet me know if I'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If use_llm is not used in the evaluation, or you need additional evaluations, you can invoke LLM as judge as shown here.\n",
    "\n",
    "from text2sql_eval_toolkit.inference.inference_tools import WXAIClient\n",
    "from text2sql_eval_toolkit.evaluation.llm_as_judge import (\n",
    "    evaluate_sql_prediction_with_llm,\n",
    "    load_llm_judge_config,\n",
    ")\n",
    "\n",
    "prediction_pipeline_id = \"wxai:openai/gpt-oss-120b-greedy-zero-shot-chatapi\"\n",
    "failed_example = failed_examples[0]\n",
    "question = (\n",
    "    failed_example[\"page_content\"]\n",
    "    if \"page_content\" in failed_example\n",
    "    else failed_example[\"question\"]\n",
    "    if \"question\" in failed_example\n",
    "    else failed_example[\"utterance\"]\n",
    ")\n",
    "ground_truth_sql = failed_example[\"sql\"]\n",
    "ground_truth_df = failed_example[\"gt_df\"]\n",
    "predicted_sql = failed_example[\"predictions\"][prediction_pipeline_id][\"predicted_sql\"]\n",
    "predicted_df = failed_example[\"predictions\"][prediction_pipeline_id][\"predicted_df\"]\n",
    "prompt = failed_example[\"predictions\"][prediction_pipeline_id][\"prompt\"]\n",
    "llm_judge_config = load_llm_judge_config()\n",
    "llm_as_judge_response = evaluate_sql_prediction_with_llm(\n",
    "    question,\n",
    "    ground_truth_sql,\n",
    "    ground_truth_df,\n",
    "    predicted_sql,\n",
    "    predicted_df,\n",
    "    prompt,\n",
    "    llm_judge_config,\n",
    ")\n",
    "llm_as_judge_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "662c23e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [02:46<00:00,  8.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Verdict</th>\n",
       "      <th>Score</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes\\n\\nThe predicted SQL query is a reasonable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes\\n\\nThe predicted SQL query is correct. Alt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes\\n\\nThe predicted SQL query is correct. Alt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes\\n\\nThe predicted SQL query is correct. It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes\\n\\nThe predicted SQL query is correct. Alt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes\\n\\nThe predicted SQL query is correct. It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes\\n\\nThe predicted SQL query is correct. Alt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes\\n\\nThe predicted SQL query is a reasonable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No\\n\\nThe predicted SQL is incorrect because i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes\\n\\nThe predicted SQL query is correct. It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No\\n\\nThe predicted SQL is incorrect for sever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes\\n\\nThe predicted SQL query is correct. Alt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes\\n\\nThe predicted SQL query is correct. Alt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No\\n\\nThe predicted SQL query does not correct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No\\n\\nThe predicted SQL does not match the gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes\\n\\nThe predicted SQL query is correct. It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes\\n\\nThe predicted SQL query is a reasonable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes\\n\\nThe predicted SQL query is correct. It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No\\n\\nThe predicted SQL does not correctly ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes\\n\\nThe predicted SQL query is correct. It ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index Verdict  Score                                        Explanation\n",
       "0       0     Yes    1.0  Yes\\n\\nThe predicted SQL query is a reasonable...\n",
       "1       1     Yes    1.0  Yes\\n\\nThe predicted SQL query is correct. Alt...\n",
       "2       2     Yes    1.0  Yes\\n\\nThe predicted SQL query is correct. Alt...\n",
       "3       3     Yes    1.0  Yes\\n\\nThe predicted SQL query is correct. It ...\n",
       "4       4     Yes    1.0  Yes\\n\\nThe predicted SQL query is correct. Alt...\n",
       "5       5     Yes    1.0  Yes\\n\\nThe predicted SQL query is correct. It ...\n",
       "6       6     Yes    1.0  Yes\\n\\nThe predicted SQL query is correct. Alt...\n",
       "7       7     Yes    1.0  Yes\\n\\nThe predicted SQL query is a reasonable...\n",
       "8       8      No    0.0  No\\n\\nThe predicted SQL is incorrect because i...\n",
       "9       9     Yes    1.0  Yes\\n\\nThe predicted SQL query is correct. It ...\n",
       "10     10      No    0.0  No\\n\\nThe predicted SQL is incorrect for sever...\n",
       "11     11     Yes    1.0  Yes\\n\\nThe predicted SQL query is correct. Alt...\n",
       "12     12     Yes    1.0  Yes\\n\\nThe predicted SQL query is correct. Alt...\n",
       "13     13      No    0.0  No\\n\\nThe predicted SQL query does not correct...\n",
       "14     14      No    0.0  No\\n\\nThe predicted SQL does not match the gro...\n",
       "15     15     Yes    1.0  Yes\\n\\nThe predicted SQL query is correct. It ...\n",
       "16     16     Yes    1.0  Yes\\n\\nThe predicted SQL query is a reasonable...\n",
       "17     17     Yes    1.0  Yes\\n\\nThe predicted SQL query is correct. It ...\n",
       "18     18      No    0.0  No\\n\\nThe predicted SQL does not correctly ans...\n",
       "19     19     Yes    1.0  Yes\\n\\nThe predicted SQL query is correct. It ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Use the pipeline_id from the current analysis\n",
    "prediction_pipeline_id = pipeline_id\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "for idx, failed_example in tqdm(enumerate(failed_examples), total=len(failed_examples)):\n",
    "    question = (\n",
    "        failed_example.get(\"page_content\")\n",
    "        or failed_example.get(\"question\")\n",
    "        or failed_example.get(\"utterance\")\n",
    "    )\n",
    "    \n",
    "    # Use safe access with .get() to handle missing fields\n",
    "    ground_truth_sql = failed_example.get(\"sql\") or failed_example.get(\"SQL\") or failed_example.get(\"metadata\", {}).get(\"sql\", [])\n",
    "    ground_truth_df = failed_example.get(\"gt_df\", \"\")\n",
    "    \n",
    "    # Check if pipeline_id exists in predictions\n",
    "    if prediction_pipeline_id not in failed_example.get(\"predictions\", {}):\n",
    "        print(f\"Skipping example {idx}: pipeline_id not found\")\n",
    "        continue\n",
    "    \n",
    "    pred = failed_example[\"predictions\"][prediction_pipeline_id]\n",
    "    predicted_sql = pred.get(\"predicted_sql\", \"\")\n",
    "    predicted_df = pred.get(\"predicted_df\", \"\")\n",
    "    prompt = pred.get(\"prompt\", \"\")\n",
    "    \n",
    "    # Skip if predicted_df is missing (execution error)\n",
    "    if not predicted_df:\n",
    "        print(f\"Skipping example {idx}: no predicted_df (likely execution error)\")\n",
    "        continue\n",
    "\n",
    "    eval_response = evaluate_sql_prediction_with_llm(\n",
    "        question,\n",
    "        ground_truth_sql,\n",
    "        ground_truth_df,\n",
    "        predicted_sql,\n",
    "        predicted_df,\n",
    "        prompt,\n",
    "        llm_judge_config,\n",
    "    )\n",
    "\n",
    "    evaluation_results.append(\n",
    "        {\n",
    "            \"Index\": idx,\n",
    "            \"Verdict\": eval_response.get(\"verdict\"),\n",
    "            \"Score\": eval_response.get(\"score\"),\n",
    "            \"Explanation\": eval_response.get(\"explanation\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "results_df = pd.DataFrame(evaluation_results)\n",
    "results_df[[\"Index\", \"Verdict\", \"Score\", \"Explanation\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "661c32de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ‚ùì Failed Question #1 (out of 20) - Question ID: 1498\n",
       "Question: What is the highest monthly consumption in the year 2012?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ‚úÖ Ground Truth SQL(s)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```sql\n",
       "SELECT SUM(Consumption) FROM yearmonth WHERE SUBSTR(Date, 1, 4) = '2012' GROUP BY SUBSTR(Date, 5, 2) ORDER BY SUM(Consumption) DESC LIMIT 1\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ‚ùå Predicted SQL"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```sql\n",
       "SELECT MAX(month_total) AS highest_monthly_consumption\n",
       "FROM (\n",
       "    SELECT SUM(Consumption) AS month_total\n",
       "    FROM yearmonth\n",
       "    WHERE Date LIKE '2012%'\n",
       "    GROUP BY Date\n",
       ")\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üìä Evaluation Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>execution_accuracy</th>\n",
       "      <th>non_empty_execution_accuracy</th>\n",
       "      <th>subset_non_empty_execution_accuracy</th>\n",
       "      <th>logic_execution_accuracy</th>\n",
       "      <th>bird_execution_accuracy</th>\n",
       "      <th>is_sqlglot_parsable</th>\n",
       "      <th>is_sqlparse_parsable</th>\n",
       "      <th>sqlglot_equivalence</th>\n",
       "      <th>sqlglot_optimized_equivalence</th>\n",
       "      <th>sqlparse_equivalence</th>\n",
       "      <th>sql_exact_match</th>\n",
       "      <th>sql_syntactic_equivalence</th>\n",
       "      <th>eval_error</th>\n",
       "      <th>df_error</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>inference_time_ms</th>\n",
       "      <th>llm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>952</td>\n",
       "      <td>390</td>\n",
       "      <td>1342</td>\n",
       "      <td>4570.91</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   execution_accuracy  non_empty_execution_accuracy  \\\n",
       "0                   1                             1   \n",
       "\n",
       "   subset_non_empty_execution_accuracy  logic_execution_accuracy  \\\n",
       "0                                    1                         1   \n",
       "\n",
       "   bird_execution_accuracy  is_sqlglot_parsable  is_sqlparse_parsable  \\\n",
       "0                        1                    1                     1   \n",
       "\n",
       "   sqlglot_equivalence  sqlglot_optimized_equivalence  sqlparse_equivalence  \\\n",
       "0                    0                              0                     0   \n",
       "\n",
       "   sql_exact_match  sql_syntactic_equivalence  eval_error  df_error  \\\n",
       "0                0                          0           0         0   \n",
       "\n",
       "   prompt_tokens  completion_tokens  total_tokens  inference_time_ms  \\\n",
       "0            952                390          1342            4570.91   \n",
       "\n",
       "   llm_score  \n",
       "0        1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üìò Ground Truth Result(s)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Result 1:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUM(Consumption)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51787161.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUM(Consumption)\n",
       "0       51787161.74"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üìï Predicted Result"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highest_monthly_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51787161.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   highest_monthly_consumption\n",
       "0                  51787161.74"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ü§ñ Agent Interaction Trace"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Step 1: generate_sql_attempt_1**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<details><summary>üìù Messages</summary>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**System:**\n",
       "```\n",
       "You are a SQL expert. Your task is to convert natural language questions into accurate SQL queries using the given database schema and instructions.\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**User:**\n",
       "```\n",
       "Your task is to convert a natural language question into an accurate SQL query using the given sqlite database schema.\n",
       "\n",
       "**Question:**:\n",
       "What is the highest monthly consumption in the year 2012?\n",
       "\n",
       "**Database Engine / Dialect:**:\n",
       "sqlite\n",
       "\n",
       "**Schema:**\n",
       "Table: customers\n",
       "  Columns:\n",
       "    - CustomerID (INTEGER) (Primary Key) # Example values: 3, 5, 6, 7, 9\n",
       "    - Segment (TEXT) # Example values: SME, LAM, KAM\n",
       "    - Currency (TEXT) # Example values: EUR, CZK\n",
       "\n",
       "Table: gasstations\n",
       "  Columns:\n",
       "    - GasStationID (\n",
       "‚Ä¶\n",
       "e columns listed in the schema.\n",
       "- Do not use any other columns or tables not mentioned in the schema.\n",
       "- Ensure the SQL query is valid and executable.\n",
       "- Use proper SQL syntax and conventions.\n",
       "- Generate a complete SQL query that answers the question.\n",
       "- Use the correct SQL dialect for the database, i.e., sqlite.\n",
       "- Do not include any explanations or comments in the SQL output.\n",
       "- Your output must start with ```sql and end with ```.\n",
       "\n",
       "Question: What is the highest monthly consumption in the year 2012?\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "</details>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Response:** `SELECT MAX(month_total) AS highest_monthly_consumption\n",
       "FROM (\n",
       "    SELECT SUM(Consumption) AS month_total\n",
       "    FROM yearmonth\n",
       "    WHERE Date LIKE '2012%'\n",
       "    GROUP BY Date\n",
       ")`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Parsed SQL:** \n",
       "```sql\n",
       "SELECT MAX(month_total) AS highest_monthly_consumption\n",
       "FROM (\n",
       "    SELECT SUM(Consumption) AS month_total\n",
       "    FROM yearmonth\n",
       "    WHERE Date LIKE '2012%'\n",
       "    GROUP BY Date\n",
       ")\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Total Attempts:** 1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ü§ñ LLM Judge Assessment\n",
       "LLM judge score: `1.0`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "LLM judge explanation (if applicable):\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "N/A (did not use LLM due to subset match)\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_investigate = 1\n",
    "show_failed_example(pipeline_id, failed_examples, index_to_investigate)\n",
    "# Note: LLM judge explanation is now displayed within show_failed_example() if available"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
